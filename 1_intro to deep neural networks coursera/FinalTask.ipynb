{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dad3b8ec",
   "metadata": {},
   "source": [
    "# Deep learning and neural networks with Keras \n",
    "## Final Assignment\n",
    "\n",
    "Dear Reviewer,\n",
    "\n",
    "As the code takes long to run, feel free to confirm the results from the print statements below.\n",
    "The full code and output is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecf5a202",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE over 50 runs: 166.5135204473709\n",
      "Average MSE standard deviation over 50 runs: 26.807393038683127\n"
     ]
    }
   ],
   "source": [
    "# Model A\n",
    "average_mse = 166.5135204473709\n",
    "mse_std_dev = 26.807393038683127\n",
    "\n",
    "print(f\"Average MSE over 50 runs: {average_mse}\")\n",
    "print(f\"Average MSE standard deviation over 50 runs: {mse_std_dev}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0223359",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE over 50 runs: 174.3180182607921\n",
      "Average MSE standard deviation over 50 runs: 11.690801559261702\n"
     ]
    }
   ],
   "source": [
    "# Model B\n",
    "average_mse = 174.3180182607921\n",
    "mse_std_dev = 11.690801559261702\n",
    "\n",
    "print(f\"Average MSE over 50 runs: {average_mse}\")\n",
    "print(f\"Average MSE standard deviation over 50 runs: {mse_std_dev}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a688d614",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE over 50 runs: 150.51735768566263\n",
      "Average MSE standard deviation over 50 runs: 8.652536798143476\n"
     ]
    }
   ],
   "source": [
    "#Model C\n",
    "average_mse = 150.51735768566263\n",
    "mse_std_dev = 8.652536798143476\n",
    "\n",
    "print(f\"Average MSE over 50 runs: {average_mse}\")\n",
    "print(f\"Average MSE standard deviation over 50 runs: {mse_std_dev}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e8b3228",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE over 50 runs: 142.12590004321572\n",
      "Average MSE standard deviation over 50 runs: 9.318308613870558\n"
     ]
    }
   ],
   "source": [
    "# Model D\n",
    "\n",
    "average_mse = 142.12590004321572\n",
    "mse_std_dev = 9.318308613870558\n",
    "\n",
    "print(f\"Average MSE over 50 runs: {average_mse}\")\n",
    "print(f\"Average MSE standard deviation over 50 runs: {mse_std_dev}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad12f5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv(\"concrete_data.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aae0f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 14:53:46.677023: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-24 14:53:58.940980: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-11-24 14:53:58.941037: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-11-24 14:54:46.191536: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-24 14:54:46.191977: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-24 14:54:46.192009: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#Libraries used\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09f13cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns of the original data frame are:  ['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer', 'Coarse Aggregate', 'Fine Aggregate', 'Age', 'Strength']\n",
      "The features in this dataset are:  ['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer', 'Coarse Aggregate', 'Fine Aggregate']\n",
      "The dependent variable of this dataset is: Strength\n"
     ]
    }
   ],
   "source": [
    "#Defining the X and Y variables\n",
    "print(\"The columns of the original data frame are: \",list(data.columns))\n",
    "\n",
    "#Strength is removed as it is the dependent variable.\n",
    "#Age is removed as per assignment instruction\n",
    "\n",
    "X=data.drop([\"Strength\",\"Age\"],axis=1)  \n",
    "print(\"The features in this dataset are: \",list(X.columns))\n",
    "Y=data[\"Strength\"]\n",
    "print(\"The dependent variable of this dataset is: Strength\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60365726",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "A. Build a baseline model (5 marks) \n",
    "\n",
    "Use the Keras library to build a neural network with the following:\n",
    "\n",
    "- One hidden layer of 10 nodes, and a ReLU activation function\n",
    "\n",
    "- Use the adam optimizer and the mean squared error  as the loss function.\n",
    "\n",
    "1. Randomly split the data into a training and test sets by holding 30% of the data for testing. You can use the \n",
    "train_test_split\n",
    "helper function from Scikit-learn.\n",
    "\n",
    "2. Train the model on the training data using 50 epochs.\n",
    "\n",
    "3. Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn.\n",
    "\n",
    "4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors.\n",
    "\n",
    "5. Report the mean and the standard deviation of the mean squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b362c6e7",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 14:55:18.145567: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-11-24 14:55:18.145621: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-11-24 14:55:18.145673: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sikikompjuter): /proc/driver/nvidia/version does not exist\n",
      "2023-11-24 14:55:18.146294: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 11ms/step - loss: 1099.5201 - val_loss: 352.1482\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 391.4521 - val_loss: 355.3238\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 317.6089 - val_loss: 289.6486\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 284.3217 - val_loss: 248.8376\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 257.4626 - val_loss: 224.3273\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 235.5041 - val_loss: 209.3641\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 221.6794 - val_loss: 197.2276\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 206.6474 - val_loss: 178.7059\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.7194 - val_loss: 173.2126\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.8831 - val_loss: 163.2948\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.7746 - val_loss: 157.8470\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.1866 - val_loss: 168.3272\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.7154 - val_loss: 157.2133\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.3791 - val_loss: 151.9427\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.2528 - val_loss: 158.3311\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 170.2121 - val_loss: 149.5577\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.9507 - val_loss: 161.5389\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.6273 - val_loss: 169.2791\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 169.5016 - val_loss: 161.9598\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.8437 - val_loss: 146.7793\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 167.3490 - val_loss: 177.7040\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.4105 - val_loss: 156.4801\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 162.0298 - val_loss: 152.5616\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.4592 - val_loss: 145.9717\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.1842 - val_loss: 178.8195\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.1605 - val_loss: 151.9536\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.0085 - val_loss: 143.5459\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.5830 - val_loss: 146.4806\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 163.7909 - val_loss: 145.4724\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.8960 - val_loss: 143.3263\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.4368 - val_loss: 150.1882\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.6508 - val_loss: 144.8862\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.4347 - val_loss: 143.7901\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.4087 - val_loss: 150.0642\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.2879 - val_loss: 143.0240\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.8995 - val_loss: 146.8020\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.3806 - val_loss: 146.6098\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.5231 - val_loss: 142.4754\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.2112 - val_loss: 143.0868\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.6137 - val_loss: 143.3434\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.8562 - val_loss: 169.1015\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.2061 - val_loss: 142.5609\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.0435 - val_loss: 145.9585\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.9220 - val_loss: 149.8762\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.6702 - val_loss: 144.6352\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.4574 - val_loss: 142.4897\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.5528 - val_loss: 145.2724\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.9517 - val_loss: 147.1599\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.4753 - val_loss: 188.1195\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.4349 - val_loss: 168.8072\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 967.4166 - val_loss: 514.4152\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 403.0788 - val_loss: 267.3116\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 293.3051 - val_loss: 232.7445\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 257.5525 - val_loss: 206.5381\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 230.9308 - val_loss: 196.7085\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 215.8002 - val_loss: 194.4921\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.2819 - val_loss: 211.4956\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.8537 - val_loss: 181.9453\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.3749 - val_loss: 195.5033\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.1763 - val_loss: 174.6755\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 183.5652 - val_loss: 177.1371\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.9839 - val_loss: 171.3883\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.5369 - val_loss: 172.0407\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.7669 - val_loss: 164.7083\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.1828 - val_loss: 163.3635\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.0067 - val_loss: 170.0471\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.2630 - val_loss: 163.1858\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.3913 - val_loss: 165.0042\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.1155 - val_loss: 170.6451\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.7975 - val_loss: 164.3501\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.7622 - val_loss: 160.6897\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.2056 - val_loss: 162.5853\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.5650 - val_loss: 179.3417\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.2149 - val_loss: 163.8695\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.6565 - val_loss: 184.0017\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.1271 - val_loss: 163.6160\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.3956 - val_loss: 160.2729\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.5055 - val_loss: 158.8226\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.2811 - val_loss: 164.2127\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.4879 - val_loss: 160.6364\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.1658 - val_loss: 162.1394\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.6054 - val_loss: 160.4224\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.6794 - val_loss: 158.7285\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.0997 - val_loss: 158.0416\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.9910 - val_loss: 158.6624\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.3850 - val_loss: 157.1494\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.0603 - val_loss: 161.4590\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.0479 - val_loss: 166.6082\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.8060 - val_loss: 161.1816\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.1444 - val_loss: 159.9184\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.6789 - val_loss: 180.2684\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.5140 - val_loss: 159.5221\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.7816 - val_loss: 167.2824\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.6124 - val_loss: 159.4851\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.9224 - val_loss: 168.8041\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8622 - val_loss: 156.9852\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.4456 - val_loss: 160.8195\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.6403 - val_loss: 164.4831\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.0407 - val_loss: 156.4152\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.8197 - val_loss: 162.0480\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 17833.7324 - val_loss: 3448.7839\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1526.7776 - val_loss: 360.0921\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 309.2161 - val_loss: 299.4840\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 288.9990 - val_loss: 277.9868\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 273.5101 - val_loss: 265.4462\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 259.3189 - val_loss: 255.0510\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 245.2243 - val_loss: 241.3306\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 232.9610 - val_loss: 228.1179\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 222.9247 - val_loss: 222.6492\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.8651 - val_loss: 201.9772\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.4973 - val_loss: 194.1119\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.9651 - val_loss: 190.5095\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.9347 - val_loss: 198.2939\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.4436 - val_loss: 180.7581\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.1990 - val_loss: 177.8102\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.6849 - val_loss: 176.0665\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.7606 - val_loss: 180.4615\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 168.0953 - val_loss: 172.7239\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.0075 - val_loss: 173.2252\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.8923 - val_loss: 169.9482\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.6412 - val_loss: 168.7759\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.1526 - val_loss: 168.9758\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.7650 - val_loss: 172.8705\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.4419 - val_loss: 171.1778\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.0137 - val_loss: 170.2251\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8180 - val_loss: 165.2891\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.7318 - val_loss: 166.0445\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.6468 - val_loss: 166.1404\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.3325 - val_loss: 175.7395\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.5629 - val_loss: 166.1954\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.4774 - val_loss: 165.3013\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8849 - val_loss: 164.8614\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.3212 - val_loss: 165.5451\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.7206 - val_loss: 180.9327\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.8294 - val_loss: 170.9892\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.8216 - val_loss: 162.5624\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.5066 - val_loss: 166.2292\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.6322 - val_loss: 163.9901\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.8891 - val_loss: 161.7292\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.3526 - val_loss: 161.9163\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.7533 - val_loss: 162.0196\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.5284 - val_loss: 161.3118\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.3938 - val_loss: 163.1694\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.6532 - val_loss: 171.9766\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.5977 - val_loss: 166.6421\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.0909 - val_loss: 160.6272\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.3457 - val_loss: 160.5927\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.2167 - val_loss: 160.4192\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.1426 - val_loss: 160.5318\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.6983 - val_loss: 159.9814\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 515.3992 - val_loss: 352.9023\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 295.4099 - val_loss: 272.8033\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 272.4687 - val_loss: 260.2891\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 245.4100 - val_loss: 249.8915\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 233.3099 - val_loss: 228.3564\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.9679 - val_loss: 212.9862\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.7159 - val_loss: 204.5838\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.5884 - val_loss: 205.3598\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.0736 - val_loss: 194.9702\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.4094 - val_loss: 183.5346\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.2764 - val_loss: 178.7427\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.3816 - val_loss: 185.5716\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.1258 - val_loss: 183.1899\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.0201 - val_loss: 165.2036\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.5588 - val_loss: 165.0726\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.1911 - val_loss: 167.2099\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.2069 - val_loss: 164.7639\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.3097 - val_loss: 182.7918\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.4767 - val_loss: 180.7383\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.5782 - val_loss: 181.3203\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.2664 - val_loss: 169.6611\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.0541 - val_loss: 169.4877\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.1077 - val_loss: 159.6621\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.9671 - val_loss: 162.8314\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.5678 - val_loss: 157.9465\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.0031 - val_loss: 155.3220\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.5702 - val_loss: 161.0494\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.5474 - val_loss: 169.3661\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.6813 - val_loss: 182.4073\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.5405 - val_loss: 163.2522\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 157.6049 - val_loss: 166.3131\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 159.5793 - val_loss: 180.5498\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.7809 - val_loss: 173.6225\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.3394 - val_loss: 164.4996\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.8358 - val_loss: 183.0869\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.1128 - val_loss: 190.9840\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.0859 - val_loss: 159.6844\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.9451 - val_loss: 178.4139\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.9406 - val_loss: 159.0990\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.0376 - val_loss: 159.8462\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.0066 - val_loss: 166.3077\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.4207 - val_loss: 155.6869\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.2434 - val_loss: 158.4658\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.9030 - val_loss: 169.6082\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.7832 - val_loss: 163.0600\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.7523 - val_loss: 161.8151\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.1235 - val_loss: 160.5586\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.9845 - val_loss: 157.9198\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.4640 - val_loss: 172.2212\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.1760 - val_loss: 161.9161\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 74329.4766 - val_loss: 5196.5391\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2200.9495 - val_loss: 1823.8481\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 968.2011 - val_loss: 416.3090\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 582.4863 - val_loss: 374.5579\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 489.9987 - val_loss: 339.4213\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 434.5017 - val_loss: 311.0508\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 391.5557 - val_loss: 291.6740\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 354.9240 - val_loss: 275.8299\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 327.6797 - val_loss: 264.6032\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 302.5362 - val_loss: 255.2060\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 284.5871 - val_loss: 245.5945\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 267.3279 - val_loss: 241.0008\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 255.9915 - val_loss: 234.3525\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 243.9935 - val_loss: 229.6647\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 236.9370 - val_loss: 224.5526\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 228.6931 - val_loss: 221.9461\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 223.1328 - val_loss: 216.1841\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 215.9631 - val_loss: 212.7990\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.9210 - val_loss: 213.1743\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.8946 - val_loss: 206.8077\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.6661 - val_loss: 202.8025\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.5568 - val_loss: 200.3806\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.9717 - val_loss: 198.2489\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.5434 - val_loss: 198.9632\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.7925 - val_loss: 192.9175\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.0970 - val_loss: 198.0879\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.2984 - val_loss: 194.1698\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.8985 - val_loss: 191.3135\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.7871 - val_loss: 187.5637\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.2659 - val_loss: 185.7092\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.9200 - val_loss: 185.6328\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.2594 - val_loss: 182.5185\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.0456 - val_loss: 184.6889\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.9104 - val_loss: 181.4016\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.1810 - val_loss: 180.1368\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.6440 - val_loss: 181.3209\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.2994 - val_loss: 177.8724\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.2698 - val_loss: 177.1516\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.0071 - val_loss: 178.8020\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.7861 - val_loss: 176.3323\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.8525 - val_loss: 178.6361\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.1109 - val_loss: 179.1706\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.0370 - val_loss: 177.5713\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.0958 - val_loss: 173.7391\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.3635 - val_loss: 173.2945\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.4452 - val_loss: 174.1158\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.4510 - val_loss: 174.8995\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.8846 - val_loss: 174.0589\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.3201 - val_loss: 171.4053\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.2927 - val_loss: 171.2213\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 14319.1064 - val_loss: 718.3519\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 496.0522 - val_loss: 552.5971\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 400.8312 - val_loss: 302.1653\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 313.7638 - val_loss: 285.9467\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 294.3155 - val_loss: 274.8107\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 280.0579 - val_loss: 258.3664\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 265.9384 - val_loss: 247.7383\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 253.9364 - val_loss: 233.5108\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 242.3859 - val_loss: 222.6634\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 232.0538 - val_loss: 214.1947\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 224.3074 - val_loss: 205.5258\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 219.0371 - val_loss: 201.3784\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.3354 - val_loss: 193.6513\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.1695 - val_loss: 190.9448\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.3158 - val_loss: 186.4708\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.7775 - val_loss: 182.3030\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.8453 - val_loss: 183.9884\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.2764 - val_loss: 175.6302\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.1770 - val_loss: 173.4181\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.2377 - val_loss: 171.3879\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.9093 - val_loss: 168.5048\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.4270 - val_loss: 164.7750\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.7792 - val_loss: 164.1290\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.6707 - val_loss: 163.1810\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.0386 - val_loss: 159.8401\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.2330 - val_loss: 158.0800\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.8778 - val_loss: 158.7030\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.8953 - val_loss: 163.3595\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.6852 - val_loss: 158.5998\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.1883 - val_loss: 155.4819\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.0407 - val_loss: 153.3232\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.9613 - val_loss: 165.8171\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.7499 - val_loss: 157.0003\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.6519 - val_loss: 155.8401\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.3923 - val_loss: 150.9584\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8025 - val_loss: 151.4798\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.6873 - val_loss: 153.1698\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.9298 - val_loss: 153.6223\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.9149 - val_loss: 156.1770\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.0086 - val_loss: 149.7725\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.8667 - val_loss: 150.5078\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.5143 - val_loss: 151.9077\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.0618 - val_loss: 166.2818\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.0782 - val_loss: 149.6207\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.1031 - val_loss: 149.7404\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.1137 - val_loss: 149.1282\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.3861 - val_loss: 148.1866\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.4431 - val_loss: 148.2988\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.3317 - val_loss: 148.5184\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.0890 - val_loss: 149.9263\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 4370.0098 - val_loss: 1013.9464\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 650.4038 - val_loss: 432.1749\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 434.9903 - val_loss: 359.8044\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 315.6254 - val_loss: 267.4322\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 258.1168 - val_loss: 231.9385\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 229.7032 - val_loss: 210.2576\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.7299 - val_loss: 202.8759\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.4884 - val_loss: 182.7936\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.3142 - val_loss: 177.1085\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.9861 - val_loss: 179.1338\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.2564 - val_loss: 168.0566\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.4674 - val_loss: 168.0861\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.2241 - val_loss: 156.9903\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.0856 - val_loss: 155.3638\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.9434 - val_loss: 159.0907\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.6915 - val_loss: 175.5078\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.1296 - val_loss: 152.4235\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.2622 - val_loss: 153.8387\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.9863 - val_loss: 155.0807\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.7485 - val_loss: 153.5719\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.6060 - val_loss: 162.1544\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 161.4344 - val_loss: 152.7863\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.0137 - val_loss: 150.8709\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.2160 - val_loss: 171.8183\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.2792 - val_loss: 152.6946\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.3364 - val_loss: 175.7227\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.8700 - val_loss: 168.5720\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.5387 - val_loss: 151.7003\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.9514 - val_loss: 157.3149\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.7333 - val_loss: 160.3426\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.8828 - val_loss: 150.9729\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.7106 - val_loss: 173.2399\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.0589 - val_loss: 153.4470\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.8144 - val_loss: 150.7320\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.5560 - val_loss: 150.7184\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.8837 - val_loss: 168.6148\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.6624 - val_loss: 150.3606\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.5266 - val_loss: 167.3748\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.5692 - val_loss: 156.8924\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.9128 - val_loss: 154.7544\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.8567 - val_loss: 175.7173\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.8139 - val_loss: 178.5672\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.0508 - val_loss: 149.8079\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.7330 - val_loss: 151.2892\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.6300 - val_loss: 152.0491\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.1017 - val_loss: 151.5014\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.6835 - val_loss: 149.9977\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.7565 - val_loss: 160.1946\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.5011 - val_loss: 153.9274\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.3181 - val_loss: 149.0061\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 13469.4785 - val_loss: 4736.4888\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2442.9988 - val_loss: 1592.2319\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1428.6960 - val_loss: 1166.3694\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1111.8763 - val_loss: 900.1219\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 900.2127 - val_loss: 736.2103\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 742.8942 - val_loss: 637.1738\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 632.4233 - val_loss: 569.1835\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 545.1436 - val_loss: 475.4706\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 465.9958 - val_loss: 413.8146\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 409.4236 - val_loss: 363.2573\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 359.7148 - val_loss: 326.1717\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 324.7592 - val_loss: 291.0891\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 286.1260 - val_loss: 263.6498\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 258.6770 - val_loss: 243.4677\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 239.1501 - val_loss: 228.4714\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 223.5085 - val_loss: 216.5376\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.7321 - val_loss: 204.7650\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.3156 - val_loss: 198.4353\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.1331 - val_loss: 191.6540\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.5248 - val_loss: 190.3420\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.5573 - val_loss: 201.4071\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.8921 - val_loss: 181.7791\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.4091 - val_loss: 180.8958\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.3772 - val_loss: 177.8207\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.1339 - val_loss: 173.8195\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.5983 - val_loss: 173.1606\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.9891 - val_loss: 177.3938\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.3854 - val_loss: 170.8871\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.1949 - val_loss: 168.6449\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.2852 - val_loss: 181.0537\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.6722 - val_loss: 166.7982\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.9269 - val_loss: 170.1355\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.9307 - val_loss: 164.3709\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.0726 - val_loss: 172.5177\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.2418 - val_loss: 164.6276\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.7546 - val_loss: 164.1962\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.3489 - val_loss: 162.1296\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.8976 - val_loss: 161.3716\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.0564 - val_loss: 161.1451\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.6664 - val_loss: 164.6289\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.5408 - val_loss: 159.6466\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.4515 - val_loss: 158.3710\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.8730 - val_loss: 164.6880\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.1060 - val_loss: 159.2705\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.0060 - val_loss: 160.1236\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.6438 - val_loss: 156.7226\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.6880 - val_loss: 159.7085\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.6642 - val_loss: 156.4300\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.8500 - val_loss: 155.2298\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.2420 - val_loss: 185.0221\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 35198.3398 - val_loss: 1325.0381\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2192.4119 - val_loss: 574.3600\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 534.9659 - val_loss: 474.4300\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 395.2208 - val_loss: 391.8441\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 372.3032 - val_loss: 375.2491\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 354.4135 - val_loss: 359.1208\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 340.7546 - val_loss: 342.0828\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 322.9082 - val_loss: 327.9012\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 309.0008 - val_loss: 315.7952\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 295.3308 - val_loss: 301.4106\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 283.7332 - val_loss: 287.9312\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 271.3294 - val_loss: 274.8222\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 259.8199 - val_loss: 264.7852\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 247.2352 - val_loss: 250.3171\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 234.7732 - val_loss: 240.8573\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 222.8072 - val_loss: 227.3409\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.9360 - val_loss: 215.5692\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 199.9905 - val_loss: 205.8013\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.8408 - val_loss: 196.0347\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.6217 - val_loss: 196.8015\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 176.2460 - val_loss: 187.4919\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.6653 - val_loss: 181.8531\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.2243 - val_loss: 179.6838\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.7679 - val_loss: 177.7875\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 171.5280 - val_loss: 175.6567\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 171.7652 - val_loss: 177.2473\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.1834 - val_loss: 174.9960\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.0895 - val_loss: 177.3230\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.9523 - val_loss: 172.9412\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.8985 - val_loss: 175.0496\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.4889 - val_loss: 174.1821\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.5299 - val_loss: 176.0362\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.1127 - val_loss: 172.2386\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.8956 - val_loss: 171.6322\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.4060 - val_loss: 172.8858\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 164.7278 - val_loss: 171.5072\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 162.1658 - val_loss: 172.3908\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 163.0178 - val_loss: 183.9864\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 161.7398 - val_loss: 168.0280\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.6299 - val_loss: 169.3363\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 162.8567 - val_loss: 172.5123\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.2383 - val_loss: 179.7758\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 162.4586 - val_loss: 167.5870\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.1945 - val_loss: 166.4611\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.2508 - val_loss: 165.6027\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.7748 - val_loss: 165.6494\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.7886 - val_loss: 164.6564\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.1764 - val_loss: 164.2074\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.3197 - val_loss: 165.0968\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.8291 - val_loss: 168.8500\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 947.0130 - val_loss: 519.5295\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 334.7080 - val_loss: 346.1930\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 242.3825 - val_loss: 267.3492\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 219.8213 - val_loss: 246.5672\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.7994 - val_loss: 227.3198\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.0386 - val_loss: 218.8232\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.5049 - val_loss: 236.7795\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.7563 - val_loss: 207.8594\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.1754 - val_loss: 208.5869\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.9388 - val_loss: 206.3194\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.7684 - val_loss: 197.7528\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.4561 - val_loss: 197.5213\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.2265 - val_loss: 188.6498\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.5659 - val_loss: 233.9267\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.9137 - val_loss: 183.5077\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.9140 - val_loss: 185.2400\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.9166 - val_loss: 176.9434\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.0427 - val_loss: 177.1373\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.5581 - val_loss: 179.1195\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.7621 - val_loss: 175.3700\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.2837 - val_loss: 171.6886\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.5588 - val_loss: 171.7536\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.8674 - val_loss: 168.2943\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.1030 - val_loss: 170.8146\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.8201 - val_loss: 166.2427\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.4560 - val_loss: 167.2153\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.3015 - val_loss: 164.3545\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.5869 - val_loss: 179.6917\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.5723 - val_loss: 171.7725\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.1230 - val_loss: 181.3975\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4753 - val_loss: 174.8434\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.2933 - val_loss: 198.2430\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.1271 - val_loss: 160.8726\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.0406 - val_loss: 169.1069\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.9971 - val_loss: 180.9636\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.1415 - val_loss: 158.6884\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.1072 - val_loss: 165.9643\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.5117 - val_loss: 179.0031\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.7434 - val_loss: 160.5743\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.9919 - val_loss: 159.5696\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.6874 - val_loss: 167.7372\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.5999 - val_loss: 182.4742\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.0832 - val_loss: 172.8513\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.1793 - val_loss: 165.2467\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.3459 - val_loss: 171.2258\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.8681 - val_loss: 157.9478\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.2926 - val_loss: 166.5597\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.1605 - val_loss: 168.4149\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.0517 - val_loss: 157.2790\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.3013 - val_loss: 156.5179\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 16704.1074 - val_loss: 3515.2629\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2434.2573 - val_loss: 1525.3026\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1193.9263 - val_loss: 1066.6699\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 919.0319 - val_loss: 866.5368\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 707.5030 - val_loss: 673.5638\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 556.5650 - val_loss: 536.7938\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 437.7866 - val_loss: 442.2866\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 352.8628 - val_loss: 361.8562\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 290.4407 - val_loss: 311.0620\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 252.9395 - val_loss: 275.0590\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 228.6679 - val_loss: 253.0795\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.0408 - val_loss: 240.7489\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.9203 - val_loss: 231.8764\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.9157 - val_loss: 237.6578\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.5815 - val_loss: 220.8581\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.1435 - val_loss: 232.0311\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.2984 - val_loss: 232.2436\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.6690 - val_loss: 208.9026\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.4471 - val_loss: 211.1173\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.0981 - val_loss: 200.7983\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.2088 - val_loss: 198.3294\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.5786 - val_loss: 198.7641\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.2425 - val_loss: 200.6621\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.3360 - val_loss: 195.1024\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.6833 - val_loss: 193.8876\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.5551 - val_loss: 215.9319\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.6131 - val_loss: 192.9734\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.2937 - val_loss: 193.6441\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.7012 - val_loss: 192.2602\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.5459 - val_loss: 188.4648\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.6600 - val_loss: 194.4614\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.5262 - val_loss: 195.6199\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.1817 - val_loss: 187.4861\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.4887 - val_loss: 186.5300\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.0531 - val_loss: 186.6104\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.1776 - val_loss: 187.9573\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.5035 - val_loss: 184.6047\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.6738 - val_loss: 189.2764\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.4775 - val_loss: 191.5861\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.2606 - val_loss: 185.2537\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.3893 - val_loss: 184.0983\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.4392 - val_loss: 182.6834\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.0370 - val_loss: 201.7062\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.5779 - val_loss: 182.0693\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.3944 - val_loss: 188.0227\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.2336 - val_loss: 180.5177\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.5348 - val_loss: 183.1283\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.6104 - val_loss: 180.0865\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.2832 - val_loss: 201.0577\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.7019 - val_loss: 178.8823\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1414.6560 - val_loss: 460.3080\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 457.5188 - val_loss: 356.2281\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 330.6072 - val_loss: 270.7834\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 259.1179 - val_loss: 222.5128\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 220.9543 - val_loss: 195.7153\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.0947 - val_loss: 184.7856\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.7658 - val_loss: 175.0622\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.5549 - val_loss: 171.7504\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.1349 - val_loss: 169.5863\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.6519 - val_loss: 186.6776\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.0648 - val_loss: 165.0565\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.2823 - val_loss: 167.1166\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.6268 - val_loss: 161.0291\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.6949 - val_loss: 161.3296\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.4194 - val_loss: 163.5766\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.4225 - val_loss: 160.1918\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.5633 - val_loss: 158.2994\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.4394 - val_loss: 160.8410\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.5798 - val_loss: 182.0760\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.1564 - val_loss: 156.4499\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.8312 - val_loss: 156.8316\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.2027 - val_loss: 160.0581\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.6199 - val_loss: 156.8055\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.6957 - val_loss: 156.7538\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.7391 - val_loss: 168.9085\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.0665 - val_loss: 166.6104\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.1045 - val_loss: 163.0783\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.2354 - val_loss: 154.9676\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.2580 - val_loss: 192.4118\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.1458 - val_loss: 154.8195\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.0850 - val_loss: 158.4854\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.2142 - val_loss: 183.2110\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.3638 - val_loss: 156.2665\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.1329 - val_loss: 190.0883\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.5619 - val_loss: 201.5084\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.3180 - val_loss: 158.4010\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.5172 - val_loss: 165.8509\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.3544 - val_loss: 157.6368\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.8626 - val_loss: 160.4736\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.1451 - val_loss: 156.3152\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.6997 - val_loss: 164.2978\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.1505 - val_loss: 156.2573\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.9759 - val_loss: 164.8521\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.9497 - val_loss: 202.3165\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.2513 - val_loss: 191.1393\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.0626 - val_loss: 165.2888\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.5594 - val_loss: 161.0755\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.2317 - val_loss: 157.3069\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.5968 - val_loss: 171.2286\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.7546 - val_loss: 168.0007\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 47167.9219 - val_loss: 4260.9648\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1174.6008 - val_loss: 979.4080\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 698.7411 - val_loss: 516.9312\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 453.9517 - val_loss: 450.2631\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 395.6325 - val_loss: 383.2738\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 346.3548 - val_loss: 340.4216\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 312.5295 - val_loss: 313.9501\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 289.0216 - val_loss: 295.5762\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 273.7159 - val_loss: 282.4635\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 262.7580 - val_loss: 269.7903\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 251.8277 - val_loss: 261.6316\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 245.2941 - val_loss: 256.8408\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 241.6823 - val_loss: 250.4349\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 235.3771 - val_loss: 245.8555\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 232.5910 - val_loss: 243.2464\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 228.3839 - val_loss: 238.9155\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 229.7402 - val_loss: 243.4255\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 224.7049 - val_loss: 236.0157\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 221.3262 - val_loss: 232.4912\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 220.7074 - val_loss: 229.3712\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 216.8119 - val_loss: 228.6184\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 214.8183 - val_loss: 225.5631\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 214.2111 - val_loss: 222.4529\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 211.1688 - val_loss: 219.9098\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.5298 - val_loss: 221.7406\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.5785 - val_loss: 217.9058\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.6360 - val_loss: 215.8703\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.2277 - val_loss: 214.0297\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.5473 - val_loss: 210.9543\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.7977 - val_loss: 209.8540\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.5676 - val_loss: 209.7119\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.2869 - val_loss: 207.1406\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.0845 - val_loss: 205.0852\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.4813 - val_loss: 202.6741\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.0981 - val_loss: 201.9307\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.0563 - val_loss: 200.7195\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.0413 - val_loss: 201.1442\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.1748 - val_loss: 199.1694\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.3896 - val_loss: 196.1316\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.3001 - val_loss: 195.5610\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.1060 - val_loss: 194.2797\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.1137 - val_loss: 195.9691\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.8607 - val_loss: 193.0958\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.4068 - val_loss: 191.4980\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.5636 - val_loss: 192.2523\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.6657 - val_loss: 196.0906\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.4441 - val_loss: 197.3562\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.4295 - val_loss: 187.9435\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.0232 - val_loss: 186.1573\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.3180 - val_loss: 185.1749\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 16867.9844 - val_loss: 1399.6177\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1071.8920 - val_loss: 707.7918\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 460.6802 - val_loss: 364.7050\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 321.5793 - val_loss: 342.4477\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 303.1418 - val_loss: 322.6649\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 289.3288 - val_loss: 310.5367\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 278.6013 - val_loss: 301.4948\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 270.1247 - val_loss: 294.4323\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 263.0360 - val_loss: 286.2610\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 256.5476 - val_loss: 279.8441\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 250.9636 - val_loss: 273.9035\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 245.3112 - val_loss: 268.0291\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 240.5603 - val_loss: 260.8229\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 235.4137 - val_loss: 256.8304\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 230.5574 - val_loss: 250.6440\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 226.0785 - val_loss: 246.4306\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 222.1944 - val_loss: 241.2709\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 218.4752 - val_loss: 238.1915\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 215.1441 - val_loss: 234.0689\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.6801 - val_loss: 230.8619\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.0367 - val_loss: 226.9489\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 206.4262 - val_loss: 224.2341\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.0599 - val_loss: 220.7491\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.7170 - val_loss: 218.1869\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.4779 - val_loss: 215.9049\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.4313 - val_loss: 213.3867\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.3489 - val_loss: 212.2528\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.5351 - val_loss: 209.9346\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.7475 - val_loss: 205.6525\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.9511 - val_loss: 205.2185\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.1485 - val_loss: 202.4406\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.1577 - val_loss: 202.9994\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.4657 - val_loss: 199.9792\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.6366 - val_loss: 199.4782\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.7325 - val_loss: 196.4872\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.9833 - val_loss: 195.9236\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.4625 - val_loss: 193.3085\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.5873 - val_loss: 193.9731\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.5505 - val_loss: 190.5488\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.2434 - val_loss: 189.9545\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.2861 - val_loss: 187.6131\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.8980 - val_loss: 186.9021\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.5345 - val_loss: 187.2206\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.4776 - val_loss: 188.3575\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.3420 - val_loss: 183.7866\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.9680 - val_loss: 184.6893\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.1608 - val_loss: 182.9764\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.8637 - val_loss: 180.7007\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.7692 - val_loss: 181.6146\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.0103 - val_loss: 178.3409\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 21770.3691 - val_loss: 2801.9429\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1268.3513 - val_loss: 971.4769\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 788.3067 - val_loss: 956.3208\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 735.3068 - val_loss: 862.5279\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 672.7023 - val_loss: 798.8934\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 623.7314 - val_loss: 727.6608\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 582.4737 - val_loss: 671.1846\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 542.3517 - val_loss: 608.5985\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 501.3857 - val_loss: 567.0693\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 457.3664 - val_loss: 499.8410\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 415.5216 - val_loss: 441.9558\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 371.9770 - val_loss: 397.8174\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 336.1007 - val_loss: 347.3556\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 294.9534 - val_loss: 305.3440\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 262.4188 - val_loss: 263.0616\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 226.6840 - val_loss: 223.5451\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.7114 - val_loss: 205.0553\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.3476 - val_loss: 194.6628\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.0842 - val_loss: 192.5300\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.4728 - val_loss: 188.4754\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.0824 - val_loss: 176.8966\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.5308 - val_loss: 178.7162\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.5641 - val_loss: 174.9573\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.1173 - val_loss: 172.5596\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.3081 - val_loss: 171.9915\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.6022 - val_loss: 170.7742\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.3650 - val_loss: 167.0145\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.2024 - val_loss: 168.3970\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.1730 - val_loss: 167.5640\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.8089 - val_loss: 164.8414\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.1194 - val_loss: 165.6982\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.5011 - val_loss: 163.9561\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.6193 - val_loss: 161.8183\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.7894 - val_loss: 161.8204\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.5580 - val_loss: 160.9933\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.4180 - val_loss: 161.0853\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.0154 - val_loss: 159.9312\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.4293 - val_loss: 160.4965\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.5507 - val_loss: 160.2805\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.7576 - val_loss: 167.6670\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.9627 - val_loss: 174.6126\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.2931 - val_loss: 169.5029\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.5358 - val_loss: 163.0757\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.2785 - val_loss: 161.3102\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.7915 - val_loss: 159.0295\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.9374 - val_loss: 158.0894\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.0916 - val_loss: 161.0088\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.0098 - val_loss: 165.8656\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.2995 - val_loss: 161.8584\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.9362 - val_loss: 158.3897\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 4505.3564 - val_loss: 971.5494\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 902.2133 - val_loss: 509.8259\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 434.9853 - val_loss: 330.0414\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 325.3351 - val_loss: 261.8391\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 275.1201 - val_loss: 228.2485\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 243.3217 - val_loss: 206.8737\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 218.4679 - val_loss: 189.4470\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.3261 - val_loss: 174.4325\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.3607 - val_loss: 166.2546\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.3755 - val_loss: 159.1263\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.2465 - val_loss: 156.5054\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.9641 - val_loss: 155.5741\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.3706 - val_loss: 165.3491\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.6329 - val_loss: 155.7514\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.7503 - val_loss: 153.8632\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.2929 - val_loss: 154.5083\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.7700 - val_loss: 151.8956\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.4782 - val_loss: 153.0066\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.1960 - val_loss: 152.6851\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.7946 - val_loss: 158.2981\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.1729 - val_loss: 150.8287\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.0704 - val_loss: 150.5493\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.2589 - val_loss: 151.4610\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.2182 - val_loss: 150.1491\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.7643 - val_loss: 149.3844\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.2275 - val_loss: 157.3714\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.6365 - val_loss: 154.3688\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.8687 - val_loss: 149.9923\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.8670 - val_loss: 151.0457\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.5040 - val_loss: 149.1016\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.0055 - val_loss: 153.3362\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.8342 - val_loss: 154.0315\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.0105 - val_loss: 150.7829\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.2285 - val_loss: 148.7150\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.8339 - val_loss: 147.9943\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.4552 - val_loss: 149.3830\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.6436 - val_loss: 147.7225\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.2742 - val_loss: 148.3988\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.7956 - val_loss: 152.3687\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.4992 - val_loss: 151.5013\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.6558 - val_loss: 154.7495\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.3847 - val_loss: 151.4621\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.0078 - val_loss: 146.5507\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.5217 - val_loss: 146.5711\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.2226 - val_loss: 151.5389\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.4518 - val_loss: 151.5315\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.1376 - val_loss: 166.8658\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.7642 - val_loss: 150.7692\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.5501 - val_loss: 151.4798\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.1165 - val_loss: 147.7392\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 5717.2261 - val_loss: 838.9319\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 798.0237 - val_loss: 469.7051\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 464.8789 - val_loss: 413.6756\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 386.9087 - val_loss: 351.5961\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 332.1202 - val_loss: 298.8536\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 280.2466 - val_loss: 251.9092\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 229.9117 - val_loss: 206.6229\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.5652 - val_loss: 185.3102\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.1594 - val_loss: 178.1250\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.1715 - val_loss: 174.0279\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.5015 - val_loss: 168.9854\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.0894 - val_loss: 168.4777\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.7003 - val_loss: 169.4921\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.9829 - val_loss: 169.2277\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.8918 - val_loss: 167.6465\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.5465 - val_loss: 168.6918\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.3218 - val_loss: 168.3617\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.7640 - val_loss: 166.2963\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.2531 - val_loss: 167.6723\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.6039 - val_loss: 165.9396\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.3735 - val_loss: 165.6393\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.2401 - val_loss: 166.5121\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.5918 - val_loss: 165.1054\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.9096 - val_loss: 165.3573\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.7765 - val_loss: 164.2907\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.6272 - val_loss: 165.4622\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.4804 - val_loss: 169.2366\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.9240 - val_loss: 167.7772\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.5787 - val_loss: 163.7203\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.0190 - val_loss: 163.4399\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.5554 - val_loss: 165.4457\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.4379 - val_loss: 163.5235\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.8488 - val_loss: 168.7949\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.8952 - val_loss: 168.6198\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.0298 - val_loss: 164.0427\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.9958 - val_loss: 165.9844\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.9230 - val_loss: 162.5924\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.2751 - val_loss: 165.9402\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.6833 - val_loss: 162.8652\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.7591 - val_loss: 163.3681\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.2448 - val_loss: 162.0706\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.3991 - val_loss: 162.9806\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.7290 - val_loss: 164.0442\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.6726 - val_loss: 166.6552\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.4655 - val_loss: 162.9052\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.3241 - val_loss: 164.9798\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.8339 - val_loss: 177.9700\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.2541 - val_loss: 161.6075\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.4133 - val_loss: 162.0508\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.1387 - val_loss: 161.3208\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 910.1085 - val_loss: 738.8243\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 460.3553 - val_loss: 395.3582\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 318.0094 - val_loss: 307.3297\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 265.9401 - val_loss: 268.9992\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 244.8293 - val_loss: 247.9612\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 237.3119 - val_loss: 240.0385\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 227.2088 - val_loss: 235.4490\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 214.9395 - val_loss: 218.6171\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.0011 - val_loss: 217.5649\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.3737 - val_loss: 224.9200\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.6382 - val_loss: 219.7342\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.4315 - val_loss: 201.2519\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.6010 - val_loss: 210.6775\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.9554 - val_loss: 200.2163\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.4419 - val_loss: 202.7696\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.8422 - val_loss: 207.8667\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.0352 - val_loss: 194.5253\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.4225 - val_loss: 192.8026\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.0469 - val_loss: 191.0932\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.5916 - val_loss: 190.9790\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.3563 - val_loss: 189.8349\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.1006 - val_loss: 188.8335\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.6341 - val_loss: 191.4304\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.6884 - val_loss: 193.7619\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.1945 - val_loss: 185.2731\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.1143 - val_loss: 194.2660\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.7938 - val_loss: 195.3368\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.8546 - val_loss: 181.9803\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.8923 - val_loss: 187.7162\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.2211 - val_loss: 178.5643\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.1751 - val_loss: 178.3501\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.3159 - val_loss: 176.1676\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.4213 - val_loss: 179.6745\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.8417 - val_loss: 165.4868\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.6443 - val_loss: 161.3436\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.5878 - val_loss: 163.9243\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.6899 - val_loss: 175.1290\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.6628 - val_loss: 157.8564\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.5141 - val_loss: 184.0975\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.1165 - val_loss: 161.5359\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.4146 - val_loss: 164.4463\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.4582 - val_loss: 160.2453\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.7748 - val_loss: 157.1296\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 143.8126 - val_loss: 158.1520\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.3452 - val_loss: 156.1866\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.4529 - val_loss: 155.6497\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.2686 - val_loss: 163.8182\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.8522 - val_loss: 156.6720\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.4095 - val_loss: 160.6325\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.9039 - val_loss: 154.5426\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 627.6975 - val_loss: 368.0836\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 294.6978 - val_loss: 293.4580\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 260.5569 - val_loss: 261.6233\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 238.0703 - val_loss: 268.3087\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 228.2310 - val_loss: 259.8340\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 214.1603 - val_loss: 226.0389\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.0873 - val_loss: 215.5864\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.3785 - val_loss: 223.5582\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.5089 - val_loss: 220.0459\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.0311 - val_loss: 195.8461\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.7958 - val_loss: 228.6083\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.4863 - val_loss: 229.5908\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.1285 - val_loss: 190.4850\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 187.2498 - val_loss: 219.1193\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.3426 - val_loss: 176.3145\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.8749 - val_loss: 174.3732\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.9732 - val_loss: 193.3480\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.3245 - val_loss: 172.5867\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.7473 - val_loss: 172.0696\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.0375 - val_loss: 176.1143\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.3853 - val_loss: 182.1487\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.6384 - val_loss: 169.7066\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 163.1804 - val_loss: 170.0297\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.7485 - val_loss: 187.3340\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.0014 - val_loss: 178.1407\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.2953 - val_loss: 165.9275\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.2481 - val_loss: 174.4929\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.0042 - val_loss: 168.4477\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.3627 - val_loss: 168.4261\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.5138 - val_loss: 194.0258\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.4593 - val_loss: 183.5069\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.7753 - val_loss: 182.5226\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.3493 - val_loss: 166.5932\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.3253 - val_loss: 191.5854\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.6055 - val_loss: 168.1316\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.5353 - val_loss: 167.2509\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.3468 - val_loss: 187.0881\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.9153 - val_loss: 168.4619\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.9801 - val_loss: 211.8013\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.1359 - val_loss: 169.6217\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.3584 - val_loss: 187.5169\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.3977 - val_loss: 177.7592\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.3466 - val_loss: 172.1575\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.5955 - val_loss: 165.6492\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.7197 - val_loss: 177.7592\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.4043 - val_loss: 168.0544\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.4789 - val_loss: 168.9981\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.6733 - val_loss: 172.5263\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8991 - val_loss: 176.5301\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.0601 - val_loss: 171.0275\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 58574.9688 - val_loss: 11628.3174\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4052.2717 - val_loss: 1831.3356\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1637.4291 - val_loss: 1449.8093\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1259.6930 - val_loss: 1197.8014\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1122.1479 - val_loss: 1078.1605\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1004.1348 - val_loss: 964.4880\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 893.6047 - val_loss: 852.5197\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 796.1469 - val_loss: 759.0155\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 712.8021 - val_loss: 675.0664\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 635.3621 - val_loss: 601.2596\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 567.6746 - val_loss: 539.6122\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 511.3018 - val_loss: 484.7536\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 460.9233 - val_loss: 439.7910\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 418.9674 - val_loss: 400.3810\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 383.7017 - val_loss: 363.9486\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 351.2841 - val_loss: 338.7834\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 327.6088 - val_loss: 313.7580\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 303.9354 - val_loss: 295.7872\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 285.8212 - val_loss: 285.5753\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 269.8458 - val_loss: 270.9806\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 257.6908 - val_loss: 255.9144\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 248.5624 - val_loss: 253.3969\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 237.3174 - val_loss: 243.6090\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 227.4609 - val_loss: 233.4452\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 219.0197 - val_loss: 231.4338\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.9759 - val_loss: 224.2736\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 206.5522 - val_loss: 216.0477\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.7494 - val_loss: 212.7416\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.5946 - val_loss: 210.9079\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.1218 - val_loss: 203.8225\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.4771 - val_loss: 202.6193\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.7553 - val_loss: 203.7237\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.6101 - val_loss: 195.6100\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.1030 - val_loss: 192.5669\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.2129 - val_loss: 194.6254\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.5754 - val_loss: 194.5570\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.6474 - val_loss: 188.5959\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.5237 - val_loss: 186.4351\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.0700 - val_loss: 187.7737\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.3632 - val_loss: 185.1821\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.1503 - val_loss: 184.7275\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.1989 - val_loss: 180.7137\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.0924 - val_loss: 179.6212\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.4595 - val_loss: 190.1736\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.8981 - val_loss: 177.7587\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.2277 - val_loss: 178.4892\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.2596 - val_loss: 184.1338\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.4016 - val_loss: 175.8034\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.6070 - val_loss: 179.0113\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.2924 - val_loss: 174.7767\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1199.6661 - val_loss: 478.5574\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 321.1673 - val_loss: 309.3190\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 272.6450 - val_loss: 249.0476\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 244.2281 - val_loss: 228.8690\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 224.9400 - val_loss: 217.8422\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 217.4827 - val_loss: 211.8166\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.8598 - val_loss: 206.5762\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.7103 - val_loss: 201.8769\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.1379 - val_loss: 196.8029\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.8269 - val_loss: 201.7113\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.6271 - val_loss: 193.9878\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.2967 - val_loss: 196.4933\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.4363 - val_loss: 180.7199\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.1861 - val_loss: 183.1223\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.5976 - val_loss: 176.5510\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.9166 - val_loss: 177.2699\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.0609 - val_loss: 191.5813\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.1887 - val_loss: 175.4969\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.1230 - val_loss: 173.3700\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.4006 - val_loss: 178.6735\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.7239 - val_loss: 171.8516\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.1229 - val_loss: 177.0255\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.9015 - val_loss: 177.1513\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.9915 - val_loss: 179.2903\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.5708 - val_loss: 174.3689\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.2711 - val_loss: 190.1958\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.5290 - val_loss: 191.4664\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.0182 - val_loss: 169.0384\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.7215 - val_loss: 165.7896\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.6167 - val_loss: 189.8083\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.8055 - val_loss: 167.6093\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.9209 - val_loss: 197.9621\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.5820 - val_loss: 197.6387\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.9332 - val_loss: 165.1839\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.9228 - val_loss: 182.1525\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.9786 - val_loss: 166.4968\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.6878 - val_loss: 166.8982\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.5020 - val_loss: 179.3785\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.7357 - val_loss: 180.3199\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.0458 - val_loss: 161.2461\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.5674 - val_loss: 169.1329\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.8056 - val_loss: 161.6625\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.4346 - val_loss: 165.9086\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.3794 - val_loss: 175.0570\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.2580 - val_loss: 184.0135\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.8759 - val_loss: 161.1075\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.5476 - val_loss: 158.9121\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.5784 - val_loss: 167.4146\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 153.3847 - val_loss: 163.1626\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.5670 - val_loss: 165.2432\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 9ms/step - loss: 67467.8203 - val_loss: 9159.4414\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2014.5686 - val_loss: 253.7209\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 408.5340 - val_loss: 269.8434\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 315.7804 - val_loss: 218.0356\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 287.0590 - val_loss: 201.2229\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 269.2314 - val_loss: 189.2227\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 256.0608 - val_loss: 179.9457\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 243.0326 - val_loss: 171.6324\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 231.3949 - val_loss: 164.7814\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 221.0095 - val_loss: 158.1043\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 213.0248 - val_loss: 153.8772\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.8999 - val_loss: 151.6746\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.9636 - val_loss: 149.1840\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.6517 - val_loss: 147.3234\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.7130 - val_loss: 147.9875\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.0390 - val_loss: 144.0004\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.6099 - val_loss: 142.7153\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.9781 - val_loss: 141.9331\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.1749 - val_loss: 141.9621\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.6342 - val_loss: 140.0900\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.7640 - val_loss: 139.7095\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.5247 - val_loss: 139.7598\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.1353 - val_loss: 138.6837\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.5678 - val_loss: 138.4192\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.5435 - val_loss: 138.7510\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.4003 - val_loss: 138.5958\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.9895 - val_loss: 137.5235\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.1077 - val_loss: 137.4574\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.2669 - val_loss: 137.0412\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.7276 - val_loss: 137.8369\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.8718 - val_loss: 138.0349\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.1004 - val_loss: 137.1198\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.5560 - val_loss: 136.7251\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.7432 - val_loss: 136.4938\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.1384 - val_loss: 135.9067\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.2815 - val_loss: 141.4785\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.0841 - val_loss: 136.5648\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.8569 - val_loss: 136.4599\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.2533 - val_loss: 134.5896\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.8827 - val_loss: 137.2798\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.6839 - val_loss: 134.4518\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 161.8331 - val_loss: 137.0452\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.9948 - val_loss: 137.5071\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 160.2019 - val_loss: 134.4160\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 159.0971 - val_loss: 133.6058\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.9659 - val_loss: 133.8501\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.8953 - val_loss: 133.2299\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.2915 - val_loss: 135.3283\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.1241 - val_loss: 134.5626\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.0507 - val_loss: 133.4122\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 6061.2559 - val_loss: 2532.2495\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1459.4893 - val_loss: 1164.3210\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 987.7484 - val_loss: 842.6581\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 764.0784 - val_loss: 638.1417\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 556.1221 - val_loss: 504.6040\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 431.8929 - val_loss: 389.7023\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 344.2556 - val_loss: 307.4000\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 289.0314 - val_loss: 270.7087\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 254.5832 - val_loss: 247.7277\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 241.2286 - val_loss: 218.8635\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 220.3242 - val_loss: 208.1816\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.0621 - val_loss: 201.3993\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.1867 - val_loss: 202.9743\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.8553 - val_loss: 191.7758\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.3548 - val_loss: 196.4630\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.5442 - val_loss: 185.5980\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.8872 - val_loss: 186.8094\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.7235 - val_loss: 190.9274\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.7368 - val_loss: 179.0966\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.0732 - val_loss: 176.0119\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.6056 - val_loss: 179.2011\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.6023 - val_loss: 180.2548\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.0217 - val_loss: 177.1786\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.2090 - val_loss: 171.4818\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.5297 - val_loss: 171.3148\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.2954 - val_loss: 169.6512\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.4984 - val_loss: 169.3591\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.3046 - val_loss: 174.9851\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.2727 - val_loss: 166.9842\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.6350 - val_loss: 165.8748\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.5178 - val_loss: 171.6065\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.2171 - val_loss: 166.2283\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.3416 - val_loss: 164.2540\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.2891 - val_loss: 164.9084\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.3148 - val_loss: 165.9640\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.7292 - val_loss: 165.8081\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.5921 - val_loss: 163.0031\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.5949 - val_loss: 170.3946\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.4670 - val_loss: 163.1427\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.4795 - val_loss: 162.6661\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.3118 - val_loss: 169.5558\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.1653 - val_loss: 167.4565\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.0172 - val_loss: 190.8906\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.5326 - val_loss: 162.1923\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.3008 - val_loss: 179.3216\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.9527 - val_loss: 190.4984\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.2326 - val_loss: 161.7974\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.1946 - val_loss: 172.1680\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.7921 - val_loss: 161.8177\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8238 - val_loss: 162.5032\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 10ms/step - loss: 12798.3916 - val_loss: 1747.2192\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1829.4912 - val_loss: 998.0098\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 980.3836 - val_loss: 755.9947\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 711.6126 - val_loss: 542.7784\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 460.6635 - val_loss: 327.2081\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 309.4286 - val_loss: 250.4254\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 240.8696 - val_loss: 216.3235\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 205.9537 - val_loss: 197.1112\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 186.1542 - val_loss: 188.6048\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 170.4902 - val_loss: 177.6511\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 165.2566 - val_loss: 192.6039\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 165.0839 - val_loss: 175.5213\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 159.8584 - val_loss: 176.3281\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 155.6079 - val_loss: 170.0407\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.8995 - val_loss: 167.1425\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.6398 - val_loss: 166.6271\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.5109 - val_loss: 166.8013\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 146.6832 - val_loss: 166.8767\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 147.1454 - val_loss: 165.1966\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 147.6534 - val_loss: 165.5157\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 152.1709 - val_loss: 196.9105\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 147.2935 - val_loss: 164.7666\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.8361 - val_loss: 164.9415\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 144.7646 - val_loss: 186.9641\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 154.5154 - val_loss: 185.7592\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 148.4713 - val_loss: 170.3618\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.7365 - val_loss: 164.2412\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.3437 - val_loss: 168.8238\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 145.7160 - val_loss: 167.0432\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.9384 - val_loss: 164.8150\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 145.8543 - val_loss: 164.7822\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.3549 - val_loss: 166.6570\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.4272 - val_loss: 164.8399\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.1596 - val_loss: 169.4623\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 143.4661 - val_loss: 166.9564\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.3307 - val_loss: 166.1159\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 149.8130 - val_loss: 167.8184\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.2336 - val_loss: 164.0369\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.4459 - val_loss: 164.2220\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.0240 - val_loss: 171.2929\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.2780 - val_loss: 163.8785\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.3262 - val_loss: 163.5963\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 145.4781 - val_loss: 164.4937\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.7314 - val_loss: 163.9257\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.4632 - val_loss: 172.0546\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.3661 - val_loss: 169.2373\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 145.0780 - val_loss: 167.8154\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.2888 - val_loss: 163.8691\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 143.2385 - val_loss: 163.3598\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.1258 - val_loss: 172.5776\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 10ms/step - loss: 551.0500 - val_loss: 331.6135\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 264.1467 - val_loss: 226.6411\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 206.7204 - val_loss: 183.1022\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 184.4129 - val_loss: 169.2146\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 174.7079 - val_loss: 162.9932\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.0818 - val_loss: 160.9079\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.9011 - val_loss: 161.8431\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.4997 - val_loss: 159.3160\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 168.0425 - val_loss: 159.9837\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.2059 - val_loss: 160.8426\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.1086 - val_loss: 156.1302\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.9550 - val_loss: 155.1215\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.7807 - val_loss: 151.5136\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 159.7607 - val_loss: 153.0434\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 154.8674 - val_loss: 155.9216\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 152.9386 - val_loss: 155.6563\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.8250 - val_loss: 149.5383\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.8892 - val_loss: 154.0860\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 152.8881 - val_loss: 151.8242\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.1590 - val_loss: 152.4929\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.7290 - val_loss: 153.2869\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.0993 - val_loss: 195.9262\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.0852 - val_loss: 149.3714\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 153.4152 - val_loss: 161.7832\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 162.0789 - val_loss: 152.7674\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 161.8421 - val_loss: 150.1128\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.3834 - val_loss: 165.9347\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 154.7388 - val_loss: 147.4978\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 151.3436 - val_loss: 147.1038\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.3316 - val_loss: 148.5745\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.0909 - val_loss: 147.5845\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.5044 - val_loss: 153.1853\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.7491 - val_loss: 148.2825\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 150.1314 - val_loss: 155.0226\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 152.8512 - val_loss: 148.7880\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 155.3955 - val_loss: 146.3769\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.8267 - val_loss: 150.7760\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.6163 - val_loss: 161.8076\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 151.7514 - val_loss: 146.4572\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.4158 - val_loss: 146.4865\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 147.4253 - val_loss: 153.3457\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.7682 - val_loss: 145.9282\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.2401 - val_loss: 146.0220\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.7621 - val_loss: 163.3401\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.5025 - val_loss: 145.3581\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 147.2538 - val_loss: 165.4511\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 149.2332 - val_loss: 145.6531\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.6212 - val_loss: 145.7282\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.7706 - val_loss: 148.4201\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.0112 - val_loss: 145.2284\n",
      "10/10 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 31070.6914 - val_loss: 3547.3696\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3807.8479 - val_loss: 1737.6288\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 1880.9312 - val_loss: 1417.0646\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1572.9933 - val_loss: 1305.9398\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1339.2094 - val_loss: 1074.8419\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1132.7223 - val_loss: 919.9628\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 951.7744 - val_loss: 781.4700\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 785.3103 - val_loss: 609.6196\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 653.7583 - val_loss: 501.4503\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 532.9603 - val_loss: 412.9137\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 436.5326 - val_loss: 357.7692\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 364.7313 - val_loss: 295.9779\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 308.0189 - val_loss: 270.8365\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 264.8890 - val_loss: 222.2135\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 234.9148 - val_loss: 208.2413\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 210.0488 - val_loss: 186.6459\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.1267 - val_loss: 178.6280\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.5688 - val_loss: 171.5226\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.4741 - val_loss: 166.3366\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 168.8615 - val_loss: 167.2690\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 167.8976 - val_loss: 162.5729\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.9455 - val_loss: 164.3969\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.6232 - val_loss: 161.2631\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.2739 - val_loss: 164.6562\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.5939 - val_loss: 169.8033\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.1323 - val_loss: 160.4780\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.6500 - val_loss: 161.6548\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.1991 - val_loss: 160.1499\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.2538 - val_loss: 159.8926\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.3017 - val_loss: 161.8600\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.6391 - val_loss: 163.3521\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.4612 - val_loss: 160.6335\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 156.7521 - val_loss: 161.2282\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 156.8392 - val_loss: 160.2720\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.4575 - val_loss: 162.2051\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.3166 - val_loss: 159.3438\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.0396 - val_loss: 161.4606\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 158.0092 - val_loss: 160.9836\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 159.0648 - val_loss: 159.1771\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.7861 - val_loss: 168.2140\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.5623 - val_loss: 160.3050\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.9586 - val_loss: 159.6071\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.0805 - val_loss: 161.6954\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.4061 - val_loss: 159.6257\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.9614 - val_loss: 159.6763\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 154.4063 - val_loss: 160.5945\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.1324 - val_loss: 164.1394\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.7409 - val_loss: 170.5486\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 164.7469 - val_loss: 159.5632\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.5196 - val_loss: 159.4252\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 11ms/step - loss: 1655.9011 - val_loss: 1117.4611\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 729.0449 - val_loss: 619.7574\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 469.2424 - val_loss: 382.2560\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 288.0233 - val_loss: 245.8820\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.5262 - val_loss: 196.3311\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.8104 - val_loss: 184.2085\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.7900 - val_loss: 172.1382\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 162.1818 - val_loss: 161.5501\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.7289 - val_loss: 163.8756\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.7645 - val_loss: 171.1495\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.0944 - val_loss: 198.7281\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.6654 - val_loss: 159.5491\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.1056 - val_loss: 158.2798\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.9767 - val_loss: 160.8528\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.9512 - val_loss: 154.9225\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.5771 - val_loss: 164.2846\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 152.1250 - val_loss: 159.0953\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 160.0717 - val_loss: 153.5828\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.7243 - val_loss: 175.9925\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.2380 - val_loss: 170.8313\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.4624 - val_loss: 170.6572\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.3630 - val_loss: 154.5675\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 150.5200 - val_loss: 152.8496\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.2753 - val_loss: 160.3552\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.9912 - val_loss: 151.9118\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 147.6563 - val_loss: 167.7592\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.1865 - val_loss: 153.9046\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.7811 - val_loss: 152.7675\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.0557 - val_loss: 167.1072\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.2610 - val_loss: 156.8737\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.9855 - val_loss: 163.7654\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.5539 - val_loss: 155.1371\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.0697 - val_loss: 163.4653\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.2660 - val_loss: 218.6107\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 156.7536 - val_loss: 160.3826\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 159.8217 - val_loss: 178.1979\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.4687 - val_loss: 157.2432\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.6209 - val_loss: 242.2641\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.1365 - val_loss: 169.7179\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0714 - val_loss: 154.6654\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.5841 - val_loss: 167.0637\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 151.6604 - val_loss: 188.5343\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.9526 - val_loss: 154.4710\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.5237 - val_loss: 163.8631\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 148.8374 - val_loss: 161.6488\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 166.4748 - val_loss: 152.8941\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 147.4719 - val_loss: 173.3658\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.5117 - val_loss: 154.8522\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.2770 - val_loss: 170.9431\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.1173 - val_loss: 153.0139\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 10ms/step - loss: 36774.5703 - val_loss: 3510.5679\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1505.7870 - val_loss: 1030.5054\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 898.3676 - val_loss: 832.7283\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 688.6995 - val_loss: 695.7549\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 568.4979 - val_loss: 628.2866\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 512.8358 - val_loss: 562.8720\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 465.9361 - val_loss: 512.2748\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 427.2159 - val_loss: 470.9023\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 390.5542 - val_loss: 427.9865\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 360.1439 - val_loss: 389.0549\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 330.5955 - val_loss: 355.0707\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 305.0863 - val_loss: 327.2794\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 284.3831 - val_loss: 301.9454\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 265.7505 - val_loss: 282.8009\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 249.4203 - val_loss: 264.4780\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 235.9516 - val_loss: 249.8269\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 224.1797 - val_loss: 235.2011\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 214.5682 - val_loss: 221.0630\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 205.3590 - val_loss: 213.8378\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 197.8387 - val_loss: 200.1495\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 191.6622 - val_loss: 193.2158\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 185.7930 - val_loss: 183.7576\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 184.4436 - val_loss: 184.9094\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 178.5082 - val_loss: 176.2994\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.5362 - val_loss: 169.7828\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 172.1395 - val_loss: 168.6468\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.7747 - val_loss: 161.9685\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.1992 - val_loss: 160.9057\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 167.3478 - val_loss: 161.4284\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.6969 - val_loss: 156.3313\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.8689 - val_loss: 160.0044\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 166.7203 - val_loss: 161.0218\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 163.5743 - val_loss: 152.2862\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 163.6903 - val_loss: 155.7402\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 163.8098 - val_loss: 150.2175\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 161.0831 - val_loss: 156.5043\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.9953 - val_loss: 149.1811\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.2449 - val_loss: 157.0760\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.2325 - val_loss: 148.1759\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 162.4962 - val_loss: 147.7361\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.5408 - val_loss: 158.9554\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.5499 - val_loss: 149.4904\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.9040 - val_loss: 147.5171\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.6134 - val_loss: 153.4167\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.6396 - val_loss: 148.8855\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 160.3777 - val_loss: 147.8024\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 160.4332 - val_loss: 151.1068\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 160.2992 - val_loss: 147.2383\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 160.4693 - val_loss: 147.7639\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.4177 - val_loss: 147.6689\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 88979.3672 - val_loss: 38857.0469\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 19404.8457 - val_loss: 5527.5918\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2345.8074 - val_loss: 718.4594\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 669.7963 - val_loss: 683.6937\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 615.2909 - val_loss: 608.9908\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 570.7502 - val_loss: 572.5983\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 546.0179 - val_loss: 555.5090\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 524.6966 - val_loss: 536.1652\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 505.6029 - val_loss: 516.4264\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 484.3518 - val_loss: 498.4546\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 464.2498 - val_loss: 480.5054\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 445.1033 - val_loss: 462.3504\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 427.3940 - val_loss: 443.7510\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 409.9547 - val_loss: 425.4667\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 392.8008 - val_loss: 407.4787\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 375.9751 - val_loss: 391.4764\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 361.5364 - val_loss: 378.2866\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 349.6567 - val_loss: 367.3059\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 339.3945 - val_loss: 355.6081\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 328.3460 - val_loss: 346.0668\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 318.1281 - val_loss: 337.7437\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 309.4185 - val_loss: 329.3808\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 301.5112 - val_loss: 321.9194\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 295.2755 - val_loss: 315.2550\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 287.5574 - val_loss: 307.6523\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 280.7493 - val_loss: 301.1582\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 274.2033 - val_loss: 293.3661\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 268.2422 - val_loss: 288.1352\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 264.2247 - val_loss: 281.8950\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 257.3508 - val_loss: 274.8720\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 252.2204 - val_loss: 269.3055\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 247.2268 - val_loss: 264.0642\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 241.9662 - val_loss: 256.1839\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 236.0113 - val_loss: 249.4323\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 230.2405 - val_loss: 242.6546\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 225.0693 - val_loss: 238.1167\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 220.8960 - val_loss: 232.5312\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 217.6342 - val_loss: 228.3431\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 214.0273 - val_loss: 224.5987\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 209.6084 - val_loss: 221.9844\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 206.9447 - val_loss: 216.6912\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.7198 - val_loss: 213.7313\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.3394 - val_loss: 211.2004\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.8418 - val_loss: 208.0591\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.2537 - val_loss: 217.0806\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.3862 - val_loss: 203.9750\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.5242 - val_loss: 201.9015\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 190.5345 - val_loss: 199.0423\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.9742 - val_loss: 199.3552\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.8099 - val_loss: 195.5552\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 9ms/step - loss: 56359.1133 - val_loss: 17293.3457\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7453.2295 - val_loss: 2499.6509\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 995.6031 - val_loss: 702.9811\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 547.1207 - val_loss: 649.3482\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 512.3138 - val_loss: 613.6894\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 473.6288 - val_loss: 574.8004\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 440.3138 - val_loss: 531.3019\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 410.8503 - val_loss: 492.1450\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 381.6176 - val_loss: 457.8863\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 355.4047 - val_loss: 422.7004\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 330.7080 - val_loss: 391.3745\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 308.8769 - val_loss: 364.9632\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 289.0365 - val_loss: 339.8012\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 272.2945 - val_loss: 320.3490\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 257.5742 - val_loss: 301.1698\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 244.4364 - val_loss: 282.5665\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 231.5311 - val_loss: 268.5226\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 221.7903 - val_loss: 255.7017\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.7906 - val_loss: 244.7708\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.7331 - val_loss: 235.2487\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.3261 - val_loss: 226.5623\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.7869 - val_loss: 219.1907\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.2673 - val_loss: 213.5776\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.4741 - val_loss: 208.9162\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.0947 - val_loss: 202.4654\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.8058 - val_loss: 199.1104\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.1602 - val_loss: 195.8038\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 175.1582 - val_loss: 192.3628\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.6410 - val_loss: 189.9450\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.5378 - val_loss: 188.3149\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.2941 - val_loss: 184.3357\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.9445 - val_loss: 184.8788\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.9476 - val_loss: 180.6570\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.0670 - val_loss: 181.3594\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.1539 - val_loss: 180.0735\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.2610 - val_loss: 177.7854\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.2428 - val_loss: 174.9998\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.0713 - val_loss: 173.8113\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.5524 - val_loss: 172.5807\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.5404 - val_loss: 172.6513\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.4221 - val_loss: 171.9524\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.1385 - val_loss: 170.5269\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.5612 - val_loss: 169.4550\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.2725 - val_loss: 169.9241\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.3831 - val_loss: 168.0157\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.8830 - val_loss: 167.9838\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.9077 - val_loss: 167.1536\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.1747 - val_loss: 166.4299\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.4838 - val_loss: 165.5093\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.0259 - val_loss: 168.7818\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1690.9097 - val_loss: 470.0266\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 472.6592 - val_loss: 354.9917\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 377.1571 - val_loss: 333.0129\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 334.3229 - val_loss: 287.7599\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 302.7174 - val_loss: 257.6134\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 278.1891 - val_loss: 237.9456\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 261.6884 - val_loss: 226.4029\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 243.3127 - val_loss: 211.6627\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 232.3599 - val_loss: 202.7346\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 219.4533 - val_loss: 205.3872\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.6144 - val_loss: 186.4486\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.2890 - val_loss: 179.9565\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.4718 - val_loss: 175.3315\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.8628 - val_loss: 181.3183\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.0216 - val_loss: 173.1038\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.3403 - val_loss: 171.7030\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.3791 - val_loss: 164.5655\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.9164 - val_loss: 163.5471\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.1173 - val_loss: 160.4619\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.7231 - val_loss: 165.3241\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.6669 - val_loss: 165.7184\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.4675 - val_loss: 180.0179\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.1230 - val_loss: 157.5910\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.0986 - val_loss: 182.7134\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.0244 - val_loss: 169.2493\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.6575 - val_loss: 179.5427\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.7592 - val_loss: 155.6408\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.0246 - val_loss: 157.4505\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.0378 - val_loss: 156.4365\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.5869 - val_loss: 152.3492\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.4893 - val_loss: 162.1929\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.3508 - val_loss: 165.0039\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.4427 - val_loss: 153.9689\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.5338 - val_loss: 153.2454\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.1124 - val_loss: 174.9139\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.4920 - val_loss: 150.3698\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.2353 - val_loss: 154.0504\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.6536 - val_loss: 148.6810\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.4442 - val_loss: 149.5049\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.4946 - val_loss: 158.6795\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.7570 - val_loss: 149.2759\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.7723 - val_loss: 148.8277\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.2975 - val_loss: 157.2213\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.7828 - val_loss: 149.1082\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.7819 - val_loss: 158.9638\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.9520 - val_loss: 150.1278\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.2632 - val_loss: 147.9530\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.3401 - val_loss: 151.6420\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.5790 - val_loss: 152.8094\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.7150 - val_loss: 147.3103\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 2087.1833 - val_loss: 919.1293\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 487.4040 - val_loss: 331.0275\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 302.3862 - val_loss: 266.7822\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 256.2414 - val_loss: 241.2055\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 233.9909 - val_loss: 242.7870\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 225.5312 - val_loss: 218.6547\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 220.1171 - val_loss: 205.4428\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.3406 - val_loss: 199.7679\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.4126 - val_loss: 197.8248\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.8439 - val_loss: 194.3830\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.6596 - val_loss: 194.6289\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.8300 - val_loss: 198.0617\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.8955 - val_loss: 186.8431\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.3013 - val_loss: 180.7732\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.3891 - val_loss: 189.6849\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.2612 - val_loss: 176.1121\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.6196 - val_loss: 183.6516\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.8164 - val_loss: 187.8118\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.7756 - val_loss: 173.9403\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.9898 - val_loss: 167.7498\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.0778 - val_loss: 167.4393\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.8229 - val_loss: 167.9716\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.0881 - val_loss: 164.4348\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.3229 - val_loss: 166.5592\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.8794 - val_loss: 163.0236\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.9360 - val_loss: 160.9558\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.5093 - val_loss: 162.4875\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.1725 - val_loss: 159.2342\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.6881 - val_loss: 158.3212\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.2773 - val_loss: 159.2258\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.9797 - val_loss: 158.6703\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.9232 - val_loss: 155.4310\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.5834 - val_loss: 157.6835\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.1066 - val_loss: 168.4240\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.7624 - val_loss: 155.0598\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.0372 - val_loss: 153.3313\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.7972 - val_loss: 154.2662\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.3097 - val_loss: 152.2690\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.1734 - val_loss: 152.7952\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8781 - val_loss: 149.8519\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.7579 - val_loss: 149.3566\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.4834 - val_loss: 152.7455\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.2483 - val_loss: 147.9348\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.1941 - val_loss: 159.1539\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.6894 - val_loss: 147.8528\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.8177 - val_loss: 146.3131\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.0751 - val_loss: 146.2256\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.3754 - val_loss: 147.6074\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.0078 - val_loss: 145.6717\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.9603 - val_loss: 145.3410\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 20773.2344 - val_loss: 585.8461\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1448.5239 - val_loss: 492.5850\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 492.6476 - val_loss: 367.5590\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 372.1200 - val_loss: 291.7141\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 299.4905 - val_loss: 251.1467\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 255.1016 - val_loss: 222.9159\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 230.9667 - val_loss: 211.5203\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 214.9645 - val_loss: 202.5504\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.0566 - val_loss: 192.5782\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.8689 - val_loss: 188.0996\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.3425 - val_loss: 189.2319\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.8336 - val_loss: 176.7323\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.4304 - val_loss: 177.0165\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.1757 - val_loss: 175.4759\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.5662 - val_loss: 188.6414\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.3351 - val_loss: 172.5749\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.1803 - val_loss: 163.0723\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 163.0355 - val_loss: 160.8327\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 161.5476 - val_loss: 160.6250\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.6442 - val_loss: 169.2229\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.0771 - val_loss: 156.4585\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8957 - val_loss: 155.6439\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.4017 - val_loss: 155.1155\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.0894 - val_loss: 154.7248\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4987 - val_loss: 160.2392\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.1774 - val_loss: 159.3791\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.4713 - val_loss: 153.8575\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.5417 - val_loss: 156.3411\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.6065 - val_loss: 153.3639\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.6193 - val_loss: 155.6997\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.1518 - val_loss: 155.6894\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.1688 - val_loss: 156.0979\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.8729 - val_loss: 155.8309\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.7350 - val_loss: 152.8348\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.2813 - val_loss: 152.6885\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.1922 - val_loss: 153.1288\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.0287 - val_loss: 158.9622\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.1171 - val_loss: 155.8212\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.7728 - val_loss: 153.0343\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.0408 - val_loss: 153.3232\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.4683 - val_loss: 152.2482\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 154.0934 - val_loss: 152.8961\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.1527 - val_loss: 152.8529\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.3642 - val_loss: 163.6180\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.2454 - val_loss: 156.2364\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.6936 - val_loss: 152.1480\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.7315 - val_loss: 160.6480\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8803 - val_loss: 152.5526\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.9831 - val_loss: 152.1769\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.5014 - val_loss: 158.2463\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 720.2551 - val_loss: 342.6743\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 301.0830 - val_loss: 284.7290\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 247.0966 - val_loss: 250.8182\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 220.2800 - val_loss: 225.5317\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.9282 - val_loss: 213.5525\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.0484 - val_loss: 194.2753\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.5316 - val_loss: 186.8767\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.4472 - val_loss: 181.6361\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.3580 - val_loss: 178.4109\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.6272 - val_loss: 176.0290\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.8191 - val_loss: 172.0578\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.5965 - val_loss: 170.6816\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.8982 - val_loss: 169.6898\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.8177 - val_loss: 168.1038\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.4926 - val_loss: 168.7999\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.3414 - val_loss: 165.7054\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.4007 - val_loss: 167.1196\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.7656 - val_loss: 168.7290\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.4507 - val_loss: 161.9902\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.8447 - val_loss: 166.0028\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.1227 - val_loss: 161.8570\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.3190 - val_loss: 165.6368\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.0916 - val_loss: 159.8809\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.8570 - val_loss: 158.6833\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.2119 - val_loss: 157.7841\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.2066 - val_loss: 159.0264\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.9067 - val_loss: 159.9771\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.0649 - val_loss: 157.6110\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.5443 - val_loss: 155.7516\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4381 - val_loss: 157.4604\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.8396 - val_loss: 160.9969\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.6294 - val_loss: 157.0811\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.9616 - val_loss: 152.5187\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.3890 - val_loss: 152.6558\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8359 - val_loss: 159.3084\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.4681 - val_loss: 155.5574\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.7210 - val_loss: 151.0492\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.2534 - val_loss: 153.4431\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.7962 - val_loss: 150.5304\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.5235 - val_loss: 149.0454\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.4504 - val_loss: 154.4379\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.3299 - val_loss: 150.7124\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.9669 - val_loss: 150.8362\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.1994 - val_loss: 151.9067\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4400 - val_loss: 152.0069\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.6110 - val_loss: 150.1716\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.9269 - val_loss: 153.4127\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.3045 - val_loss: 151.7888\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.9474 - val_loss: 151.8222\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.0083 - val_loss: 150.4043\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 741.0453 - val_loss: 400.8806\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 268.0143 - val_loss: 236.0279\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.5027 - val_loss: 192.0764\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.2501 - val_loss: 185.5335\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.6836 - val_loss: 183.5135\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4070 - val_loss: 181.9611\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.9521 - val_loss: 178.9549\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.3754 - val_loss: 177.1145\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.7078 - val_loss: 176.9225\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.6296 - val_loss: 177.1175\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.8265 - val_loss: 180.4955\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.0177 - val_loss: 172.8908\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.8175 - val_loss: 171.5705\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.1290 - val_loss: 173.8727\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.6309 - val_loss: 169.7414\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.6758 - val_loss: 173.9065\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.8693 - val_loss: 173.7035\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.3162 - val_loss: 169.4880\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.3844 - val_loss: 180.2628\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.8919 - val_loss: 168.9306\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.8423 - val_loss: 169.0796\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.9402 - val_loss: 167.8008\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.6221 - val_loss: 167.1643\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.2344 - val_loss: 167.8191\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.5729 - val_loss: 169.6234\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.6118 - val_loss: 166.0975\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.6713 - val_loss: 167.8699\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.4382 - val_loss: 167.4428\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.7730 - val_loss: 164.8015\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.4989 - val_loss: 166.1098\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.3437 - val_loss: 165.5979\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.7300 - val_loss: 170.3067\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.5946 - val_loss: 165.4230\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.9786 - val_loss: 185.1926\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.0494 - val_loss: 165.4273\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.2935 - val_loss: 164.9189\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.1898 - val_loss: 163.9363\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.1016 - val_loss: 165.2319\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.7756 - val_loss: 164.2058\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.2733 - val_loss: 165.7145\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.0318 - val_loss: 193.3525\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.0018 - val_loss: 168.2520\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.5950 - val_loss: 170.8244\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.0730 - val_loss: 162.6761\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.2213 - val_loss: 167.6314\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.2584 - val_loss: 166.7900\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.4767 - val_loss: 167.3533\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.6623 - val_loss: 167.5334\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.1002 - val_loss: 165.5495\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.5951 - val_loss: 166.7998\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 29288.1641 - val_loss: 1946.3744\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1208.3658 - val_loss: 406.2592\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 423.3437 - val_loss: 360.5992\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 321.9059 - val_loss: 294.1333\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 270.3929 - val_loss: 267.3409\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 240.6668 - val_loss: 242.4763\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 216.7309 - val_loss: 229.4364\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.3264 - val_loss: 217.8839\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.3525 - val_loss: 207.0110\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.6820 - val_loss: 208.1165\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.3578 - val_loss: 199.0636\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.6303 - val_loss: 197.7376\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.7268 - val_loss: 198.1761\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.0304 - val_loss: 201.6972\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.6674 - val_loss: 192.5775\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.5832 - val_loss: 188.3647\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.2887 - val_loss: 185.8815\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.4116 - val_loss: 184.3112\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.7555 - val_loss: 183.0753\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.8290 - val_loss: 186.6005\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.1280 - val_loss: 193.4713\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.6658 - val_loss: 179.0610\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.8105 - val_loss: 178.9391\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.2309 - val_loss: 178.0261\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.4071 - val_loss: 177.6566\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4750 - val_loss: 175.9248\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.2041 - val_loss: 199.3917\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.8178 - val_loss: 179.7160\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8383 - val_loss: 174.0037\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.6935 - val_loss: 174.6045\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.9673 - val_loss: 175.2860\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.3985 - val_loss: 181.3748\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.3740 - val_loss: 178.1775\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.2863 - val_loss: 171.5635\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.2917 - val_loss: 186.5076\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.2074 - val_loss: 172.8790\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.1535 - val_loss: 180.5256\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.6161 - val_loss: 174.5979\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.0029 - val_loss: 170.7054\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.9004 - val_loss: 171.2286\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.0537 - val_loss: 173.3115\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.8602 - val_loss: 170.3477\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.8143 - val_loss: 170.6914\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.0710 - val_loss: 172.4891\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8737 - val_loss: 170.5806\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.1610 - val_loss: 176.7291\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.5021 - val_loss: 169.5671\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.7918 - val_loss: 194.2701\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.6771 - val_loss: 174.7373\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.6874 - val_loss: 168.4073\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 313.4547 - val_loss: 292.4998\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.4209 - val_loss: 189.0067\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.1274 - val_loss: 198.7629\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.2481 - val_loss: 184.3454\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.7585 - val_loss: 178.5459\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.1712 - val_loss: 198.2212\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.9151 - val_loss: 179.9362\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.5046 - val_loss: 174.9492\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.9379 - val_loss: 185.8757\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.2916 - val_loss: 174.5982\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.8566 - val_loss: 168.5637\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 151.3194 - val_loss: 174.4048\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.0621 - val_loss: 167.7271\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.4029 - val_loss: 168.2267\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.9535 - val_loss: 176.0327\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.2419 - val_loss: 195.0806\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.2052 - val_loss: 196.7556\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.8830 - val_loss: 170.9346\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.9876 - val_loss: 168.6401\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.8963 - val_loss: 181.1560\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.1864 - val_loss: 181.4752\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.4940 - val_loss: 166.5741\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.0004 - val_loss: 172.2036\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.5877 - val_loss: 179.7997\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.0521 - val_loss: 180.7628\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.3980 - val_loss: 163.1100\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.0137 - val_loss: 164.2940\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.6029 - val_loss: 175.9499\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.5592 - val_loss: 164.3960\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.3286 - val_loss: 182.4913\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.1318 - val_loss: 179.9866\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.2557 - val_loss: 164.2498\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.6633 - val_loss: 168.1963\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.5152 - val_loss: 162.2921\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.7703 - val_loss: 172.4278\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.4287 - val_loss: 172.9370\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.4582 - val_loss: 166.2786\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.9779 - val_loss: 178.7448\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.6582 - val_loss: 196.9355\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.0890 - val_loss: 176.5021\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.9523 - val_loss: 179.8450\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.8574 - val_loss: 193.8927\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.4487 - val_loss: 185.8005\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.5930 - val_loss: 162.8183\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.9442 - val_loss: 163.5717\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.8067 - val_loss: 165.3605\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.2419 - val_loss: 182.8449\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.7036 - val_loss: 173.9688\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 140.4686 - val_loss: 167.7946\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.1771 - val_loss: 165.7422\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 26862.4297 - val_loss: 2340.8201\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2974.9900 - val_loss: 1364.0946\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 961.2001 - val_loss: 446.1024\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 386.8363 - val_loss: 309.3845\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 316.2384 - val_loss: 290.7570\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 297.7491 - val_loss: 276.9315\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 281.0659 - val_loss: 264.7156\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 269.0525 - val_loss: 254.3198\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 259.7870 - val_loss: 244.9158\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 251.6757 - val_loss: 237.2367\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 247.0498 - val_loss: 232.8952\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 241.1071 - val_loss: 228.0706\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 237.2872 - val_loss: 222.9374\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 232.4762 - val_loss: 219.5340\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 230.4006 - val_loss: 219.5782\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 228.3452 - val_loss: 219.8607\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 223.6424 - val_loss: 212.3712\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 221.9546 - val_loss: 207.5379\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 220.8602 - val_loss: 204.7885\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 220.1672 - val_loss: 203.2074\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 214.6848 - val_loss: 200.9688\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.4136 - val_loss: 198.9181\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.7702 - val_loss: 198.7249\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 208.4393 - val_loss: 200.2229\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.2932 - val_loss: 197.5911\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.6567 - val_loss: 195.1819\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.8331 - val_loss: 193.1948\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.2246 - val_loss: 189.8486\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.2123 - val_loss: 194.4376\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.0598 - val_loss: 188.7294\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 201.0722 - val_loss: 185.7707\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.6705 - val_loss: 184.9123\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.5943 - val_loss: 184.5369\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.3311 - val_loss: 183.5867\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.7155 - val_loss: 181.2675\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.6264 - val_loss: 179.9285\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.5005 - val_loss: 178.3976\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.2160 - val_loss: 176.9067\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.4088 - val_loss: 178.2547\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.0481 - val_loss: 181.6381\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.6854 - val_loss: 173.4805\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.3706 - val_loss: 173.3313\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.7532 - val_loss: 175.2964\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.6970 - val_loss: 172.7613\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.3357 - val_loss: 168.3872\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.6951 - val_loss: 178.6557\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.0562 - val_loss: 168.4402\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.6696 - val_loss: 166.9028\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.6940 - val_loss: 164.3573\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.4604 - val_loss: 164.6214\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1775.0271 - val_loss: 637.1020\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 436.4533 - val_loss: 255.1212\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 275.7879 - val_loss: 201.2930\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 229.3908 - val_loss: 221.8849\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.3472 - val_loss: 183.7393\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.8277 - val_loss: 172.1342\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.7422 - val_loss: 239.2923\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.7280 - val_loss: 187.9468\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.0891 - val_loss: 170.4124\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.7689 - val_loss: 160.6918\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.6694 - val_loss: 179.3530\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.7988 - val_loss: 184.5028\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.2505 - val_loss: 159.6441\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.6071 - val_loss: 160.5451\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.1295 - val_loss: 205.1822\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.9262 - val_loss: 164.1649\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.5857 - val_loss: 169.1675\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.8071 - val_loss: 163.8277\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.3967 - val_loss: 153.8118\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.6761 - val_loss: 164.2945\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.7819 - val_loss: 154.5025\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.2491 - val_loss: 154.4522\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.9903 - val_loss: 192.5082\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.7820 - val_loss: 167.7938\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.5071 - val_loss: 152.0389\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.1823 - val_loss: 148.1197\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.1764 - val_loss: 147.6165\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.9772 - val_loss: 146.4916\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.6049 - val_loss: 146.6987\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.2864 - val_loss: 149.5176\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.0623 - val_loss: 197.2690\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.8315 - val_loss: 185.5342\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.3723 - val_loss: 145.2110\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.1771 - val_loss: 157.7190\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.1206 - val_loss: 149.4493\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 155.4403 - val_loss: 146.1006\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 153.9074 - val_loss: 183.0964\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 175.0886 - val_loss: 147.2314\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.1313 - val_loss: 143.0614\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.8129 - val_loss: 169.3830\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.2972 - val_loss: 148.5762\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.8113 - val_loss: 144.7183\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.5197 - val_loss: 202.0330\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.9177 - val_loss: 144.0455\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8509 - val_loss: 149.2159\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.5319 - val_loss: 163.6304\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.5598 - val_loss: 146.6983\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.8914 - val_loss: 142.4497\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.3642 - val_loss: 142.9351\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.5525 - val_loss: 148.2087\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 5032.0923 - val_loss: 1731.7743\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 999.2679 - val_loss: 605.7678\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 638.0575 - val_loss: 500.0458\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 506.0575 - val_loss: 413.5903\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 407.1767 - val_loss: 350.1848\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 344.8637 - val_loss: 296.2722\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 305.7460 - val_loss: 268.3123\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 279.9966 - val_loss: 244.9959\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 258.8840 - val_loss: 227.5287\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 244.4366 - val_loss: 211.8604\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 230.8746 - val_loss: 200.1577\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 217.9688 - val_loss: 187.7309\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.3866 - val_loss: 179.6638\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.6563 - val_loss: 178.3041\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.7116 - val_loss: 165.5183\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.6171 - val_loss: 159.9533\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.2777 - val_loss: 159.1994\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.1226 - val_loss: 157.3246\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.6293 - val_loss: 150.6234\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.3597 - val_loss: 147.9417\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.9420 - val_loss: 146.1358\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.4921 - val_loss: 143.8126\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.9425 - val_loss: 142.1329\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.9201 - val_loss: 141.4045\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.2907 - val_loss: 141.7777\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.7202 - val_loss: 151.6735\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.7872 - val_loss: 138.6246\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.7963 - val_loss: 139.3754\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.0530 - val_loss: 138.6047\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.3247 - val_loss: 138.8004\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.0992 - val_loss: 137.0473\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.9408 - val_loss: 138.7340\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.3855 - val_loss: 151.0388\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.2073 - val_loss: 136.8080\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.8812 - val_loss: 136.2063\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.9780 - val_loss: 136.8969\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.0991 - val_loss: 140.6545\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.9230 - val_loss: 136.3595\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.6083 - val_loss: 137.1359\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.4998 - val_loss: 136.0310\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.8104 - val_loss: 136.7587\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.1827 - val_loss: 134.9173\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.0457 - val_loss: 136.3821\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.5706 - val_loss: 135.1690\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.0709 - val_loss: 141.1568\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.5837 - val_loss: 137.9523\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.3252 - val_loss: 134.7594\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.5437 - val_loss: 137.1716\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.9982 - val_loss: 135.0238\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.1051 - val_loss: 148.7547\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 2480.4509 - val_loss: 777.5908\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 463.1887 - val_loss: 277.2897\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 242.9106 - val_loss: 244.3824\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 224.3259 - val_loss: 221.4473\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.7945 - val_loss: 212.6243\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.5817 - val_loss: 205.2045\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 201.3028 - val_loss: 198.9187\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.0052 - val_loss: 194.1233\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.0079 - val_loss: 191.4573\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.3181 - val_loss: 185.1078\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.4920 - val_loss: 183.6895\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.4130 - val_loss: 179.0632\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.0624 - val_loss: 176.9114\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.5285 - val_loss: 174.7761\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.5023 - val_loss: 172.9825\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.6337 - val_loss: 171.7375\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.4904 - val_loss: 172.7415\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.6396 - val_loss: 168.5246\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.6706 - val_loss: 167.4301\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.1401 - val_loss: 167.2691\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.5143 - val_loss: 165.1531\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.2985 - val_loss: 164.1591\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.0295 - val_loss: 163.3699\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.3520 - val_loss: 167.3033\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.0967 - val_loss: 164.2007\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.0226 - val_loss: 161.3537\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.7317 - val_loss: 160.3294\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.1062 - val_loss: 160.2485\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.7824 - val_loss: 159.5430\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.8393 - val_loss: 158.6695\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.3798 - val_loss: 158.7924\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.0732 - val_loss: 158.4458\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.1211 - val_loss: 165.0751\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.9256 - val_loss: 157.8605\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.2571 - val_loss: 161.0186\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.0703 - val_loss: 159.6420\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.5533 - val_loss: 157.0201\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.4390 - val_loss: 165.8284\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.9530 - val_loss: 157.1762\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.0473 - val_loss: 157.0031\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8358 - val_loss: 157.9201\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0027 - val_loss: 156.5123\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.4421 - val_loss: 156.8989\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.9997 - val_loss: 156.2393\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.1101 - val_loss: 160.9224\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.3418 - val_loss: 155.7913\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.8507 - val_loss: 158.6971\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.7751 - val_loss: 169.1551\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.5708 - val_loss: 156.5202\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.3539 - val_loss: 160.1164\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 20ms/step - loss: 6055.1069 - val_loss: 1412.9205\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 621.4387 - val_loss: 351.8991\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 253.0104 - val_loss: 189.0182\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.7843 - val_loss: 179.2654\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.3513 - val_loss: 174.5273\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.1153 - val_loss: 177.3106\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.5968 - val_loss: 172.1232\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.5098 - val_loss: 168.4307\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.0330 - val_loss: 167.1119\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.5441 - val_loss: 167.4711\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.2816 - val_loss: 164.7689\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.2032 - val_loss: 175.4640\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.7553 - val_loss: 164.8150\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.8866 - val_loss: 162.8289\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.7191 - val_loss: 168.7161\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.3074 - val_loss: 160.9376\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.3110 - val_loss: 160.8819\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.1894 - val_loss: 158.5985\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 174.3162 - val_loss: 160.0060\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.3724 - val_loss: 157.7344\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.2672 - val_loss: 156.5434\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.5454 - val_loss: 159.7223\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.1614 - val_loss: 154.1822\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.8240 - val_loss: 159.1753\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.1129 - val_loss: 152.9915\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.2113 - val_loss: 161.7902\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.1648 - val_loss: 152.6610\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.2379 - val_loss: 151.7922\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.7726 - val_loss: 152.7828\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.4363 - val_loss: 150.8483\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.2982 - val_loss: 151.6409\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.9998 - val_loss: 149.8308\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.2550 - val_loss: 149.0525\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.5361 - val_loss: 150.9729\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.8271 - val_loss: 149.6689\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 159.2588 - val_loss: 153.8870\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.8658 - val_loss: 150.4589\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.7692 - val_loss: 148.9248\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.4734 - val_loss: 149.1407\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.8619 - val_loss: 147.9703\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.8263 - val_loss: 147.8886\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.1663 - val_loss: 147.9145\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.1919 - val_loss: 148.9110\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.6098 - val_loss: 147.7795\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.9631 - val_loss: 152.7193\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.4198 - val_loss: 148.4965\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.2583 - val_loss: 147.9614\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.7452 - val_loss: 147.9196\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.2640 - val_loss: 147.0681\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.1692 - val_loss: 148.2366\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 609.6362 - val_loss: 236.1178\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 213.1716 - val_loss: 185.3273\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.2656 - val_loss: 177.6443\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.5237 - val_loss: 168.1972\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.8480 - val_loss: 166.2346\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.8914 - val_loss: 162.0528\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.4814 - val_loss: 161.3112\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.2710 - val_loss: 157.4957\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.0591 - val_loss: 160.4148\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 161.0078 - val_loss: 157.7296\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.0832 - val_loss: 159.1466\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.1987 - val_loss: 160.0946\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 157.9687 - val_loss: 155.3848\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.7895 - val_loss: 156.6175\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.2209 - val_loss: 157.5157\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.2577 - val_loss: 152.8374\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.7554 - val_loss: 152.9522\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.1591 - val_loss: 152.9222\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.6118 - val_loss: 153.0679\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.0606 - val_loss: 155.1800\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8248 - val_loss: 163.2004\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.5126 - val_loss: 152.8378\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.7168 - val_loss: 154.1763\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.1842 - val_loss: 158.0872\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.3214 - val_loss: 154.0248\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.8457 - val_loss: 161.3889\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.3418 - val_loss: 151.8335\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.3756 - val_loss: 151.3105\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.6350 - val_loss: 155.7751\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.4748 - val_loss: 153.4240\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.9930 - val_loss: 159.5640\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.1442 - val_loss: 152.0965\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.2284 - val_loss: 156.7868\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.6960 - val_loss: 157.0401\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.3722 - val_loss: 150.0968\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.5125 - val_loss: 152.2054\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.0000 - val_loss: 174.6140\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.7526 - val_loss: 149.8055\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.2190 - val_loss: 149.4005\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.9954 - val_loss: 157.6916\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.3656 - val_loss: 150.3563\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.2911 - val_loss: 148.8938\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.4790 - val_loss: 163.7625\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.5159 - val_loss: 147.9581\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.8652 - val_loss: 148.5335\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.0106 - val_loss: 151.0648\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.0883 - val_loss: 147.9909\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.5461 - val_loss: 147.0914\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.5341 - val_loss: 146.9169\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0587 - val_loss: 148.5443\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 2830.5923 - val_loss: 624.3091\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 598.3644 - val_loss: 425.5911\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 431.8687 - val_loss: 339.7489\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 355.8283 - val_loss: 281.0321\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 303.3412 - val_loss: 254.2337\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 272.7360 - val_loss: 228.6432\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 248.9063 - val_loss: 205.2216\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 225.6732 - val_loss: 191.9954\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 210.7124 - val_loss: 188.0041\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.1474 - val_loss: 171.3876\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.9665 - val_loss: 164.5882\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.0680 - val_loss: 169.2264\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.1708 - val_loss: 164.9031\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.9797 - val_loss: 156.2911\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.0726 - val_loss: 160.5469\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.9882 - val_loss: 178.9781\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.8174 - val_loss: 148.2825\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.3455 - val_loss: 147.7703\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.7945 - val_loss: 151.5213\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.4261 - val_loss: 151.4194\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.5433 - val_loss: 147.6837\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.0930 - val_loss: 146.4923\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.1329 - val_loss: 148.3158\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.4340 - val_loss: 146.5175\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.6668 - val_loss: 149.9886\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.5703 - val_loss: 141.2884\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.5275 - val_loss: 142.4829\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.3699 - val_loss: 140.8161\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.8407 - val_loss: 140.3176\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.8084 - val_loss: 146.4942\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.1711 - val_loss: 177.6725\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.7510 - val_loss: 139.6961\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.6713 - val_loss: 138.1233\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.0903 - val_loss: 139.2033\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.9340 - val_loss: 146.0120\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.5809 - val_loss: 150.4947\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.2511 - val_loss: 169.4110\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.2605 - val_loss: 146.0200\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.3652 - val_loss: 136.7171\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.7314 - val_loss: 139.7618\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.4787 - val_loss: 153.7360\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.3703 - val_loss: 158.9525\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.2217 - val_loss: 137.2363\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.5136 - val_loss: 153.3904\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8008 - val_loss: 142.2925\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.6701 - val_loss: 137.4395\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.7735 - val_loss: 136.8887\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.9522 - val_loss: 135.7188\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.2311 - val_loss: 159.2911\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.3343 - val_loss: 134.6878\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 4357.9814 - val_loss: 1030.9170\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 780.5071 - val_loss: 646.8789\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 491.9619 - val_loss: 425.4068\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 344.7040 - val_loss: 301.8534\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 263.7980 - val_loss: 231.8470\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 219.6733 - val_loss: 193.5274\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.4494 - val_loss: 173.3322\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.2287 - val_loss: 159.9315\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.0157 - val_loss: 161.3378\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.6597 - val_loss: 152.1076\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.3220 - val_loss: 161.0659\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.7940 - val_loss: 150.2696\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.1153 - val_loss: 147.3961\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.4528 - val_loss: 146.9149\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.8132 - val_loss: 144.9377\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.4717 - val_loss: 144.0434\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.5626 - val_loss: 151.0105\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.1458 - val_loss: 143.0816\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.4223 - val_loss: 146.4843\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.8865 - val_loss: 147.8939\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.9651 - val_loss: 142.9847\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.7961 - val_loss: 141.9219\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.8037 - val_loss: 142.0904\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.6340 - val_loss: 141.8161\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.2995 - val_loss: 141.6613\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.2256 - val_loss: 144.2911\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.8730 - val_loss: 154.6856\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.7089 - val_loss: 153.3414\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.0302 - val_loss: 144.9530\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.6075 - val_loss: 140.1973\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.4813 - val_loss: 144.3352\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.6587 - val_loss: 140.4712\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.8565 - val_loss: 140.2467\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.5168 - val_loss: 141.2581\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.6834 - val_loss: 148.1217\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.8845 - val_loss: 142.2024\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.1861 - val_loss: 139.4791\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.0926 - val_loss: 139.8784\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.6694 - val_loss: 163.0692\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.1484 - val_loss: 141.6071\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.0762 - val_loss: 150.7027\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.5830 - val_loss: 139.5732\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.3009 - val_loss: 139.1212\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.6237 - val_loss: 140.3340\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.3779 - val_loss: 154.8383\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.9628 - val_loss: 147.4382\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.7676 - val_loss: 148.5488\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.4284 - val_loss: 141.2748\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.0488 - val_loss: 147.5272\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.8476 - val_loss: 152.0272\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 18148.9824 - val_loss: 1523.2712\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 513.7513 - val_loss: 429.6978\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 383.2594 - val_loss: 302.4142\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 283.9375 - val_loss: 293.2959\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 276.4445 - val_loss: 284.6510\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 267.6589 - val_loss: 278.5822\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 259.4791 - val_loss: 273.6630\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 252.8690 - val_loss: 268.9319\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 247.4494 - val_loss: 263.6174\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 239.8268 - val_loss: 258.6727\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 236.0946 - val_loss: 254.2798\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 228.9535 - val_loss: 249.5264\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 225.4552 - val_loss: 245.7063\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 221.3359 - val_loss: 242.2097\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 217.4935 - val_loss: 238.9552\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.5406 - val_loss: 236.0259\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 208.9344 - val_loss: 232.5625\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 205.6546 - val_loss: 230.2007\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.7103 - val_loss: 228.1778\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 202.9643 - val_loss: 228.8764\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 198.2941 - val_loss: 224.3093\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 195.4885 - val_loss: 222.7204\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.5254 - val_loss: 221.9954\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.9145 - val_loss: 219.7650\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.1948 - val_loss: 219.1821\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.8319 - val_loss: 219.9920\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.6299 - val_loss: 215.1183\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.8103 - val_loss: 215.0237\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.6272 - val_loss: 212.6695\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 184.7113 - val_loss: 214.2137\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.1440 - val_loss: 210.2827\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.0922 - val_loss: 213.7976\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.7693 - val_loss: 208.7556\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.3544 - val_loss: 206.7178\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.4617 - val_loss: 208.9275\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.9041 - val_loss: 204.7390\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.4482 - val_loss: 205.2902\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.0178 - val_loss: 205.2754\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.7227 - val_loss: 202.1260\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.7039 - val_loss: 204.0550\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.6682 - val_loss: 200.1410\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.5776 - val_loss: 201.1856\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.9970 - val_loss: 199.2663\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.4931 - val_loss: 202.4713\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.4774 - val_loss: 198.0785\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.6725 - val_loss: 195.2060\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 166.4393 - val_loss: 196.8392\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.7856 - val_loss: 198.1320\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.0567 - val_loss: 195.5471\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.7512 - val_loss: 192.0582\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 2254.7861 - val_loss: 1125.4913\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 859.8016 - val_loss: 510.3420\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 398.4776 - val_loss: 328.7614\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 276.7606 - val_loss: 287.8888\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 232.0891 - val_loss: 261.5638\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.2877 - val_loss: 239.2072\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.8611 - val_loss: 220.5394\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.6721 - val_loss: 205.0709\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.3690 - val_loss: 202.6648\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.6241 - val_loss: 217.0813\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.4325 - val_loss: 189.2052\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.5377 - val_loss: 186.1614\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.9773 - val_loss: 183.1900\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.6825 - val_loss: 206.8003\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.5748 - val_loss: 182.3693\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 160.5565 - val_loss: 177.6705\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.4613 - val_loss: 190.1591\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.4210 - val_loss: 189.0871\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.9294 - val_loss: 177.9100\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.7773 - val_loss: 179.1927\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.3766 - val_loss: 179.0963\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.5549 - val_loss: 175.0943\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.6083 - val_loss: 188.0801\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.1377 - val_loss: 172.7608\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.5460 - val_loss: 174.8153\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.1888 - val_loss: 172.3704\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.4091 - val_loss: 188.5632\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.5151 - val_loss: 171.2006\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.4237 - val_loss: 171.0562\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.9616 - val_loss: 171.5564\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 149.5834 - val_loss: 173.8270\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.8832 - val_loss: 181.2439\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.6190 - val_loss: 212.0974\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.8499 - val_loss: 182.8058\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.9541 - val_loss: 175.1069\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.0897 - val_loss: 185.3201\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.0992 - val_loss: 174.7979\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.0665 - val_loss: 179.3995\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.4054 - val_loss: 176.5050\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.4004 - val_loss: 196.4155\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.9528 - val_loss: 177.3392\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.4743 - val_loss: 191.5835\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.7967 - val_loss: 191.5810\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.8672 - val_loss: 207.4309\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.3389 - val_loss: 175.9150\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.7257 - val_loss: 192.4919\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.2012 - val_loss: 183.9562\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.1928 - val_loss: 175.3945\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.7075 - val_loss: 170.2713\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.6537 - val_loss: 193.7563\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 29895.0117 - val_loss: 2482.8179\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2204.7141 - val_loss: 847.3813\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 803.0437 - val_loss: 572.3634\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 517.1603 - val_loss: 429.3663\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 394.0826 - val_loss: 351.4558\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 324.2993 - val_loss: 300.5054\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 287.5486 - val_loss: 278.1687\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 269.5900 - val_loss: 263.5011\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 255.7354 - val_loss: 252.6020\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 245.6659 - val_loss: 248.6826\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 240.9927 - val_loss: 243.5531\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 234.6785 - val_loss: 237.3428\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 225.3602 - val_loss: 225.9552\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 218.1754 - val_loss: 224.3161\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 214.4520 - val_loss: 215.8711\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.4182 - val_loss: 216.5767\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.8116 - val_loss: 205.4262\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.9035 - val_loss: 196.6309\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.1107 - val_loss: 197.8462\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.6651 - val_loss: 190.3228\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.1586 - val_loss: 189.3713\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.8316 - val_loss: 185.8936\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.0079 - val_loss: 184.6138\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.7188 - val_loss: 184.5230\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.1796 - val_loss: 187.7414\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.3983 - val_loss: 186.6483\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.3317 - val_loss: 182.7677\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.4120 - val_loss: 183.7480\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.8886 - val_loss: 183.0483\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.8681 - val_loss: 182.5253\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.4232 - val_loss: 185.3381\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.6363 - val_loss: 182.9034\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.0204 - val_loss: 183.2045\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.9474 - val_loss: 181.7288\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.3566 - val_loss: 182.4543\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.7342 - val_loss: 179.5920\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.0324 - val_loss: 190.0368\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.8392 - val_loss: 179.1824\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.8845 - val_loss: 178.3871\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.0945 - val_loss: 193.2885\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.5711 - val_loss: 177.7223\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.7017 - val_loss: 182.2057\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.1615 - val_loss: 176.9454\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.2264 - val_loss: 175.7507\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.7556 - val_loss: 184.0950\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.6187 - val_loss: 174.5101\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.9671 - val_loss: 179.9425\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.7071 - val_loss: 178.8223\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.0064 - val_loss: 172.5219\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.6470 - val_loss: 171.9753\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 88946.3594 - val_loss: 27774.5508\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 10505.9375 - val_loss: 1008.0134\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 406.8296 - val_loss: 413.4315\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 346.4699 - val_loss: 305.1910\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 273.8864 - val_loss: 286.3732\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 270.1602 - val_loss: 282.9660\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 267.0501 - val_loss: 280.0421\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 262.1207 - val_loss: 275.8250\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 258.0347 - val_loss: 272.5727\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 254.6702 - val_loss: 269.5385\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 250.6714 - val_loss: 265.6358\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 246.8722 - val_loss: 262.6381\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 243.6844 - val_loss: 259.5965\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 240.1111 - val_loss: 256.8709\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 237.1110 - val_loss: 253.8489\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 233.7392 - val_loss: 250.7996\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 230.8374 - val_loss: 248.0227\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 228.0538 - val_loss: 245.3164\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 225.5722 - val_loss: 242.7680\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 223.7020 - val_loss: 240.2113\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 220.3142 - val_loss: 239.2847\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 218.4534 - val_loss: 235.5829\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 216.0350 - val_loss: 234.1287\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.2834 - val_loss: 231.2860\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.5787 - val_loss: 228.8803\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.2421 - val_loss: 226.6840\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 206.6957 - val_loss: 224.6912\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.9876 - val_loss: 222.6956\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.4236 - val_loss: 221.1019\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 201.5527 - val_loss: 218.8293\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.1037 - val_loss: 217.0038\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.6731 - val_loss: 215.9893\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.0864 - val_loss: 213.7826\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.0958 - val_loss: 212.5037\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.1598 - val_loss: 210.5986\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.8851 - val_loss: 209.2325\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.3249 - val_loss: 207.7679\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.3167 - val_loss: 206.6695\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.1595 - val_loss: 206.0092\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.2187 - val_loss: 203.7422\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.8330 - val_loss: 202.4909\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.7555 - val_loss: 201.4980\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.8651 - val_loss: 200.3126\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.8290 - val_loss: 199.3587\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.1674 - val_loss: 198.1514\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.0221 - val_loss: 197.5574\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.2154 - val_loss: 201.7393\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.9854 - val_loss: 195.4798\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.3997 - val_loss: 195.1705\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.6576 - val_loss: 192.7896\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 20623.1035 - val_loss: 6882.5737\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2071.8752 - val_loss: 1257.2698\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 870.4661 - val_loss: 758.2195\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 613.9297 - val_loss: 605.4630\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 521.1111 - val_loss: 535.7955\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 463.2828 - val_loss: 477.9606\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 419.0672 - val_loss: 426.5941\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 381.9608 - val_loss: 397.0270\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 350.4210 - val_loss: 362.1515\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 324.3992 - val_loss: 341.9577\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 312.0530 - val_loss: 337.3347\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 288.6878 - val_loss: 301.2052\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 273.8741 - val_loss: 293.0616\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 261.6458 - val_loss: 275.5918\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 251.5995 - val_loss: 261.9630\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 245.1722 - val_loss: 251.7748\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 235.0073 - val_loss: 246.8415\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 224.5378 - val_loss: 237.3831\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 218.3597 - val_loss: 234.4907\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.8145 - val_loss: 218.5331\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.3389 - val_loss: 213.1045\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.4098 - val_loss: 216.4851\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.1839 - val_loss: 200.3260\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.2090 - val_loss: 196.1896\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.9773 - val_loss: 208.9261\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.4119 - val_loss: 186.3936\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.3397 - val_loss: 185.4666\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.2279 - val_loss: 181.4642\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.9247 - val_loss: 178.9799\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.1830 - val_loss: 182.7622\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.2495 - val_loss: 171.2803\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.4090 - val_loss: 170.4426\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.1511 - val_loss: 167.2627\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.5277 - val_loss: 168.2864\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.0165 - val_loss: 163.9485\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.7164 - val_loss: 163.1509\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.6802 - val_loss: 161.9949\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.4438 - val_loss: 161.9000\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.0673 - val_loss: 159.7949\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.4305 - val_loss: 160.5641\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.7063 - val_loss: 159.0875\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.1302 - val_loss: 158.2493\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.4225 - val_loss: 159.1395\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 158.1072 - val_loss: 160.9367\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.7908 - val_loss: 157.2421\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.3278 - val_loss: 159.5159\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.5225 - val_loss: 156.9314\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.2755 - val_loss: 156.3921\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.9173 - val_loss: 157.4041\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.3869 - val_loss: 156.8133\n",
      "10/10 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "#The code\n",
    "mse_values = []\n",
    "for i in range(50):\n",
    "    #The train test split:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3) \n",
    "    #Producing the model:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape=(X.shape[1],), activation='relu'))  # Input layer with 32 neurons\n",
    "    model.add(Dense(10, activation='relu'))  # Hidden layer with 16 neurons\n",
    "    model.add(Dense(1, activation='linear'))  \n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.001))\n",
    "    model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a58e71fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average MSE over 50 runs: 162.59484383586286\n",
      "\n",
      "Average MSE standard deviations over 50 runs: 14.605409994987946\n"
     ]
    }
   ],
   "source": [
    "average_mse = np.mean(mse_values)\n",
    "std_dev_mse=np.std(mse_values)\n",
    "print(f\"\\nAverage MSE over 50 runs: {average_mse}\")\n",
    "print(f\"\\nAverage MSE standard deviations over 50 runs: {std_dev_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f381f4",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "B. Normalize the data (5 marks) \n",
    "\n",
    "Repeat Part A but use a normalized version of the data. Recall that one way to normalize the data is by subtracting the mean from the individual predictors and dividing by the standard deviation.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step A?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61c791d8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1520.2141 - val_loss: 1646.3083\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1484.9877 - val_loss: 1604.7654\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1445.0518 - val_loss: 1556.9451\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1396.2487 - val_loss: 1492.5129\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1330.1578 - val_loss: 1409.0527\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1245.4805 - val_loss: 1300.3020\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1139.2109 - val_loss: 1166.7953\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1011.3137 - val_loss: 1013.6095\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 867.7192 - val_loss: 844.7868\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 714.7151 - val_loss: 675.7783\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 569.3011 - val_loss: 519.9985\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 441.3736 - val_loss: 397.2555\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 345.5872 - val_loss: 311.2415\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 282.8284 - val_loss: 260.7828\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 247.5150 - val_loss: 235.5368\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 228.4471 - val_loss: 224.2078\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 218.8316 - val_loss: 218.4625\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.7714 - val_loss: 213.6203\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.0145 - val_loss: 210.9661\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.3026 - val_loss: 207.8799\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 201.0990 - val_loss: 205.9397\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.0884 - val_loss: 204.5387\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.0436 - val_loss: 202.3362\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.9608 - val_loss: 200.8884\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.1252 - val_loss: 199.6176\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.3199 - val_loss: 197.8469\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.6444 - val_loss: 197.0829\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.9886 - val_loss: 195.5184\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.6132 - val_loss: 194.1954\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.4047 - val_loss: 193.3256\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.2218 - val_loss: 192.1491\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.1506 - val_loss: 191.3104\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.1154 - val_loss: 190.6688\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.9106 - val_loss: 189.2287\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.8063 - val_loss: 188.1436\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.2734 - val_loss: 186.4947\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.9377 - val_loss: 185.6049\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.9722 - val_loss: 184.1163\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.8257 - val_loss: 183.6571\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.0154 - val_loss: 182.8745\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.0174 - val_loss: 182.4394\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.2101 - val_loss: 181.1140\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.1119 - val_loss: 180.3103\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.3179 - val_loss: 179.4448\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.3171 - val_loss: 178.8171\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.0493 - val_loss: 178.3372\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.1438 - val_loss: 177.4202\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.7522 - val_loss: 176.8149\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.3167 - val_loss: 175.7719\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.8358 - val_loss: 175.0572\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 20ms/step - loss: 1600.5669 - val_loss: 1457.8494\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1563.8438 - val_loss: 1427.5189\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1528.2620 - val_loss: 1393.2644\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1483.2980 - val_loss: 1347.1406\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1420.3247 - val_loss: 1280.9366\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1332.8225 - val_loss: 1190.3120\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1217.0775 - val_loss: 1077.6000\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1075.2268 - val_loss: 942.9825\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 915.5831 - val_loss: 791.3741\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 746.2617 - val_loss: 640.4169\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 588.9515 - val_loss: 501.0528\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 455.0056 - val_loss: 389.5692\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 357.7239 - val_loss: 306.8851\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 294.2923 - val_loss: 255.2843\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 258.5928 - val_loss: 223.4843\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 238.0495 - val_loss: 206.0227\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 227.3932 - val_loss: 195.1874\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 220.6192 - val_loss: 188.4914\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 216.3243 - val_loss: 184.0282\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 211.8129 - val_loss: 180.5310\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.4228 - val_loss: 176.7929\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.2615 - val_loss: 175.4496\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.7601 - val_loss: 173.8385\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.3187 - val_loss: 171.9323\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.1049 - val_loss: 170.2668\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.2337 - val_loss: 168.7264\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.2383 - val_loss: 167.6204\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.3984 - val_loss: 166.4592\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.8530 - val_loss: 165.3100\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.4013 - val_loss: 164.0823\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.0261 - val_loss: 163.5694\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.6206 - val_loss: 162.4671\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.3936 - val_loss: 161.4613\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.2347 - val_loss: 161.2326\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.0577 - val_loss: 160.3712\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 182.1855 - val_loss: 159.7163\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.1205 - val_loss: 158.5688\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 180.1935 - val_loss: 158.1573\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.2084 - val_loss: 158.0708\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.2023 - val_loss: 156.9251\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 177.1038 - val_loss: 156.8955\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.2502 - val_loss: 156.1380\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.2392 - val_loss: 155.3260\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.5749 - val_loss: 155.3642\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.4671 - val_loss: 154.1546\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.9604 - val_loss: 152.9711\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.9155 - val_loss: 153.1838\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.2291 - val_loss: 152.3240\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.4246 - val_loss: 152.2641\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.8262 - val_loss: 151.6450\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1569.3372 - val_loss: 1595.4237\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1532.8986 - val_loss: 1560.3108\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1498.1278 - val_loss: 1524.2611\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1459.2999 - val_loss: 1480.5546\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1410.2140 - val_loss: 1423.1288\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1343.7660 - val_loss: 1346.3850\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1256.2832 - val_loss: 1243.0565\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1138.9792 - val_loss: 1110.0074\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 994.0293 - val_loss: 947.8264\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 826.9807 - val_loss: 772.5078\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 654.3517 - val_loss: 598.3412\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 493.8167 - val_loss: 449.3260\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 369.1906 - val_loss: 340.5657\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 285.3765 - val_loss: 277.3646\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 241.6160 - val_loss: 245.5700\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 221.9488 - val_loss: 232.3575\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 214.0209 - val_loss: 224.2256\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.5664 - val_loss: 219.9413\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.7707 - val_loss: 216.2402\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.7121 - val_loss: 213.0953\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.9117 - val_loss: 209.6021\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.8411 - val_loss: 206.8874\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.8231 - val_loss: 204.7647\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.6500 - val_loss: 202.0598\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.8062 - val_loss: 199.7562\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.0495 - val_loss: 197.7975\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.0043 - val_loss: 195.3819\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.2369 - val_loss: 194.8507\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.8286 - val_loss: 192.7074\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.4605 - val_loss: 190.8611\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.2810 - val_loss: 189.2643\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.2971 - val_loss: 188.2737\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 180.8160 - val_loss: 186.6243\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.6539 - val_loss: 185.8410\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.7899 - val_loss: 184.3422\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.7010 - val_loss: 183.4579\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.0791 - val_loss: 182.1011\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.0678 - val_loss: 181.3835\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.1396 - val_loss: 180.3002\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.3282 - val_loss: 179.3318\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.4010 - val_loss: 178.0737\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.5170 - val_loss: 177.2092\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.9117 - val_loss: 176.3724\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.1146 - val_loss: 175.6968\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.4750 - val_loss: 174.9909\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.6777 - val_loss: 173.4804\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.0335 - val_loss: 173.0548\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.5583 - val_loss: 172.5495\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.8681 - val_loss: 171.2809\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.0604 - val_loss: 170.9201\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1526.2722 - val_loss: 1540.6566\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1469.7334 - val_loss: 1485.9907\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1408.6633 - val_loss: 1420.1079\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1333.2974 - val_loss: 1338.4672\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1241.3728 - val_loss: 1236.9850\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1128.0824 - val_loss: 1113.9590\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 994.8474 - val_loss: 971.4647\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 843.5784 - val_loss: 815.6818\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 685.8344 - val_loss: 656.7006\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 536.3368 - val_loss: 513.4118\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 408.7468 - val_loss: 399.2379\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 317.7443 - val_loss: 316.0788\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 258.2376 - val_loss: 269.9454\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 229.7138 - val_loss: 242.3072\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 214.8191 - val_loss: 229.3891\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.5148 - val_loss: 223.3397\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.2976 - val_loss: 218.9195\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.8915 - val_loss: 214.8461\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.9100 - val_loss: 212.3158\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.6328 - val_loss: 209.8158\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.9803 - val_loss: 207.4675\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.0864 - val_loss: 205.8444\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.2616 - val_loss: 203.7680\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.4135 - val_loss: 202.3500\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.5332 - val_loss: 200.7183\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.2073 - val_loss: 199.7216\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.6319 - val_loss: 197.9712\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.4021 - val_loss: 196.9071\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.1261 - val_loss: 195.4504\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.8338 - val_loss: 195.2212\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.9186 - val_loss: 193.7704\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.6968 - val_loss: 192.7463\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.7580 - val_loss: 192.1718\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.6769 - val_loss: 191.7133\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.8408 - val_loss: 190.8126\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.8473 - val_loss: 189.9383\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.0512 - val_loss: 189.1051\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.1835 - val_loss: 188.5358\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.2906 - val_loss: 187.5741\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.4454 - val_loss: 186.7438\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.4959 - val_loss: 185.8686\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.8464 - val_loss: 184.9833\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.9667 - val_loss: 184.4819\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.2517 - val_loss: 183.5632\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.4927 - val_loss: 183.3085\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.8658 - val_loss: 182.2139\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.1521 - val_loss: 181.6083\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.4204 - val_loss: 181.5223\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.9226 - val_loss: 180.6042\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.0547 - val_loss: 179.9391\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1575.2100 - val_loss: 1407.4662\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1522.9716 - val_loss: 1353.0637\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1459.3560 - val_loss: 1284.3578\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1376.7803 - val_loss: 1197.6874\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1273.6516 - val_loss: 1089.4827\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1145.6266 - val_loss: 961.9472\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 998.6826 - val_loss: 814.9702\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 835.3094 - val_loss: 663.4127\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 670.6541 - val_loss: 517.4122\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 519.3745 - val_loss: 393.1939\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 397.5891 - val_loss: 301.6309\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 313.5723 - val_loss: 243.9472\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 263.0426 - val_loss: 213.5447\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 236.7558 - val_loss: 198.6681\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 222.7515 - val_loss: 191.4761\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 214.8266 - val_loss: 187.1191\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 209.5144 - val_loss: 184.1745\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.7341 - val_loss: 181.8837\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.1401 - val_loss: 180.2011\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.5084 - val_loss: 178.3391\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.1204 - val_loss: 176.7411\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.9183 - val_loss: 175.2442\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.1077 - val_loss: 174.1265\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.0506 - val_loss: 172.4117\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.4576 - val_loss: 171.8405\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.6320 - val_loss: 170.6872\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.0061 - val_loss: 169.3607\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.4271 - val_loss: 168.4715\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.7855 - val_loss: 167.2359\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.6597 - val_loss: 166.3162\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.5016 - val_loss: 165.8946\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.2821 - val_loss: 165.1081\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.0913 - val_loss: 164.0896\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.8681 - val_loss: 163.1352\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.1184 - val_loss: 162.3961\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.9818 - val_loss: 162.0762\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.0315 - val_loss: 161.1979\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.9378 - val_loss: 160.3357\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.9202 - val_loss: 159.6322\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.2238 - val_loss: 158.8361\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.2722 - val_loss: 158.0927\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.4335 - val_loss: 157.6092\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.4484 - val_loss: 156.8087\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.5478 - val_loss: 155.8919\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.5364 - val_loss: 155.3571\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.8020 - val_loss: 154.9848\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.9228 - val_loss: 154.4528\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.0980 - val_loss: 154.0532\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.5331 - val_loss: 153.4978\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.3499 - val_loss: 152.3467\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1549.3660 - val_loss: 1464.4644\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1503.3168 - val_loss: 1416.7764\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1452.7131 - val_loss: 1359.7452\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1390.0948 - val_loss: 1288.6188\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1312.4828 - val_loss: 1200.9686\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1216.9207 - val_loss: 1091.4822\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1100.2415 - val_loss: 967.2052\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 968.7592 - val_loss: 829.6650\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 826.5917 - val_loss: 686.7911\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 681.4353 - val_loss: 548.9781\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 543.7441 - val_loss: 432.9484\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 426.7816 - val_loss: 344.8122\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 339.7558 - val_loss: 286.0297\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 279.9153 - val_loss: 256.8698\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 247.4929 - val_loss: 245.2888\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 229.2886 - val_loss: 241.1931\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 219.7256 - val_loss: 238.1948\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 214.0752 - val_loss: 236.3205\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 209.5727 - val_loss: 232.5270\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.7844 - val_loss: 228.6429\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.5247 - val_loss: 227.0953\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.4552 - val_loss: 222.1532\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.5331 - val_loss: 220.3411\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.8990 - val_loss: 217.4292\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.6645 - val_loss: 215.1010\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.0433 - val_loss: 212.7363\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.3754 - val_loss: 209.2392\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.2414 - val_loss: 207.8129\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.7867 - val_loss: 207.0433\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.5366 - val_loss: 204.2381\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.8607 - val_loss: 202.8741\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.2418 - val_loss: 200.4304\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.6474 - val_loss: 200.0068\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.3815 - val_loss: 198.9205\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.7027 - val_loss: 195.8544\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.3478 - val_loss: 195.0572\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.0135 - val_loss: 194.5227\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.7507 - val_loss: 192.9455\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.3692 - val_loss: 190.3677\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.4214 - val_loss: 188.5790\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.2469 - val_loss: 188.9836\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.9282 - val_loss: 186.8421\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.9354 - val_loss: 186.7730\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.0911 - val_loss: 186.4575\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.0810 - val_loss: 183.6654\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.2485 - val_loss: 183.8434\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.1728 - val_loss: 184.0601\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.4671 - val_loss: 182.1734\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.8638 - val_loss: 181.1245\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.0702 - val_loss: 181.6578\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1474.0248 - val_loss: 1580.5687\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1429.0845 - val_loss: 1522.6216\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1366.8322 - val_loss: 1440.4374\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1279.8130 - val_loss: 1326.5725\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1162.3619 - val_loss: 1179.6499\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1014.0873 - val_loss: 991.7191\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 834.8746 - val_loss: 780.6124\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 649.0483 - val_loss: 573.9030\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 479.1155 - val_loss: 409.9736\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 351.5102 - val_loss: 300.8079\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 273.2449 - val_loss: 245.3385\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 236.1526 - val_loss: 223.8120\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 220.9838 - val_loss: 216.1601\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.7109 - val_loss: 211.3969\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 209.7789 - val_loss: 207.5763\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 206.3207 - val_loss: 204.5951\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.2381 - val_loss: 202.0921\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.6552 - val_loss: 198.3735\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.4165 - val_loss: 197.3542\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.7964 - val_loss: 194.2372\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.6865 - val_loss: 192.5365\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.6143 - val_loss: 190.4868\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.2858 - val_loss: 188.5302\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.8778 - val_loss: 186.6360\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.9508 - val_loss: 184.8662\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.2489 - val_loss: 183.8220\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.6979 - val_loss: 181.1865\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.0593 - val_loss: 180.3097\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.5880 - val_loss: 179.3456\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.0747 - val_loss: 177.3683\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.7262 - val_loss: 175.6483\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.2906 - val_loss: 175.0620\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.0873 - val_loss: 173.8666\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.8432 - val_loss: 172.2116\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.6238 - val_loss: 171.5325\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.5625 - val_loss: 170.2092\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.5385 - val_loss: 169.1305\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.1981 - val_loss: 168.7813\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.1953 - val_loss: 167.6595\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.1504 - val_loss: 166.8549\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.3568 - val_loss: 165.5415\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.4913 - val_loss: 165.0775\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.4757 - val_loss: 164.6815\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.9892 - val_loss: 162.7405\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.6208 - val_loss: 163.6201\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.8557 - val_loss: 162.5344\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.2966 - val_loss: 161.4799\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.2947 - val_loss: 160.7931\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.5751 - val_loss: 159.9247\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.5726 - val_loss: 159.2739\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1603.8706 - val_loss: 1475.7969\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1559.1033 - val_loss: 1430.4381\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1509.5314 - val_loss: 1377.3091\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1444.7201 - val_loss: 1305.9486\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1358.3412 - val_loss: 1214.3312\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1247.7991 - val_loss: 1098.5566\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1109.9376 - val_loss: 963.1856\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 953.1707 - val_loss: 810.1707\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 783.6868 - val_loss: 653.9176\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 617.7697 - val_loss: 510.0684\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 473.4719 - val_loss: 389.6540\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 362.3528 - val_loss: 306.4958\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 290.0272 - val_loss: 255.6886\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 248.9359 - val_loss: 228.5679\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 229.5131 - val_loss: 213.4754\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 217.9755 - val_loss: 206.6592\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.8518 - val_loss: 201.8981\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.6051 - val_loss: 198.2294\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.7438 - val_loss: 195.5886\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.9975 - val_loss: 192.2179\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.2524 - val_loss: 190.0255\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.2375 - val_loss: 188.0081\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 194.0433 - val_loss: 186.4834\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.4315 - val_loss: 184.8177\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.7938 - val_loss: 183.0762\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.4245 - val_loss: 181.9049\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.5777 - val_loss: 180.5815\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.1847 - val_loss: 179.5644\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.8947 - val_loss: 178.7608\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.4949 - val_loss: 176.9583\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.4971 - val_loss: 175.8796\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.2730 - val_loss: 174.5379\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.8811 - val_loss: 173.5799\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.9405 - val_loss: 171.9708\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.7486 - val_loss: 171.3598\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.7270 - val_loss: 170.0656\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.5538 - val_loss: 169.0912\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.6211 - val_loss: 168.4025\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.7431 - val_loss: 167.1416\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.5422 - val_loss: 166.6074\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.6844 - val_loss: 165.3452\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.6405 - val_loss: 164.8516\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.9827 - val_loss: 163.7907\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.8451 - val_loss: 163.1904\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.3625 - val_loss: 162.6597\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.0770 - val_loss: 161.5069\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.2831 - val_loss: 160.8224\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.5276 - val_loss: 160.2559\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.9723 - val_loss: 159.9630\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.9540 - val_loss: 158.8015\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1514.5247 - val_loss: 1537.8599\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1476.7855 - val_loss: 1495.0284\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1424.4517 - val_loss: 1429.1383\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1343.9869 - val_loss: 1332.9885\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1234.6401 - val_loss: 1205.7644\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1093.2755 - val_loss: 1052.4750\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 932.4243 - val_loss: 879.4092\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 758.1744 - val_loss: 708.0812\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 591.5369 - val_loss: 546.9612\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 446.3904 - val_loss: 415.3782\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 335.8597 - val_loss: 323.2269\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 266.9829 - val_loss: 261.6335\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 226.9805 - val_loss: 235.1071\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.8697 - val_loss: 221.7266\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.3968 - val_loss: 217.4769\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.7505 - val_loss: 213.3428\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.6418 - val_loss: 210.5455\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.5161 - val_loss: 208.1003\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.4932 - val_loss: 206.1451\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.7753 - val_loss: 205.0958\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.6996 - val_loss: 202.9818\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.2905 - val_loss: 201.8665\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.6810 - val_loss: 199.9365\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.1612 - val_loss: 198.8465\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.7888 - val_loss: 197.0989\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.7179 - val_loss: 195.3471\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.6297 - val_loss: 194.4774\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.4097 - val_loss: 193.3651\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.4475 - val_loss: 192.7251\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.2770 - val_loss: 191.2108\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.1965 - val_loss: 190.5792\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.3544 - val_loss: 189.6824\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.2294 - val_loss: 188.7136\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.2425 - val_loss: 187.3209\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.4180 - val_loss: 187.3540\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.4685 - val_loss: 186.1032\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.9097 - val_loss: 185.1870\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.7406 - val_loss: 184.1348\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.2290 - val_loss: 183.4451\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.5955 - val_loss: 182.4674\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.0749 - val_loss: 181.6255\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.6965 - val_loss: 180.8917\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.9431 - val_loss: 180.1736\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.5803 - val_loss: 179.6788\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.3678 - val_loss: 178.8827\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.0697 - val_loss: 178.8966\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.4906 - val_loss: 177.0538\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.4259 - val_loss: 176.9879\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.6413 - val_loss: 176.0571\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.1925 - val_loss: 175.9380\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1576.8856 - val_loss: 1461.2196\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1534.6221 - val_loss: 1414.3494\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1471.9158 - val_loss: 1343.9199\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1378.0925 - val_loss: 1238.8015\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1246.3883 - val_loss: 1094.2634\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1075.8665 - val_loss: 920.3439\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 882.6039 - val_loss: 735.3905\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 686.6585 - val_loss: 555.1697\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 511.4643 - val_loss: 403.7232\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 374.6636 - val_loss: 298.5175\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 287.2254 - val_loss: 239.8904\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 243.1898 - val_loss: 210.8394\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 221.2034 - val_loss: 200.7440\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 211.9047 - val_loss: 196.3078\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 206.9071 - val_loss: 193.7772\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.2621 - val_loss: 192.4019\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.1104 - val_loss: 189.8046\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.6696 - val_loss: 188.5194\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.5002 - val_loss: 186.7630\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.3726 - val_loss: 185.0408\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.3820 - val_loss: 184.0079\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.6615 - val_loss: 182.7460\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.9178 - val_loss: 181.0912\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.3275 - val_loss: 180.2673\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.1583 - val_loss: 179.3916\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.6334 - val_loss: 178.6775\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.2667 - val_loss: 177.5499\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.1468 - val_loss: 176.9588\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.2368 - val_loss: 176.0086\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.9166 - val_loss: 174.7907\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.8364 - val_loss: 174.8580\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.1132 - val_loss: 173.9003\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.2951 - val_loss: 173.1508\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.2772 - val_loss: 173.0676\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.4361 - val_loss: 171.8899\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.2174 - val_loss: 171.1202\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.5762 - val_loss: 170.4133\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.1404 - val_loss: 169.1773\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.7831 - val_loss: 169.4069\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.0036 - val_loss: 168.6167\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.1540 - val_loss: 167.8304\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.4026 - val_loss: 167.2258\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.7083 - val_loss: 167.0485\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.1956 - val_loss: 166.1825\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.2669 - val_loss: 165.3067\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.6867 - val_loss: 165.1244\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.5141 - val_loss: 164.2004\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.1348 - val_loss: 163.6816\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.5981 - val_loss: 163.7162\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.1244 - val_loss: 162.9089\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1516.3486 - val_loss: 1486.5905\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1456.0826 - val_loss: 1417.1122\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1383.7488 - val_loss: 1331.6801\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1292.4756 - val_loss: 1221.7312\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1175.5349 - val_loss: 1084.2025\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1032.4369 - val_loss: 921.3045\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 867.3293 - val_loss: 746.6454\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 695.2733 - val_loss: 576.2430\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 536.2219 - val_loss: 428.7563\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 407.4729 - val_loss: 318.9684\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 316.7447 - val_loss: 252.2566\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 263.1373 - val_loss: 218.1507\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 239.2572 - val_loss: 201.5125\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 227.0181 - val_loss: 195.4280\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 220.6803 - val_loss: 191.9478\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 216.7868 - val_loss: 189.8311\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.6048 - val_loss: 187.3659\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 209.3023 - val_loss: 185.7082\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 206.8645 - val_loss: 184.4961\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.3159 - val_loss: 182.8563\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.2447 - val_loss: 181.4258\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.3644 - val_loss: 179.7440\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.4679 - val_loss: 178.8447\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.4436 - val_loss: 177.8970\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.6542 - val_loss: 176.6320\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.0907 - val_loss: 175.4598\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.3752 - val_loss: 174.1912\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.7308 - val_loss: 173.5072\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.6067 - val_loss: 172.3681\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.6777 - val_loss: 171.6222\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.5520 - val_loss: 170.6253\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.2069 - val_loss: 169.6768\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.0267 - val_loss: 168.9496\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.5302 - val_loss: 168.1056\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.4367 - val_loss: 167.1283\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.5655 - val_loss: 166.6913\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.1515 - val_loss: 165.9663\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.4469 - val_loss: 165.4052\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.4694 - val_loss: 164.8542\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.6729 - val_loss: 163.9632\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.5428 - val_loss: 163.5069\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.8492 - val_loss: 162.8611\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.4048 - val_loss: 162.0087\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.4480 - val_loss: 162.0241\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.5032 - val_loss: 161.1844\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.0298 - val_loss: 160.7051\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.8966 - val_loss: 160.7217\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.5451 - val_loss: 160.1409\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.2286 - val_loss: 159.7931\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.7986 - val_loss: 159.2292\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1573.9816 - val_loss: 1370.9861\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1524.0734 - val_loss: 1320.1028\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1460.4128 - val_loss: 1251.9468\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1373.8542 - val_loss: 1157.1976\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1256.8745 - val_loss: 1032.1011\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1105.0219 - val_loss: 882.6168\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 929.0881 - val_loss: 709.9337\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 732.7554 - val_loss: 541.9739\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 548.7585 - val_loss: 393.6765\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 395.7704 - val_loss: 292.2627\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 293.7654 - val_loss: 239.1407\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 238.3580 - val_loss: 222.6778\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 216.3582 - val_loss: 219.7062\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 206.0884 - val_loss: 219.2151\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.6254 - val_loss: 219.1436\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.0139 - val_loss: 220.6941\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.1581 - val_loss: 220.5916\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.5006 - val_loss: 219.8269\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.3820 - val_loss: 217.5151\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 187.1519 - val_loss: 218.7558\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.3823 - val_loss: 218.3904\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.5552 - val_loss: 217.0168\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 181.8850 - val_loss: 216.8666\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.1981 - val_loss: 216.8880\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.9619 - val_loss: 216.3473\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.4563 - val_loss: 215.4703\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.2627 - val_loss: 217.1857\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.0521 - val_loss: 215.6881\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 173.6596 - val_loss: 214.3251\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 172.7108 - val_loss: 214.7630\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.7850 - val_loss: 213.5954\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.5281 - val_loss: 214.5840\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.3797 - val_loss: 213.2923\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 168.3402 - val_loss: 212.0771\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.7542 - val_loss: 213.2156\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.4809 - val_loss: 211.5446\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 165.8119 - val_loss: 212.6688\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 164.9504 - val_loss: 210.6297\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.3174 - val_loss: 211.0560\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.6977 - val_loss: 211.5257\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 162.6677 - val_loss: 209.3942\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.9475 - val_loss: 209.7595\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.0493 - val_loss: 209.2016\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 160.6181 - val_loss: 209.2264\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 159.7957 - val_loss: 208.6166\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 159.1049 - val_loss: 206.9417\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 158.2719 - val_loss: 207.7082\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 157.6946 - val_loss: 208.3117\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 156.9388 - val_loss: 205.8613\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 156.3904 - val_loss: 206.0682\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1495.1434 - val_loss: 1629.2734\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1456.9459 - val_loss: 1586.3459\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1409.3145 - val_loss: 1526.5172\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1338.8920 - val_loss: 1435.8680\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1232.4891 - val_loss: 1301.5060\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1084.5985 - val_loss: 1122.9125\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 896.8956 - val_loss: 915.0444\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 692.2977 - val_loss: 696.3206\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 502.2437 - val_loss: 503.5410\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 357.2673 - val_loss: 366.1100\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 271.6835 - val_loss: 290.4200\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 234.2754 - val_loss: 253.9189\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 218.7701 - val_loss: 239.4987\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.0446 - val_loss: 231.0299\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.1203 - val_loss: 227.6104\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.5274 - val_loss: 224.1421\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.3801 - val_loss: 218.1031\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.5635 - val_loss: 217.3191\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.1308 - val_loss: 213.2523\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.3721 - val_loss: 210.8938\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.2140 - val_loss: 207.8748\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.0217 - val_loss: 205.9564\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.8448 - val_loss: 204.9557\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.2101 - val_loss: 203.2547\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.5504 - val_loss: 201.1342\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.7978 - val_loss: 200.5042\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.6672 - val_loss: 198.3453\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.1263 - val_loss: 197.6951\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.7069 - val_loss: 196.2155\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.7435 - val_loss: 195.8390\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 173.2540 - val_loss: 194.3993\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.3802 - val_loss: 192.6863\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.6457 - val_loss: 193.5540\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.7089 - val_loss: 192.3340\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.5299 - val_loss: 189.6984\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.2261 - val_loss: 189.7136\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.7217 - val_loss: 190.7629\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.9925 - val_loss: 188.9488\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.7218 - val_loss: 188.2778\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.1630 - val_loss: 188.1161\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.2982 - val_loss: 186.3622\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.7217 - val_loss: 187.0039\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.0365 - val_loss: 184.0760\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.2602 - val_loss: 184.9699\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.2908 - val_loss: 185.1146\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 161.0175 - val_loss: 183.9620\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.3074 - val_loss: 182.8675\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.7965 - val_loss: 182.6549\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.9937 - val_loss: 180.9759\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.5551 - val_loss: 180.9588\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1605.1625 - val_loss: 1426.0775\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1559.1910 - val_loss: 1379.2527\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1498.5082 - val_loss: 1314.8962\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1415.9980 - val_loss: 1226.2085\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1302.2295 - val_loss: 1109.6523\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1154.0690 - val_loss: 964.5260\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 977.3613 - val_loss: 798.4688\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 787.0702 - val_loss: 628.0983\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 601.1974 - val_loss: 476.0335\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 448.0568 - val_loss: 358.1509\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 342.3080 - val_loss: 283.8838\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 281.0333 - val_loss: 243.0739\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 249.5296 - val_loss: 223.3436\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 233.7733 - val_loss: 212.6736\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 224.9941 - val_loss: 205.3949\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 219.2589 - val_loss: 201.1324\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 214.8631 - val_loss: 197.9159\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 210.1443 - val_loss: 195.2301\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 206.5203 - val_loss: 192.7030\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.3843 - val_loss: 189.9893\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.7963 - val_loss: 188.3024\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.0554 - val_loss: 187.0110\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.0821 - val_loss: 185.3258\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.3276 - val_loss: 183.5705\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.4707 - val_loss: 182.4104\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.5244 - val_loss: 181.0308\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.0936 - val_loss: 180.1347\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.4426 - val_loss: 178.4865\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.6588 - val_loss: 177.8107\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.2089 - val_loss: 176.7602\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.0973 - val_loss: 175.8659\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.7995 - val_loss: 174.6222\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.2719 - val_loss: 173.9432\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.3092 - val_loss: 173.1644\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.9247 - val_loss: 171.9379\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.9136 - val_loss: 171.4966\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.2593 - val_loss: 170.5771\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.1217 - val_loss: 170.5287\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.9235 - val_loss: 169.6257\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.0691 - val_loss: 168.5753\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.2199 - val_loss: 168.0672\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.0822 - val_loss: 167.0669\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.0427 - val_loss: 166.7542\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.2116 - val_loss: 166.1174\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.2791 - val_loss: 165.0684\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.4167 - val_loss: 164.5642\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.5266 - val_loss: 164.1758\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.8482 - val_loss: 163.1707\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.0930 - val_loss: 163.1673\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.1306 - val_loss: 162.6632\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1550.9572 - val_loss: 1610.7103\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1527.5817 - val_loss: 1591.7238\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1508.1711 - val_loss: 1567.9100\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1480.7185 - val_loss: 1531.6105\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1439.9683 - val_loss: 1482.8225\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1385.3867 - val_loss: 1416.3817\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1312.8619 - val_loss: 1329.9943\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1220.1625 - val_loss: 1221.5010\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1106.6647 - val_loss: 1090.1205\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 974.4779 - val_loss: 941.0587\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 828.2896 - val_loss: 784.9482\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 681.0282 - val_loss: 631.5376\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 542.8177 - val_loss: 496.4643\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 426.5296 - val_loss: 387.7400\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 337.8143 - val_loss: 311.3728\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 280.0780 - val_loss: 263.0858\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 247.6676 - val_loss: 235.1163\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 229.4494 - val_loss: 220.6205\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 219.8102 - val_loss: 211.4215\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 214.6250 - val_loss: 206.0098\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.6116 - val_loss: 202.2463\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 206.2643 - val_loss: 199.0428\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.1972 - val_loss: 195.8680\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.6410 - val_loss: 193.4591\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.3391 - val_loss: 191.6948\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.8940 - val_loss: 189.5041\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.1100 - val_loss: 188.0087\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.5198 - val_loss: 185.4575\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.3574 - val_loss: 184.1381\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.1319 - val_loss: 182.4520\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.2666 - val_loss: 180.8481\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.9287 - val_loss: 180.0121\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.1794 - val_loss: 178.0642\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.5087 - val_loss: 177.2601\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.2072 - val_loss: 176.0334\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.6639 - val_loss: 175.3499\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.6292 - val_loss: 174.4897\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.3584 - val_loss: 173.1183\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.0232 - val_loss: 172.6158\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.9331 - val_loss: 172.0118\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.8727 - val_loss: 170.5919\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.6982 - val_loss: 170.4483\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.9277 - val_loss: 169.9393\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.8048 - val_loss: 169.0402\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.8063 - val_loss: 168.4086\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.8412 - val_loss: 167.4971\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.9583 - val_loss: 166.8949\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.1250 - val_loss: 166.8029\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.6076 - val_loss: 165.9180\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.4585 - val_loss: 165.6597\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1583.4607 - val_loss: 1626.7720\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1554.3425 - val_loss: 1604.9365\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1535.8198 - val_loss: 1586.9944\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1516.6890 - val_loss: 1563.5972\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1490.9802 - val_loss: 1533.1847\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1458.2185 - val_loss: 1494.9419\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1416.3735 - val_loss: 1445.9554\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1363.4553 - val_loss: 1383.8052\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1296.5923 - val_loss: 1306.3625\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1213.6970 - val_loss: 1212.3157\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1115.0416 - val_loss: 1100.0229\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1000.7404 - val_loss: 974.6136\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 874.5225 - val_loss: 839.0364\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 743.0996 - val_loss: 700.9569\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 613.8289 - val_loss: 573.4164\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 498.3656 - val_loss: 459.8443\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 401.1350 - val_loss: 367.7879\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 329.1410 - val_loss: 299.2692\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 280.0375 - val_loss: 256.4438\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 251.4746 - val_loss: 229.6646\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 234.6478 - val_loss: 213.9006\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 224.2004 - val_loss: 204.9342\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 218.3597 - val_loss: 198.2502\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 213.4811 - val_loss: 194.5436\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 210.1172 - val_loss: 191.3631\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.1665 - val_loss: 189.4770\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.1608 - val_loss: 186.0384\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 201.2155 - val_loss: 185.3729\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.8538 - val_loss: 183.8095\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.6677 - val_loss: 181.9602\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.4743 - val_loss: 181.2713\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.3051 - val_loss: 179.3473\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.4799 - val_loss: 178.8836\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.5051 - val_loss: 177.7323\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.9364 - val_loss: 176.0534\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.1810 - val_loss: 175.2746\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.0485 - val_loss: 175.0811\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.0859 - val_loss: 173.9906\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.6879 - val_loss: 172.7007\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 179.4035 - val_loss: 172.1291\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.1014 - val_loss: 171.7041\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.9692 - val_loss: 171.8312\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.7432 - val_loss: 170.8392\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.7169 - val_loss: 170.3052\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.5693 - val_loss: 170.0483\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.7774 - val_loss: 169.2499\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.5956 - val_loss: 168.8411\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.7441 - val_loss: 168.1232\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.9368 - val_loss: 168.2461\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.0122 - val_loss: 167.3286\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1486.6907 - val_loss: 1497.6758\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1428.9109 - val_loss: 1430.0646\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1353.1492 - val_loss: 1339.8582\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1254.3997 - val_loss: 1220.7108\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1127.7070 - val_loss: 1072.4563\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 976.0005 - val_loss: 905.6030\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 811.3257 - val_loss: 728.1240\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 644.4454 - val_loss: 561.5827\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 497.2297 - val_loss: 417.6891\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 381.7059 - val_loss: 319.1799\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.8422 - val_loss: 257.6051\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 265.4832 - val_loss: 226.2296\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 243.7162 - val_loss: 211.7550\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 231.6131 - val_loss: 203.9139\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 224.0278 - val_loss: 199.3845\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 218.2640 - val_loss: 195.2139\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.1507 - val_loss: 192.9557\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.3000 - val_loss: 189.9058\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.6564 - val_loss: 187.7687\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.7014 - val_loss: 186.0823\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.5239 - val_loss: 184.8788\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.7028 - val_loss: 182.8389\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.2875 - val_loss: 181.6837\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.5550 - val_loss: 180.4855\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.6280 - val_loss: 179.4201\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.6674 - val_loss: 177.6722\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.2284 - val_loss: 176.4912\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.5266 - val_loss: 175.6297\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.2917 - val_loss: 175.0134\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.7905 - val_loss: 174.5404\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.5486 - val_loss: 173.1031\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.4066 - val_loss: 172.4858\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.0074 - val_loss: 171.7590\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.9666 - val_loss: 171.2035\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.0895 - val_loss: 170.2362\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.9247 - val_loss: 169.8654\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.8938 - val_loss: 169.1427\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.0747 - val_loss: 168.6379\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.4067 - val_loss: 168.0107\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.6402 - val_loss: 167.6122\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.6370 - val_loss: 166.9658\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.8038 - val_loss: 166.5449\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.2261 - val_loss: 166.2670\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.6130 - val_loss: 166.1403\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.6412 - val_loss: 165.3802\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.9429 - val_loss: 164.7735\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.3961 - val_loss: 164.4228\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.9419 - val_loss: 163.5077\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.1537 - val_loss: 163.4876\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.3207 - val_loss: 163.1517\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1500.7054 - val_loss: 1466.2368\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1443.1633 - val_loss: 1397.5743\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1367.3043 - val_loss: 1302.6989\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1263.9337 - val_loss: 1178.1974\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1130.1141 - val_loss: 1021.7960\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 966.3500 - val_loss: 841.3879\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 784.3096 - val_loss: 654.8386\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 604.2555 - val_loss: 485.3872\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 448.7389 - val_loss: 357.3609\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 336.1317 - val_loss: 279.0165\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 269.1254 - val_loss: 240.7097\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 237.6528 - val_loss: 224.7251\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 223.0953 - val_loss: 216.4062\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 216.4746 - val_loss: 208.6465\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 211.3634 - val_loss: 206.4147\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.6229 - val_loss: 200.9043\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.3890 - val_loss: 196.6610\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 201.5795 - val_loss: 192.8593\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.9850 - val_loss: 191.2631\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.6902 - val_loss: 188.3459\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.9127 - val_loss: 185.4368\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.7258 - val_loss: 183.6127\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.8965 - val_loss: 182.6965\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.3913 - val_loss: 181.7527\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.1722 - val_loss: 180.2007\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.4299 - val_loss: 178.8508\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.3622 - val_loss: 178.4876\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.9849 - val_loss: 175.9681\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.7951 - val_loss: 174.4857\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.9335 - val_loss: 174.6174\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.7353 - val_loss: 172.4473\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.7822 - val_loss: 171.7860\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.7163 - val_loss: 170.6650\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.8979 - val_loss: 170.0882\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.0217 - val_loss: 169.5471\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.2549 - val_loss: 169.2940\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.5670 - val_loss: 167.5385\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.8089 - val_loss: 167.8055\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.9939 - val_loss: 166.2730\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.2792 - val_loss: 166.4641\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.7638 - val_loss: 165.7475\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.1290 - val_loss: 165.4289\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.5693 - val_loss: 164.5715\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.9643 - val_loss: 164.4131\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.1617 - val_loss: 164.0086\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.6382 - val_loss: 163.7677\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.8759 - val_loss: 162.9879\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.3570 - val_loss: 162.7213\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.8266 - val_loss: 162.7559\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.4025 - val_loss: 161.7242\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1605.1527 - val_loss: 1497.7368\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1570.9945 - val_loss: 1461.8778\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1532.0619 - val_loss: 1415.5950\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1479.3395 - val_loss: 1352.6200\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1409.5145 - val_loss: 1272.1494\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1321.1272 - val_loss: 1174.6852\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1213.0098 - val_loss: 1056.2462\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1083.0543 - val_loss: 919.0077\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 935.9909 - val_loss: 767.1770\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 775.9800 - val_loss: 613.1995\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 618.4144 - val_loss: 471.5680\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 481.4572 - val_loss: 353.5877\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 369.1236 - val_loss: 273.2878\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 295.9955 - val_loss: 221.0867\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 252.2700 - val_loss: 194.9896\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 230.5207 - val_loss: 182.5082\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 220.0034 - val_loss: 177.7687\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 214.4793 - val_loss: 174.2190\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 210.5108 - val_loss: 173.1236\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 207.5732 - val_loss: 172.1426\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 204.6586 - val_loss: 170.9319\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 201.9917 - val_loss: 170.2148\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.3073 - val_loss: 170.2612\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.6560 - val_loss: 169.7265\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.6617 - val_loss: 169.1065\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.7487 - val_loss: 168.4986\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.9492 - val_loss: 167.5222\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.3786 - val_loss: 166.9974\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.5647 - val_loss: 166.4721\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.1354 - val_loss: 165.6883\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.5770 - val_loss: 165.1425\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.2819 - val_loss: 164.9140\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.7771 - val_loss: 163.4080\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.7044 - val_loss: 162.8590\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.4855 - val_loss: 163.1290\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.9684 - val_loss: 161.9464\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.1329 - val_loss: 162.1065\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.7381 - val_loss: 161.0020\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.2107 - val_loss: 159.7882\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.4723 - val_loss: 159.9751\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.4913 - val_loss: 159.4518\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.2314 - val_loss: 159.6617\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.4902 - val_loss: 158.6890\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.3207 - val_loss: 158.5115\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.5913 - val_loss: 158.7042\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.5792 - val_loss: 157.7443\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.4610 - val_loss: 157.5200\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.7886 - val_loss: 157.3600\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.8215 - val_loss: 157.0673\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.2843 - val_loss: 156.2533\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1511.4269 - val_loss: 1498.3118\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1455.5659 - val_loss: 1435.2452\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1382.2346 - val_loss: 1345.3597\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1280.3384 - val_loss: 1225.2761\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1149.1525 - val_loss: 1076.3954\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 992.9602 - val_loss: 904.2802\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 819.9462 - val_loss: 720.1367\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 643.6539 - val_loss: 549.3132\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 488.9521 - val_loss: 408.4151\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 372.1559 - val_loss: 316.1721\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 298.6844 - val_loss: 266.7133\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 259.7598 - val_loss: 243.8571\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 240.3912 - val_loss: 233.8198\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 229.0036 - val_loss: 227.2763\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 220.9277 - val_loss: 222.9552\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 214.7969 - val_loss: 218.7199\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.5540 - val_loss: 214.5774\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.6486 - val_loss: 211.0057\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.5600 - val_loss: 207.8421\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.2177 - val_loss: 205.5633\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.2919 - val_loss: 202.5444\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.8483 - val_loss: 201.5049\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.3719 - val_loss: 199.2600\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.2642 - val_loss: 196.5763\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.2852 - val_loss: 195.1625\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.7082 - val_loss: 193.9009\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.0785 - val_loss: 192.0536\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.5805 - val_loss: 191.4887\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.6036 - val_loss: 189.7718\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.9696 - val_loss: 188.6881\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.9310 - val_loss: 187.5332\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.4163 - val_loss: 185.7938\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.3744 - val_loss: 185.9799\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.4291 - val_loss: 183.8239\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.4760 - val_loss: 183.1785\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.5661 - val_loss: 182.5691\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.8908 - val_loss: 182.8642\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.9575 - val_loss: 181.6352\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.4281 - val_loss: 181.3106\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.6170 - val_loss: 179.5988\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.8474 - val_loss: 179.1145\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.0155 - val_loss: 178.8579\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.5198 - val_loss: 178.1003\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.8681 - val_loss: 176.6996\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.3714 - val_loss: 176.3526\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.7248 - val_loss: 175.8438\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.3377 - val_loss: 175.6159\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.6156 - val_loss: 174.2751\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.9761 - val_loss: 174.1433\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.5501 - val_loss: 173.4152\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1556.6967 - val_loss: 1520.5574\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1512.6935 - val_loss: 1470.3374\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1456.0887 - val_loss: 1399.4572\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1375.4102 - val_loss: 1301.8794\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1265.8093 - val_loss: 1170.3588\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1124.4092 - val_loss: 1010.4229\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 959.9009 - val_loss: 830.5605\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 779.0086 - val_loss: 648.9528\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 604.2142 - val_loss: 478.5787\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 451.3998 - val_loss: 348.4131\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 342.6932 - val_loss: 263.3626\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 274.3333 - val_loss: 220.2543\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 242.2197 - val_loss: 198.1471\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 226.2880 - val_loss: 188.4032\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 218.8949 - val_loss: 182.9005\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.8006 - val_loss: 180.6008\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.7304 - val_loss: 178.9358\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.9404 - val_loss: 176.8973\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.0448 - val_loss: 175.4954\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.4595 - val_loss: 174.8966\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.1289 - val_loss: 173.9198\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.0758 - val_loss: 173.1277\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.4057 - val_loss: 172.7224\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.6444 - val_loss: 171.6378\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.3160 - val_loss: 170.9486\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.9324 - val_loss: 169.9624\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.5506 - val_loss: 169.6273\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.3044 - val_loss: 169.1883\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.0270 - val_loss: 168.5985\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.3279 - val_loss: 168.8954\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.9617 - val_loss: 167.6641\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.2792 - val_loss: 167.5764\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.1263 - val_loss: 166.3352\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.0125 - val_loss: 166.1530\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.9278 - val_loss: 165.0634\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.8457 - val_loss: 165.0921\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.9037 - val_loss: 163.7919\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.0432 - val_loss: 163.3120\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.2242 - val_loss: 162.8533\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.4629 - val_loss: 162.4251\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.6320 - val_loss: 161.7522\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.8920 - val_loss: 160.9716\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.0716 - val_loss: 160.8114\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.2831 - val_loss: 160.5822\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.3873 - val_loss: 159.2954\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.1923 - val_loss: 158.7505\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.8684 - val_loss: 158.1763\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.0497 - val_loss: 157.8301\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.3813 - val_loss: 157.1982\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.7753 - val_loss: 156.7658\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1526.9991 - val_loss: 1515.4630\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1475.0969 - val_loss: 1454.0475\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1405.4576 - val_loss: 1372.8582\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1312.3024 - val_loss: 1264.3507\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1189.6921 - val_loss: 1122.8744\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1033.6930 - val_loss: 948.9890\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 850.2355 - val_loss: 751.8618\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 652.9570 - val_loss: 563.6548\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 476.3098 - val_loss: 404.7212\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 339.1677 - val_loss: 303.2720\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 259.2022 - val_loss: 251.0588\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 222.3878 - val_loss: 231.0365\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 209.5835 - val_loss: 222.2086\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 204.6879 - val_loss: 216.8063\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 201.2475 - val_loss: 213.5203\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.6619 - val_loss: 211.0614\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.5591 - val_loss: 207.7571\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.3973 - val_loss: 204.3010\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.2360 - val_loss: 202.6778\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.7031 - val_loss: 200.0905\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.5774 - val_loss: 198.4769\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.5335 - val_loss: 196.4496\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.7129 - val_loss: 195.1464\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.3131 - val_loss: 193.4822\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.0904 - val_loss: 191.9074\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.7209 - val_loss: 191.3361\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.6196 - val_loss: 190.3796\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.3997 - val_loss: 188.9357\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.3602 - val_loss: 188.0957\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.6654 - val_loss: 186.8541\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.3045 - val_loss: 186.3840\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.5826 - val_loss: 185.2558\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.7342 - val_loss: 184.1876\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.0504 - val_loss: 183.0458\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 173.0721 - val_loss: 181.8079\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.2139 - val_loss: 181.5587\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 171.6857 - val_loss: 180.8266\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.9888 - val_loss: 180.7396\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.3684 - val_loss: 180.1546\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.5455 - val_loss: 178.7681\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.8683 - val_loss: 178.6747\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.1831 - val_loss: 177.6842\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.6257 - val_loss: 176.9970\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.9955 - val_loss: 176.5266\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.4998 - val_loss: 175.5286\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.0311 - val_loss: 175.4793\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.5646 - val_loss: 174.9431\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.9364 - val_loss: 174.1392\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.4191 - val_loss: 172.5595\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.9649 - val_loss: 172.2576\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1527.2463 - val_loss: 1530.1257\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1486.7723 - val_loss: 1481.8962\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1428.7068 - val_loss: 1413.0835\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1346.3135 - val_loss: 1313.8561\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1230.9678 - val_loss: 1181.5846\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1084.4598 - val_loss: 1019.7537\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 910.7424 - val_loss: 837.6762\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 722.2788 - val_loss: 654.1110\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 548.1967 - val_loss: 486.7746\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 402.6641 - val_loss: 367.6766\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 306.2151 - val_loss: 291.0191\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 252.1368 - val_loss: 253.5133\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 228.7475 - val_loss: 233.9904\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 217.9841 - val_loss: 225.4127\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.1862 - val_loss: 219.3986\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.1209 - val_loss: 215.0701\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.9640 - val_loss: 211.6295\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.0810 - val_loss: 207.9886\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.2807 - val_loss: 205.6519\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.3277 - val_loss: 203.3091\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.1489 - val_loss: 202.1373\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.2937 - val_loss: 201.0004\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.9516 - val_loss: 198.6812\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.3485 - val_loss: 198.1805\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.0885 - val_loss: 196.7524\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.5646 - val_loss: 194.6561\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.3840 - val_loss: 194.2724\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.4883 - val_loss: 193.7160\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.2908 - val_loss: 191.9624\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.5053 - val_loss: 190.5766\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.3246 - val_loss: 189.5967\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.3566 - val_loss: 189.1811\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.5668 - val_loss: 188.1107\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.8219 - val_loss: 187.3502\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.9884 - val_loss: 186.4075\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.0565 - val_loss: 185.6264\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 177.3288 - val_loss: 184.8120\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.5793 - val_loss: 183.8971\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.8012 - val_loss: 182.9111\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.0400 - val_loss: 182.5597\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.5964 - val_loss: 181.8054\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.7634 - val_loss: 181.4612\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.1059 - val_loss: 180.0318\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.6024 - val_loss: 179.3171\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.9274 - val_loss: 179.4318\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.3954 - val_loss: 179.3414\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.6805 - val_loss: 178.1431\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.0219 - val_loss: 176.4028\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.3291 - val_loss: 176.3466\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.8696 - val_loss: 176.1101\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1533.6086 - val_loss: 1600.2793\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1498.2091 - val_loss: 1562.7744\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1456.2838 - val_loss: 1514.8889\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1400.9501 - val_loss: 1452.2698\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1327.9200 - val_loss: 1360.9088\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1227.6152 - val_loss: 1247.1808\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1109.8973 - val_loss: 1112.7578\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 973.2346 - val_loss: 959.7829\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 821.8381 - val_loss: 791.1113\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 662.0038 - val_loss: 619.0989\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 509.9658 - val_loss: 464.8854\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 382.4999 - val_loss: 350.0132\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 293.5088 - val_loss: 280.3466\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 242.2534 - val_loss: 245.6417\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 216.9724 - val_loss: 231.5956\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.9323 - val_loss: 225.9538\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.5273 - val_loss: 222.6810\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.1599 - val_loss: 219.9429\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.8171 - val_loss: 217.2988\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.1559 - val_loss: 214.7654\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.5003 - val_loss: 213.0106\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.6910 - val_loss: 209.6260\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.8185 - val_loss: 208.1053\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.4114 - val_loss: 206.4347\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.0223 - val_loss: 204.5914\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.4747 - val_loss: 203.4352\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.4360 - val_loss: 201.3767\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.1402 - val_loss: 199.8700\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.0310 - val_loss: 198.8725\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.8056 - val_loss: 197.0579\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.4330 - val_loss: 195.7689\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.4503 - val_loss: 194.6992\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.4163 - val_loss: 193.1905\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.4557 - val_loss: 192.4214\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.4398 - val_loss: 191.1829\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.4530 - val_loss: 190.1270\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.4763 - val_loss: 188.9386\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.5147 - val_loss: 187.4913\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.6734 - val_loss: 186.9380\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.5141 - val_loss: 186.2213\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.8746 - val_loss: 184.8950\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.8057 - val_loss: 183.8421\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.9094 - val_loss: 183.0786\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.2004 - val_loss: 182.0555\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.3170 - val_loss: 181.5599\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.4517 - val_loss: 180.6305\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.8058 - val_loss: 179.8481\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.8226 - val_loss: 178.7543\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.1875 - val_loss: 178.1489\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.4379 - val_loss: 177.4219\n",
      "10/10 [==============================] - 0s 990us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1589.4003 - val_loss: 1506.9728\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1572.5577 - val_loss: 1494.2314\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1558.7753 - val_loss: 1479.2125\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1540.2524 - val_loss: 1457.0210\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1513.5521 - val_loss: 1426.5803\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1477.3015 - val_loss: 1385.9871\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1428.4625 - val_loss: 1332.6877\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1364.3335 - val_loss: 1263.3700\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1281.2651 - val_loss: 1177.9872\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1180.5366 - val_loss: 1073.0063\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1060.3086 - val_loss: 955.0551\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 927.7562 - val_loss: 828.1843\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 786.9897 - val_loss: 699.9153\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 649.7520 - val_loss: 576.6378\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 525.1304 - val_loss: 469.2872\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 419.2523 - val_loss: 384.1025\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 338.3071 - val_loss: 322.3888\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 282.7450 - val_loss: 279.0846\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 245.6528 - val_loss: 254.7488\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 223.8471 - val_loss: 240.2398\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.6027 - val_loss: 231.6100\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.3379 - val_loss: 226.4682\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.0839 - val_loss: 223.0476\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.5103 - val_loss: 220.3847\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.3678 - val_loss: 218.6698\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.9046 - val_loss: 216.5826\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.1102 - val_loss: 215.7336\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.1419 - val_loss: 213.0248\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.2174 - val_loss: 212.1817\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.6638 - val_loss: 210.8029\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.1959 - val_loss: 209.7967\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.9787 - val_loss: 208.0947\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.4902 - val_loss: 206.5537\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 175.3675 - val_loss: 205.9425\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.3547 - val_loss: 204.7484\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.2594 - val_loss: 203.9811\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.2155 - val_loss: 202.6734\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.4233 - val_loss: 201.8704\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 170.4585 - val_loss: 200.9589\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 169.6756 - val_loss: 199.9579\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 169.0074 - val_loss: 198.8671\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.8808 - val_loss: 198.1878\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.1569 - val_loss: 197.2351\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 166.4721 - val_loss: 197.0366\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.5415 - val_loss: 195.8221\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.9538 - val_loss: 194.3584\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.1793 - val_loss: 193.9805\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.5826 - val_loss: 192.7708\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.6866 - val_loss: 192.9594\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.9539 - val_loss: 191.8053\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1533.0343 - val_loss: 1611.1991\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1502.1720 - val_loss: 1573.6016\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1459.3738 - val_loss: 1514.0498\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1395.1409 - val_loss: 1432.9060\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1310.4576 - val_loss: 1329.9739\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1201.3951 - val_loss: 1200.5497\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1067.3372 - val_loss: 1045.7106\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 913.2611 - val_loss: 873.7103\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 746.8926 - val_loss: 696.6273\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 582.6490 - val_loss: 534.9517\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 439.9467 - val_loss: 404.7807\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 334.5677 - val_loss: 312.8629\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 265.3472 - val_loss: 262.1582\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 228.2536 - val_loss: 236.9745\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.1671 - val_loss: 224.9711\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.7825 - val_loss: 218.3920\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.8195 - val_loss: 214.1094\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.3689 - val_loss: 209.9061\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.8352 - val_loss: 207.6686\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.4246 - val_loss: 205.1483\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.6960 - val_loss: 203.3703\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.1062 - val_loss: 201.1867\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.3318 - val_loss: 198.9776\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.8924 - val_loss: 197.4039\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.5503 - val_loss: 196.0155\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.9577 - val_loss: 194.0746\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.9451 - val_loss: 192.1140\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.4217 - val_loss: 190.9659\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.2590 - val_loss: 189.5350\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.3685 - val_loss: 188.2353\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.9591 - val_loss: 186.7004\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.1041 - val_loss: 185.0681\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.9301 - val_loss: 183.5949\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.8497 - val_loss: 182.5767\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.0322 - val_loss: 181.2963\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.9367 - val_loss: 180.8652\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.1687 - val_loss: 179.1982\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.2313 - val_loss: 177.8588\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.1752 - val_loss: 177.7025\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.3964 - val_loss: 175.8919\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.5381 - val_loss: 174.8310\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.6901 - val_loss: 173.8569\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.9358 - val_loss: 173.3571\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.1046 - val_loss: 172.0367\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.4900 - val_loss: 171.0100\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.0566 - val_loss: 170.4538\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.2464 - val_loss: 169.2402\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.1245 - val_loss: 168.8358\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.4315 - val_loss: 167.9617\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.6460 - val_loss: 166.5569\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1512.7759 - val_loss: 1529.3306\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1445.7010 - val_loss: 1452.4779\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1370.4946 - val_loss: 1360.9974\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1277.6381 - val_loss: 1249.5620\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1165.8696 - val_loss: 1112.0916\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1029.4554 - val_loss: 959.0715\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 877.8907 - val_loss: 785.5281\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 713.6513 - val_loss: 616.8286\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 558.8460 - val_loss: 465.3127\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 426.4664 - val_loss: 349.8835\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 328.5907 - val_loss: 275.2446\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 267.3954 - val_loss: 237.3051\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 236.5096 - val_loss: 220.5181\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 223.8463 - val_loss: 213.7383\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 217.0269 - val_loss: 209.4865\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.3190 - val_loss: 206.4218\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 210.3676 - val_loss: 202.1929\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.6989 - val_loss: 200.3801\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.1761 - val_loss: 197.5891\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.2462 - val_loss: 195.3459\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.4672 - val_loss: 194.2877\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.2487 - val_loss: 190.9436\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.2423 - val_loss: 188.8661\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.5954 - val_loss: 187.7502\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.9096 - val_loss: 186.1738\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.3437 - val_loss: 184.4909\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.0845 - val_loss: 183.4392\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.8731 - val_loss: 182.2652\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.4608 - val_loss: 179.7365\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.2990 - val_loss: 178.7122\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.7966 - val_loss: 177.9109\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.5188 - val_loss: 176.2536\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.6250 - val_loss: 175.0258\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.0219 - val_loss: 174.8514\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.3643 - val_loss: 173.1162\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.9474 - val_loss: 171.7307\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.4348 - val_loss: 170.9563\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.3730 - val_loss: 170.1964\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.7707 - val_loss: 170.2449\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.7706 - val_loss: 168.5794\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.6829 - val_loss: 168.0113\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.0513 - val_loss: 167.6011\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.2049 - val_loss: 167.0273\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.6767 - val_loss: 166.3008\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.9208 - val_loss: 165.3153\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.3789 - val_loss: 164.9310\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.4930 - val_loss: 164.3952\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.8153 - val_loss: 163.6615\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.2662 - val_loss: 163.0114\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 169.8063 - val_loss: 162.6505\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1540.9227 - val_loss: 1472.3386\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1497.3656 - val_loss: 1420.6686\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1436.0037 - val_loss: 1346.4979\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1349.4009 - val_loss: 1245.9998\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1232.1078 - val_loss: 1119.0811\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1090.1246 - val_loss: 970.1178\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 925.7230 - val_loss: 806.4536\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 752.0274 - val_loss: 638.7823\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 583.9888 - val_loss: 485.7742\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 435.3166 - val_loss: 361.4250\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 325.6614 - val_loss: 277.6151\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 261.6759 - val_loss: 231.9755\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 228.3516 - val_loss: 215.1842\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 216.9262 - val_loss: 206.0146\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.1553 - val_loss: 201.2297\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 206.7761 - val_loss: 198.3936\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.7500 - val_loss: 195.5005\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.7576 - val_loss: 194.1111\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.1751 - val_loss: 192.5860\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.0585 - val_loss: 191.3898\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.4162 - val_loss: 189.4998\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.3465 - val_loss: 187.9617\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.4669 - val_loss: 186.6194\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.2810 - val_loss: 186.4993\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.9450 - val_loss: 184.3883\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.3348 - val_loss: 183.7509\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.6245 - val_loss: 182.8554\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.2128 - val_loss: 181.6610\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.6743 - val_loss: 180.9265\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.3674 - val_loss: 180.4306\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.9683 - val_loss: 179.2519\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.6548 - val_loss: 178.4062\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.4554 - val_loss: 177.6508\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.6225 - val_loss: 176.9809\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.1524 - val_loss: 175.9370\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.8849 - val_loss: 175.7603\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.2916 - val_loss: 174.3156\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.2429 - val_loss: 174.3125\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.5699 - val_loss: 174.0112\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.3360 - val_loss: 172.9228\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.1550 - val_loss: 172.5288\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.2864 - val_loss: 171.5382\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.2024 - val_loss: 171.3044\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.2443 - val_loss: 170.6117\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.2696 - val_loss: 169.8275\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.2186 - val_loss: 169.2087\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.1864 - val_loss: 169.0693\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.3725 - val_loss: 168.3696\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.1903 - val_loss: 167.8668\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.5048 - val_loss: 167.3243\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1557.1748 - val_loss: 1568.2238\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1508.9215 - val_loss: 1519.1776\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1454.4133 - val_loss: 1457.3016\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1383.2349 - val_loss: 1375.6158\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1287.2893 - val_loss: 1263.9358\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1158.7239 - val_loss: 1116.5941\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 997.9247 - val_loss: 941.5996\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 816.9264 - val_loss: 753.8327\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 634.7136 - val_loss: 571.3846\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 472.7214 - val_loss: 421.5457\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 352.3531 - val_loss: 320.2734\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 281.9001 - val_loss: 260.6960\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 246.5429 - val_loss: 232.3942\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 230.4629 - val_loss: 217.4380\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 221.2969 - val_loss: 209.7545\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 215.6409 - val_loss: 204.2632\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.5397 - val_loss: 200.3953\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.4406 - val_loss: 198.3806\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.3199 - val_loss: 195.8754\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.5557 - val_loss: 193.9183\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.1246 - val_loss: 192.1358\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.9018 - val_loss: 190.2895\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.9327 - val_loss: 189.3046\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.9232 - val_loss: 188.4749\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.2890 - val_loss: 187.0440\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.8512 - val_loss: 185.7793\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.2517 - val_loss: 185.1642\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.9550 - val_loss: 184.0059\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.7399 - val_loss: 183.4464\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.4634 - val_loss: 182.5856\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.2939 - val_loss: 181.3101\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.2203 - val_loss: 180.1840\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 181.1581 - val_loss: 179.5493\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.8197 - val_loss: 178.9127\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.9886 - val_loss: 178.1828\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.9586 - val_loss: 177.4000\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.8768 - val_loss: 176.4868\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.9973 - val_loss: 175.6553\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.1457 - val_loss: 175.3874\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.2535 - val_loss: 174.5008\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.2551 - val_loss: 173.7699\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 172.8013 - val_loss: 172.6921\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.6745 - val_loss: 172.7896\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.1141 - val_loss: 171.7080\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.3048 - val_loss: 171.2092\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.4315 - val_loss: 170.3444\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.7916 - val_loss: 169.8058\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.3513 - val_loss: 169.2826\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.4366 - val_loss: 168.4595\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.7579 - val_loss: 168.3517\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1466.8990 - val_loss: 1499.5576\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1407.0702 - val_loss: 1427.1212\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1330.4310 - val_loss: 1332.9578\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1230.3615 - val_loss: 1212.8813\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1103.0599 - val_loss: 1065.9813\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 951.8434 - val_loss: 896.7255\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 784.8328 - val_loss: 719.3197\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 614.5997 - val_loss: 553.4783\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 462.8030 - val_loss: 416.2686\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 344.5421 - val_loss: 323.9097\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 269.6970 - val_loss: 271.6816\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 228.6741 - val_loss: 248.5041\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.9073 - val_loss: 237.8882\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.4541 - val_loss: 232.3762\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.6046 - val_loss: 228.6679\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.1617 - val_loss: 225.2148\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.5372 - val_loss: 221.8719\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.7131 - val_loss: 219.7965\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.6058 - val_loss: 217.1858\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.4285 - val_loss: 214.4873\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.7198 - val_loss: 212.6315\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.1241 - val_loss: 210.4150\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.0665 - val_loss: 207.9361\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.1121 - val_loss: 207.6087\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.3213 - val_loss: 206.9241\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.9549 - val_loss: 205.7380\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.7878 - val_loss: 202.6569\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.7381 - val_loss: 201.5181\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.7707 - val_loss: 200.9989\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.8163 - val_loss: 200.0366\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.1122 - val_loss: 199.4819\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.0967 - val_loss: 198.3303\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.3558 - val_loss: 198.4148\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.4319 - val_loss: 195.9743\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.7441 - val_loss: 194.7632\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.7148 - val_loss: 194.2112\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.2708 - val_loss: 193.4857\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.4464 - val_loss: 192.7560\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.8003 - val_loss: 191.7248\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.1373 - val_loss: 190.9685\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.5777 - val_loss: 190.4500\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.1026 - val_loss: 190.4994\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.5916 - val_loss: 188.7982\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.0005 - val_loss: 188.6391\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.5450 - val_loss: 187.8291\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.0059 - val_loss: 186.4284\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.4901 - val_loss: 186.5713\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.3314 - val_loss: 185.6743\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.8981 - val_loss: 185.4671\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.1128 - val_loss: 184.7520\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1600.1047 - val_loss: 1536.5333\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1579.7175 - val_loss: 1519.5640\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1565.0011 - val_loss: 1504.0991\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1548.1257 - val_loss: 1484.3617\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1525.9347 - val_loss: 1459.5780\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1497.3940 - val_loss: 1425.8894\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1459.0421 - val_loss: 1381.7212\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1408.8582 - val_loss: 1323.4473\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1343.5375 - val_loss: 1249.9222\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1261.9547 - val_loss: 1159.0514\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1161.6431 - val_loss: 1051.0955\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1044.8026 - val_loss: 927.4512\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 914.0014 - val_loss: 793.5378\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 774.2614 - val_loss: 650.0773\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 627.6470 - val_loss: 504.1808\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 489.0005 - val_loss: 382.2719\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 380.9535 - val_loss: 292.6680\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 306.5681 - val_loss: 238.5231\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 263.2002 - val_loss: 209.8245\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 241.5646 - val_loss: 194.9406\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 229.6114 - val_loss: 188.8602\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 223.8424 - val_loss: 184.4526\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 219.2110 - val_loss: 181.7854\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 215.6920 - val_loss: 179.5528\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 213.0846 - val_loss: 177.4065\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 210.3784 - val_loss: 175.3714\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.7954 - val_loss: 174.1375\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.6619 - val_loss: 172.7173\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.8462 - val_loss: 171.2547\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.8487 - val_loss: 170.2885\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.5076 - val_loss: 168.9884\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.1126 - val_loss: 167.8157\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.2199 - val_loss: 166.7869\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.9258 - val_loss: 166.0121\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.6958 - val_loss: 164.8808\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.1183 - val_loss: 164.4287\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 191.7878 - val_loss: 164.0044\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.8838 - val_loss: 162.6605\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.3277 - val_loss: 162.4627\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.3583 - val_loss: 161.3240\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.1378 - val_loss: 160.8510\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.8921 - val_loss: 159.9252\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.9696 - val_loss: 159.4868\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.0322 - val_loss: 159.2828\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.8777 - val_loss: 157.9853\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.6481 - val_loss: 156.4752\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.0491 - val_loss: 156.8459\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.5034 - val_loss: 156.6884\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.5667 - val_loss: 156.2464\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.5699 - val_loss: 155.1796\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1533.2001 - val_loss: 1551.7952\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1493.7108 - val_loss: 1508.8589\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1444.8583 - val_loss: 1449.5206\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1373.1042 - val_loss: 1360.4165\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1271.1709 - val_loss: 1237.3877\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1132.5483 - val_loss: 1079.0380\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 964.7054 - val_loss: 891.5208\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 773.9940 - val_loss: 701.8353\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 592.8226 - val_loss: 523.4498\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 435.9705 - val_loss: 389.7657\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 325.8332 - val_loss: 307.1215\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 264.8523 - val_loss: 267.5498\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 234.9998 - val_loss: 248.0726\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 221.0663 - val_loss: 238.6748\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.5879 - val_loss: 231.2037\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.6214 - val_loss: 225.7558\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.5951 - val_loss: 220.5889\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.5073 - val_loss: 217.5642\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.8273 - val_loss: 213.7288\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.2914 - val_loss: 210.3961\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.9271 - val_loss: 207.6016\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.7149 - val_loss: 205.1576\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.4880 - val_loss: 202.9207\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.8243 - val_loss: 201.1633\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.1538 - val_loss: 199.4820\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.1456 - val_loss: 198.0424\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.4878 - val_loss: 196.0173\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.0165 - val_loss: 195.1184\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.7947 - val_loss: 194.4898\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.7413 - val_loss: 193.1057\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.7601 - val_loss: 191.4337\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.6049 - val_loss: 189.5525\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.9214 - val_loss: 189.3965\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.6414 - val_loss: 187.8954\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.0453 - val_loss: 186.5339\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.0231 - val_loss: 185.8049\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.0217 - val_loss: 185.3090\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 170.2191 - val_loss: 184.1635\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.3925 - val_loss: 183.1603\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.5389 - val_loss: 181.8209\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.9166 - val_loss: 181.6154\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.1314 - val_loss: 181.3274\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.4119 - val_loss: 179.0846\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.1809 - val_loss: 179.0865\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.3454 - val_loss: 178.7305\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.7296 - val_loss: 177.2282\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.8894 - val_loss: 176.7834\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.7184 - val_loss: 175.5385\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.1718 - val_loss: 173.9720\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.1594 - val_loss: 173.7619\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1553.1589 - val_loss: 1329.7100\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1492.2966 - val_loss: 1266.0150\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1408.3978 - val_loss: 1177.5283\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1292.8491 - val_loss: 1062.7051\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1148.4465 - val_loss: 921.8503\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 976.9623 - val_loss: 762.3678\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 789.9901 - val_loss: 595.8854\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 603.0330 - val_loss: 444.7317\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 441.5372 - val_loss: 328.2583\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 325.4919 - val_loss: 258.9310\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 260.9638 - val_loss: 227.7841\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 231.3719 - val_loss: 215.1996\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 218.3096 - val_loss: 209.0814\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 211.9154 - val_loss: 205.1517\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.8264 - val_loss: 202.1179\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.1799 - val_loss: 197.5570\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.9888 - val_loss: 194.7535\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.8764 - val_loss: 192.9812\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.4537 - val_loss: 190.0479\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.0409 - val_loss: 187.4989\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.8596 - val_loss: 186.5904\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.4197 - val_loss: 184.2470\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.1485 - val_loss: 183.3845\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.9188 - val_loss: 181.9440\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.1716 - val_loss: 180.9058\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.7094 - val_loss: 179.5005\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.4828 - val_loss: 178.4269\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.5265 - val_loss: 177.5561\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.1205 - val_loss: 176.2139\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.0205 - val_loss: 175.1960\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.9117 - val_loss: 175.1758\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.9370 - val_loss: 173.6760\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.0380 - val_loss: 173.8421\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.5357 - val_loss: 172.5739\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.2466 - val_loss: 171.7948\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.4570 - val_loss: 171.0751\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.4787 - val_loss: 170.6508\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.7868 - val_loss: 169.7263\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.7656 - val_loss: 169.3183\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.1736 - val_loss: 168.8077\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 168.4179 - val_loss: 167.8942\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.8080 - val_loss: 167.6981\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.9706 - val_loss: 167.0535\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.3188 - val_loss: 166.2171\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.6068 - val_loss: 165.8265\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.5424 - val_loss: 166.0625\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.3907 - val_loss: 164.5174\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.8220 - val_loss: 164.1232\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.2000 - val_loss: 163.6371\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.8841 - val_loss: 163.0950\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1533.2802 - val_loss: 1555.5361\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1493.6827 - val_loss: 1513.1459\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1446.0892 - val_loss: 1458.9495\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1382.0957 - val_loss: 1383.8611\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1294.8718 - val_loss: 1283.9929\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1181.7969 - val_loss: 1159.3281\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1046.5190 - val_loss: 1012.7523\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 893.5050 - val_loss: 850.2251\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 730.9688 - val_loss: 687.0933\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 573.4697 - val_loss: 536.3086\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 439.7064 - val_loss: 409.5927\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 337.4791 - val_loss: 323.6346\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 275.3957 - val_loss: 270.5462\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 241.8268 - val_loss: 244.4617\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 227.0184 - val_loss: 228.9935\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 219.1752 - val_loss: 221.7134\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.8859 - val_loss: 216.6156\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.9429 - val_loss: 213.0322\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 206.6623 - val_loss: 208.1681\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.4124 - val_loss: 206.1077\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.5078 - val_loss: 202.5853\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.0988 - val_loss: 200.9183\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.4971 - val_loss: 198.3652\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.3192 - val_loss: 196.9962\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.3929 - val_loss: 195.4797\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.3593 - val_loss: 193.3925\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.5618 - val_loss: 190.6824\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.8337 - val_loss: 189.3591\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.9697 - val_loss: 188.4670\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.6429 - val_loss: 187.1799\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.1057 - val_loss: 185.5895\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.5416 - val_loss: 184.4933\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.1360 - val_loss: 183.5782\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.9396 - val_loss: 181.5948\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.3750 - val_loss: 180.8009\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.3566 - val_loss: 179.9051\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.2159 - val_loss: 178.8914\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 172.1437 - val_loss: 178.3321\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.3347 - val_loss: 177.0174\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 170.3610 - val_loss: 176.5264\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.2580 - val_loss: 175.3719\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.4710 - val_loss: 175.0513\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.3424 - val_loss: 174.4413\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 166.2639 - val_loss: 173.1047\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.6287 - val_loss: 172.0619\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 164.8399 - val_loss: 172.7584\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.0338 - val_loss: 171.0642\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 163.0264 - val_loss: 170.7657\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.3650 - val_loss: 170.0178\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.6805 - val_loss: 169.5816\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1524.8202 - val_loss: 1519.7306\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1465.1353 - val_loss: 1456.0470\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1389.7379 - val_loss: 1370.6193\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1285.8823 - val_loss: 1252.3210\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1147.0004 - val_loss: 1103.3347\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 979.9105 - val_loss: 935.1927\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 801.3445 - val_loss: 756.3762\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 624.4514 - val_loss: 589.3416\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 473.3528 - val_loss: 450.2625\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 361.0558 - val_loss: 354.1978\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 290.0941 - val_loss: 296.3049\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 254.2459 - val_loss: 259.2137\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 236.1441 - val_loss: 239.5838\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 226.7625 - val_loss: 227.6273\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 220.5919 - val_loss: 218.7881\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 215.4559 - val_loss: 213.1624\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.2972 - val_loss: 208.2849\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.2622 - val_loss: 204.6641\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.1561 - val_loss: 200.8166\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 201.0029 - val_loss: 198.2573\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.2409 - val_loss: 195.8760\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.5879 - val_loss: 192.8098\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.1806 - val_loss: 191.9530\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.1224 - val_loss: 190.1945\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.9574 - val_loss: 187.9854\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.3810 - val_loss: 185.9300\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.6360 - val_loss: 184.8778\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.0881 - val_loss: 183.4449\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.4049 - val_loss: 181.6003\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.0203 - val_loss: 180.9747\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.7056 - val_loss: 180.3026\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.2225 - val_loss: 178.6370\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.1684 - val_loss: 177.7306\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.7606 - val_loss: 176.4629\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.8241 - val_loss: 175.8855\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.5301 - val_loss: 175.6307\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.0118 - val_loss: 174.7917\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.5465 - val_loss: 172.8686\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.5085 - val_loss: 172.2164\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.5290 - val_loss: 170.3795\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.7935 - val_loss: 169.8953\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.6429 - val_loss: 170.5539\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.6274 - val_loss: 169.5045\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.2601 - val_loss: 168.8978\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.2840 - val_loss: 166.7338\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.4985 - val_loss: 166.4973\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.1266 - val_loss: 165.9479\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.1770 - val_loss: 164.5778\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.7066 - val_loss: 164.1220\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.7240 - val_loss: 162.9816\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1509.4542 - val_loss: 1471.0297\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1454.1733 - val_loss: 1408.7356\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1380.0930 - val_loss: 1323.3729\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1284.7994 - val_loss: 1212.3405\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1161.4230 - val_loss: 1080.8827\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1016.7828 - val_loss: 925.0417\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 851.0280 - val_loss: 755.3162\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 677.1854 - val_loss: 581.4905\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 511.9685 - val_loss: 426.6382\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 374.9950 - val_loss: 317.1568\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 287.8941 - val_loss: 252.0483\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 243.1853 - val_loss: 220.7886\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 221.8755 - val_loss: 208.2875\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.0000 - val_loss: 202.6558\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.9341 - val_loss: 198.6245\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.9008 - val_loss: 195.9250\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.5273 - val_loss: 193.8419\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.9803 - val_loss: 192.1537\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.7346 - val_loss: 190.8545\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.7833 - val_loss: 189.6109\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.1204 - val_loss: 188.2302\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.8400 - val_loss: 187.4313\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.4341 - val_loss: 186.0568\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.9631 - val_loss: 185.1689\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.7552 - val_loss: 184.2828\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.6454 - val_loss: 183.6241\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.6846 - val_loss: 182.3535\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.4971 - val_loss: 181.6824\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.8610 - val_loss: 180.5915\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.6875 - val_loss: 179.3796\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.0126 - val_loss: 178.7285\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.9961 - val_loss: 177.4356\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.2586 - val_loss: 176.6362\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.3218 - val_loss: 175.4442\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.6098 - val_loss: 174.9297\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.7616 - val_loss: 173.9854\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.2069 - val_loss: 173.6033\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.3510 - val_loss: 173.2057\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.1510 - val_loss: 172.1145\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.8095 - val_loss: 171.6838\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.2252 - val_loss: 170.7169\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.3833 - val_loss: 170.2089\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.7834 - val_loss: 169.9936\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.1831 - val_loss: 169.3008\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.7544 - val_loss: 168.1115\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.5149 - val_loss: 167.7533\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.7485 - val_loss: 167.3102\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.0841 - val_loss: 167.3339\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.5233 - val_loss: 166.2366\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.7193 - val_loss: 165.4999\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1622.5776 - val_loss: 1412.4010\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1586.3613 - val_loss: 1381.1090\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1551.5121 - val_loss: 1345.4283\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1507.2292 - val_loss: 1297.1490\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1446.8566 - val_loss: 1231.0579\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1366.5164 - val_loss: 1145.3046\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1265.3606 - val_loss: 1036.9631\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1138.6198 - val_loss: 910.1334\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 991.4289 - val_loss: 767.4626\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 829.3195 - val_loss: 620.1281\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 668.3434 - val_loss: 478.7646\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 519.2330 - val_loss: 361.6769\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 400.3360 - val_loss: 277.4621\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 315.4524 - val_loss: 230.3599\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 265.4393 - val_loss: 206.8194\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 239.3578 - val_loss: 198.0810\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 227.0878 - val_loss: 195.5170\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 220.4376 - val_loss: 193.5479\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 216.3276 - val_loss: 191.4588\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.9574 - val_loss: 190.1411\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 210.2429 - val_loss: 188.2215\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.2549 - val_loss: 185.9601\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.0210 - val_loss: 184.2176\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.5657 - val_loss: 183.2962\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.2828 - val_loss: 181.8779\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.2438 - val_loss: 180.1920\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.1702 - val_loss: 179.5172\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.4174 - val_loss: 177.9140\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.8645 - val_loss: 175.9748\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.0259 - val_loss: 175.8315\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.6289 - val_loss: 174.8333\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.1794 - val_loss: 173.5442\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.8746 - val_loss: 172.4174\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.3654 - val_loss: 172.1559\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.0296 - val_loss: 171.1385\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.8862 - val_loss: 169.5078\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.4272 - val_loss: 169.5739\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.2497 - val_loss: 168.5384\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.0489 - val_loss: 168.0275\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.9769 - val_loss: 166.7059\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.7794 - val_loss: 166.6820\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.7959 - val_loss: 166.4976\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.7405 - val_loss: 165.7733\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.9830 - val_loss: 164.8147\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.8665 - val_loss: 164.5719\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.7756 - val_loss: 163.8467\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.9413 - val_loss: 163.1373\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.7176 - val_loss: 163.0896\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.8477 - val_loss: 161.8846\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.0350 - val_loss: 162.1361\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1463.8993 - val_loss: 1465.6415\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1380.7430 - val_loss: 1367.9072\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1265.6141 - val_loss: 1232.5734\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1118.3463 - val_loss: 1072.4729\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 949.7028 - val_loss: 891.5160\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 768.1140 - val_loss: 703.6882\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 590.5881 - val_loss: 529.0647\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 437.0337 - val_loss: 397.0628\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 329.3737 - val_loss: 309.6141\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 263.9485 - val_loss: 269.7491\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 235.6631 - val_loss: 250.6014\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 222.4713 - val_loss: 241.9777\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 215.9209 - val_loss: 235.8416\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 211.2065 - val_loss: 231.5426\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.5163 - val_loss: 227.0502\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.3280 - val_loss: 224.1932\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.5047 - val_loss: 220.1650\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.0116 - val_loss: 217.9734\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.2410 - val_loss: 213.9526\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.8587 - val_loss: 211.3364\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.0496 - val_loss: 209.6275\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.0476 - val_loss: 207.3415\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.3884 - val_loss: 205.1458\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.6869 - val_loss: 203.2062\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.0413 - val_loss: 201.4098\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.7646 - val_loss: 200.3369\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.1836 - val_loss: 198.2227\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.7707 - val_loss: 196.5857\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.5762 - val_loss: 195.1879\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.0161 - val_loss: 193.5198\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.8949 - val_loss: 192.1779\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.7484 - val_loss: 191.1052\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.7588 - val_loss: 189.2346\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.6447 - val_loss: 188.3692\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.4146 - val_loss: 187.6162\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.1491 - val_loss: 186.0449\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.2859 - val_loss: 184.6028\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.4778 - val_loss: 184.4769\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.9126 - val_loss: 183.6578\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.7224 - val_loss: 181.8293\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.6440 - val_loss: 181.2044\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.7648 - val_loss: 180.2457\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.7574 - val_loss: 179.8991\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.2405 - val_loss: 178.4920\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.1453 - val_loss: 177.6961\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.5583 - val_loss: 177.6513\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.8126 - val_loss: 176.4243\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.7841 - val_loss: 175.5849\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.5762 - val_loss: 174.6996\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.9520 - val_loss: 173.8670\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1475.8392 - val_loss: 1519.4006\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1423.4496 - val_loss: 1455.1213\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1343.0358 - val_loss: 1357.1704\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1227.3743 - val_loss: 1223.3829\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1078.5447 - val_loss: 1055.8221\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 905.4489 - val_loss: 868.9179\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 726.4332 - val_loss: 683.2730\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 563.4832 - val_loss: 519.3419\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 430.2325 - val_loss: 388.3104\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 332.6371 - val_loss: 299.7454\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 271.5908 - val_loss: 250.5320\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 236.0974 - val_loss: 229.2403\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 219.1506 - val_loss: 220.0067\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.5485 - val_loss: 215.6548\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.1866 - val_loss: 213.0617\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.2888 - val_loss: 210.5160\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.7447 - val_loss: 208.5939\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.2495 - val_loss: 207.0977\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.7392 - val_loss: 205.1374\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.5343 - val_loss: 203.1646\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.6080 - val_loss: 201.7777\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.7643 - val_loss: 200.3242\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.4874 - val_loss: 199.4100\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.6189 - val_loss: 197.2080\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.0916 - val_loss: 195.4215\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.5019 - val_loss: 194.4087\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.3884 - val_loss: 193.1628\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.8710 - val_loss: 192.3112\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.9898 - val_loss: 190.6346\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.3407 - val_loss: 190.0415\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 172.3957 - val_loss: 189.4968\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.1333 - val_loss: 187.3854\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.3924 - val_loss: 186.2885\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.1092 - val_loss: 186.0650\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.3315 - val_loss: 184.7157\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.3630 - val_loss: 183.7808\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.2488 - val_loss: 183.4639\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.3236 - val_loss: 182.6379\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.6518 - val_loss: 181.4523\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.7319 - val_loss: 180.9450\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.0259 - val_loss: 180.7310\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.0184 - val_loss: 179.6906\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.4303 - val_loss: 179.2302\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.4721 - val_loss: 178.6133\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.9026 - val_loss: 177.6035\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.2145 - val_loss: 177.1527\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.3932 - val_loss: 176.2827\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.8444 - val_loss: 176.0578\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.9141 - val_loss: 175.6720\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 156.2068 - val_loss: 174.4897\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1488.4747 - val_loss: 1603.9656\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1456.2046 - val_loss: 1563.5708\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1413.8900 - val_loss: 1507.7252\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1356.3624 - val_loss: 1431.9000\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1278.9218 - val_loss: 1330.6567\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1178.0842 - val_loss: 1204.2697\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1055.0848 - val_loss: 1051.1483\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 912.3531 - val_loss: 879.9265\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 754.7451 - val_loss: 708.2325\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 603.4717 - val_loss: 543.3881\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 465.4496 - val_loss: 411.6209\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 358.0699 - val_loss: 320.3697\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 284.7038 - val_loss: 267.8327\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 242.6619 - val_loss: 243.1709\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 221.2548 - val_loss: 233.9435\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.8935 - val_loss: 229.8597\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 206.3390 - val_loss: 227.1261\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.7274 - val_loss: 223.9629\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.5849 - val_loss: 221.9515\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.0931 - val_loss: 219.0079\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.0926 - val_loss: 217.3474\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.1476 - val_loss: 214.3186\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.1118 - val_loss: 213.1915\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.3937 - val_loss: 211.0311\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.9268 - val_loss: 209.9617\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.5379 - val_loss: 207.6423\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.3930 - val_loss: 207.0005\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.0239 - val_loss: 204.7448\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.5724 - val_loss: 203.6097\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.5954 - val_loss: 201.8861\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.4272 - val_loss: 201.1101\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.5650 - val_loss: 199.8181\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.8890 - val_loss: 199.3894\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.6550 - val_loss: 197.3636\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.6377 - val_loss: 196.7348\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.9036 - val_loss: 195.5336\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.9174 - val_loss: 194.2444\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.0158 - val_loss: 193.0202\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.4700 - val_loss: 192.4162\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.2565 - val_loss: 191.8883\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.6405 - val_loss: 191.1344\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.8288 - val_loss: 189.8785\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.1948 - val_loss: 188.8882\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.3313 - val_loss: 188.2700\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.9013 - val_loss: 187.6723\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.3936 - val_loss: 187.3157\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.5749 - val_loss: 185.9109\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.7900 - val_loss: 185.6629\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.4075 - val_loss: 184.8270\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.8083 - val_loss: 184.4163\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1528.5609 - val_loss: 1643.1176\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1499.5009 - val_loss: 1617.1760\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1473.1144 - val_loss: 1589.2843\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1442.6589 - val_loss: 1554.6149\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1404.5112 - val_loss: 1512.0889\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1357.7911 - val_loss: 1458.5975\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1298.7833 - val_loss: 1393.6046\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1227.5109 - val_loss: 1314.0292\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1142.2968 - val_loss: 1218.5065\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1042.1224 - val_loss: 1109.9141\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 930.9201 - val_loss: 987.0709\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 809.9903 - val_loss: 858.0847\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 686.0878 - val_loss: 728.1454\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 569.7535 - val_loss: 601.9929\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 463.5626 - val_loss: 492.7640\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 375.5761 - val_loss: 402.6929\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.9649 - val_loss: 336.9680\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 261.4919 - val_loss: 293.6346\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 232.8467 - val_loss: 266.2745\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 215.4179 - val_loss: 251.0701\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 206.7081 - val_loss: 242.0444\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 200.4717 - val_loss: 236.9746\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.8118 - val_loss: 233.3147\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.7644 - val_loss: 229.9477\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.5889 - val_loss: 226.8521\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.4481 - val_loss: 224.4142\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.5113 - val_loss: 222.0939\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.7659 - val_loss: 220.0314\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.3158 - val_loss: 217.7528\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.6780 - val_loss: 215.5132\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.2613 - val_loss: 213.7695\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.7810 - val_loss: 211.9284\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.3363 - val_loss: 210.0998\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.0169 - val_loss: 208.4813\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.9135 - val_loss: 206.5257\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 174.8121 - val_loss: 205.0648\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.5395 - val_loss: 203.6910\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.5745 - val_loss: 202.3448\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.7296 - val_loss: 200.8557\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.7243 - val_loss: 199.3862\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.5813 - val_loss: 198.3224\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 168.9265 - val_loss: 196.9255\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.8939 - val_loss: 195.9037\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 167.0165 - val_loss: 194.9105\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.3319 - val_loss: 193.6129\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.3524 - val_loss: 192.4171\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.5956 - val_loss: 191.2998\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 163.8044 - val_loss: 190.1925\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.1328 - val_loss: 188.9695\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.6497 - val_loss: 187.9364\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 9ms/step - loss: 1551.2491 - val_loss: 1606.4952\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1525.5884 - val_loss: 1576.8962\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1493.2516 - val_loss: 1537.9208\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1448.4778 - val_loss: 1482.3640\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1384.3990 - val_loss: 1402.7450\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1294.6625 - val_loss: 1295.7800\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1176.5283 - val_loss: 1159.9214\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1031.5554 - val_loss: 998.5060\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 864.4324 - val_loss: 823.1723\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 692.3597 - val_loss: 646.9428\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 528.2930 - val_loss: 497.9034\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 397.8442 - val_loss: 380.6450\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 308.8951 - val_loss: 304.0624\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 253.2421 - val_loss: 263.6060\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 226.7203 - val_loss: 240.3614\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.6019 - val_loss: 228.2817\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.6160 - val_loss: 221.3671\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.3634 - val_loss: 216.9155\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.1421 - val_loss: 213.5574\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.2416 - val_loss: 210.4139\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.9364 - val_loss: 208.3438\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.1730 - val_loss: 205.9612\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.7473 - val_loss: 203.8260\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.6963 - val_loss: 201.8174\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.2658 - val_loss: 200.5251\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.9785 - val_loss: 198.7447\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.4915 - val_loss: 197.3827\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.5477 - val_loss: 195.5733\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 181.3668 - val_loss: 194.8392\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.0163 - val_loss: 193.4698\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.3683 - val_loss: 192.0281\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.8998 - val_loss: 190.6176\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.1376 - val_loss: 189.9884\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.0275 - val_loss: 188.5978\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.1242 - val_loss: 187.5576\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.2452 - val_loss: 186.9048\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.2851 - val_loss: 185.5725\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.4864 - val_loss: 184.5861\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.5296 - val_loss: 183.4729\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.7016 - val_loss: 182.6855\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.9516 - val_loss: 181.8654\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.6423 - val_loss: 181.0918\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.9257 - val_loss: 180.5199\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.0435 - val_loss: 179.5185\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.4281 - val_loss: 179.0115\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.7165 - val_loss: 178.0718\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.0006 - val_loss: 177.2115\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.6376 - val_loss: 176.5791\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.8924 - val_loss: 176.0262\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.3600 - val_loss: 175.6460\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1539.8354 - val_loss: 1442.1372\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1469.8151 - val_loss: 1362.0902\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1381.1436 - val_loss: 1260.8867\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1268.0366 - val_loss: 1132.9036\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1126.0105 - val_loss: 977.9503\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 958.4674 - val_loss: 802.4315\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 771.6376 - val_loss: 619.3716\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 583.5500 - val_loss: 456.6275\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 428.0118 - val_loss: 329.7093\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 316.2322 - val_loss: 254.0214\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 256.4622 - val_loss: 215.8293\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 228.2570 - val_loss: 203.1732\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 217.5559 - val_loss: 198.3434\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 211.7333 - val_loss: 194.9260\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.4166 - val_loss: 193.1996\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.9975 - val_loss: 191.4671\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.3164 - val_loss: 189.3600\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.9780 - val_loss: 188.0121\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.8758 - val_loss: 186.6883\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.8775 - val_loss: 185.7096\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.0113 - val_loss: 184.6771\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.7536 - val_loss: 183.8414\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.3645 - val_loss: 182.9159\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.6237 - val_loss: 182.1790\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.1507 - val_loss: 181.3249\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.6042 - val_loss: 180.5941\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.2048 - val_loss: 179.5279\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.8093 - val_loss: 179.0073\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.7132 - val_loss: 178.1816\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.4667 - val_loss: 177.5747\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.5860 - val_loss: 177.0748\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.6489 - val_loss: 176.6069\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.5045 - val_loss: 176.0922\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.6662 - val_loss: 175.2313\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.8192 - val_loss: 174.4264\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.5474 - val_loss: 174.1036\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.9529 - val_loss: 173.7383\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.5114 - val_loss: 172.7467\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.4246 - val_loss: 172.2768\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.4089 - val_loss: 171.5045\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.5216 - val_loss: 171.0414\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.7797 - val_loss: 170.6092\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.0614 - val_loss: 169.6579\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.2669 - val_loss: 169.1680\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.3066 - val_loss: 168.3888\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.8570 - val_loss: 167.8038\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.9927 - val_loss: 166.8711\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.0724 - val_loss: 166.6352\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.6956 - val_loss: 165.9596\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.7604 - val_loss: 165.2581\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1513.3639 - val_loss: 1627.0585\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1480.9152 - val_loss: 1591.0701\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1440.6674 - val_loss: 1541.9521\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1387.2135 - val_loss: 1478.2977\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1318.7217 - val_loss: 1395.9456\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1229.1874 - val_loss: 1291.1200\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1117.8704 - val_loss: 1159.9784\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 983.3181 - val_loss: 1010.7227\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 834.7411 - val_loss: 848.3876\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 679.3553 - val_loss: 681.0414\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 526.0989 - val_loss: 519.0807\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 388.6895 - val_loss: 386.9494\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 286.3540 - val_loss: 297.3609\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 228.3911 - val_loss: 251.5386\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.2915 - val_loss: 231.5076\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.6421 - val_loss: 223.5911\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.0965 - val_loss: 219.4686\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.2655 - val_loss: 216.8049\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.1793 - val_loss: 213.6402\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 185.1951 - val_loss: 211.6527\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.2744 - val_loss: 209.5532\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.5669 - val_loss: 207.8399\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.0811 - val_loss: 205.3701\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.6986 - val_loss: 203.4200\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.7118 - val_loss: 201.1245\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.2713 - val_loss: 199.5336\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.1391 - val_loss: 198.2039\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.9878 - val_loss: 196.7658\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.5880 - val_loss: 194.7967\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.5822 - val_loss: 193.1707\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.7308 - val_loss: 192.7365\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.5849 - val_loss: 190.0732\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.6333 - val_loss: 188.5616\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.5994 - val_loss: 188.1906\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.4245 - val_loss: 187.3966\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.0489 - val_loss: 185.3440\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.6584 - val_loss: 184.9846\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.0077 - val_loss: 183.7667\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.0028 - val_loss: 182.9389\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.2267 - val_loss: 182.0206\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.3329 - val_loss: 180.5523\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.5756 - val_loss: 179.8307\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.0246 - val_loss: 179.0688\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.1358 - val_loss: 178.0945\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4819 - val_loss: 176.7487\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.6595 - val_loss: 176.6502\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.0760 - val_loss: 176.6087\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.2523 - val_loss: 174.7317\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.5780 - val_loss: 174.3053\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.9675 - val_loss: 172.8145\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1545.7661 - val_loss: 1452.6742\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1499.7867 - val_loss: 1404.7081\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1442.6732 - val_loss: 1342.5953\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1370.0125 - val_loss: 1264.1908\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1279.4802 - val_loss: 1168.3175\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1168.9319 - val_loss: 1052.6263\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1038.6313 - val_loss: 917.6808\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 890.4200 - val_loss: 772.0870\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 735.6370 - val_loss: 625.0397\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 585.0345 - val_loss: 488.5140\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 452.8284 - val_loss: 376.0600\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 350.5522 - val_loss: 294.5535\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 281.8914 - val_loss: 241.7889\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 241.3682 - val_loss: 215.7641\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 221.2581 - val_loss: 202.9370\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.5909 - val_loss: 195.7909\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 206.6690 - val_loss: 192.3708\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.4690 - val_loss: 189.6965\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.8493 - val_loss: 187.3092\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.2659 - val_loss: 185.6154\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.3661 - val_loss: 183.9203\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.4956 - val_loss: 182.5317\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.7820 - val_loss: 181.1478\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.1822 - val_loss: 179.5355\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.4520 - val_loss: 178.0510\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.9111 - val_loss: 176.9460\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.6989 - val_loss: 175.5636\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.2213 - val_loss: 174.5284\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.0070 - val_loss: 173.7141\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.5455 - val_loss: 172.4045\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.8944 - val_loss: 171.5836\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.3843 - val_loss: 170.6331\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 179.5830 - val_loss: 169.6816\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.2469 - val_loss: 168.6309\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.2341 - val_loss: 167.8609\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.2814 - val_loss: 166.9219\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.4552 - val_loss: 166.0969\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.2494 - val_loss: 165.1776\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.4068 - val_loss: 164.3880\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.6922 - val_loss: 163.7786\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.8329 - val_loss: 163.2793\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.0293 - val_loss: 162.2857\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.1777 - val_loss: 161.6212\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.8665 - val_loss: 160.6345\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.6449 - val_loss: 160.4728\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.1699 - val_loss: 159.5537\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.2194 - val_loss: 158.8500\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.4116 - val_loss: 158.6268\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.9163 - val_loss: 157.9726\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.0955 - val_loss: 157.1341\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1529.0754 - val_loss: 1466.5121\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1477.1035 - val_loss: 1411.2469\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1412.6812 - val_loss: 1336.2874\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1324.3964 - val_loss: 1232.9600\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1208.8273 - val_loss: 1103.5565\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1065.8066 - val_loss: 953.2975\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 904.9957 - val_loss: 787.0302\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 733.9978 - val_loss: 624.4908\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 572.0875 - val_loss: 477.4469\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 432.5818 - val_loss: 363.7648\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 331.4054 - val_loss: 285.8065\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 268.2294 - val_loss: 243.6290\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 236.2012 - val_loss: 223.3497\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 221.9146 - val_loss: 213.6678\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 214.7499 - val_loss: 208.1214\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 209.9625 - val_loss: 203.8908\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 206.2671 - val_loss: 201.3337\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.5500 - val_loss: 199.0174\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.1222 - val_loss: 196.0217\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.3720 - val_loss: 193.7677\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.8109 - val_loss: 192.2502\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.9779 - val_loss: 190.8320\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.9716 - val_loss: 189.1863\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.9645 - val_loss: 187.7926\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.2787 - val_loss: 186.5321\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.8700 - val_loss: 185.7073\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.7998 - val_loss: 184.4137\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.9920 - val_loss: 183.4165\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.5447 - val_loss: 183.0583\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.1692 - val_loss: 182.2923\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.9588 - val_loss: 181.4465\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.7359 - val_loss: 180.4592\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.7393 - val_loss: 179.8581\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.8564 - val_loss: 178.5233\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.6429 - val_loss: 177.9730\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.2026 - val_loss: 177.6863\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.9404 - val_loss: 177.1411\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.2819 - val_loss: 176.7632\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.3089 - val_loss: 175.2617\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.6032 - val_loss: 174.8732\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.7783 - val_loss: 174.6007\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.5032 - val_loss: 174.4415\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.8822 - val_loss: 173.3846\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.8710 - val_loss: 173.8457\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.5190 - val_loss: 172.4611\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.2246 - val_loss: 173.9696\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.4151 - val_loss: 171.9074\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.4586 - val_loss: 172.1673\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.0461 - val_loss: 171.9719\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.4943 - val_loss: 171.4986\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1550.3618 - val_loss: 1492.6710\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1509.0842 - val_loss: 1445.9310\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1449.0931 - val_loss: 1378.4832\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1364.9580 - val_loss: 1282.9066\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1248.8223 - val_loss: 1154.0255\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1099.0830 - val_loss: 1001.5032\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 926.6069 - val_loss: 830.5358\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 746.2911 - val_loss: 656.1331\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 571.2489 - val_loss: 500.9737\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 425.5963 - val_loss: 379.1385\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 321.9464 - val_loss: 299.3599\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 260.8574 - val_loss: 255.8204\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 233.1514 - val_loss: 234.1196\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 219.5649 - val_loss: 224.6129\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.3787 - val_loss: 219.9145\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.5383 - val_loss: 214.6232\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.6716 - val_loss: 211.6711\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.2971 - val_loss: 208.6817\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.4742 - val_loss: 206.9431\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.8573 - val_loss: 204.7874\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.3868 - val_loss: 202.8810\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.4811 - val_loss: 200.6642\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.1170 - val_loss: 199.6390\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.3429 - val_loss: 197.9155\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.7775 - val_loss: 196.6385\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.1532 - val_loss: 194.8646\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.7488 - val_loss: 194.2691\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.3297 - val_loss: 193.5127\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.0433 - val_loss: 192.6551\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.9860 - val_loss: 191.4442\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.4620 - val_loss: 190.1367\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.3714 - val_loss: 188.8823\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.2699 - val_loss: 188.0441\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 173.2111 - val_loss: 187.3650\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.1439 - val_loss: 185.6366\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.2970 - val_loss: 185.2514\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.9805 - val_loss: 184.3185\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.5808 - val_loss: 183.1278\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.1627 - val_loss: 182.2654\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.3335 - val_loss: 182.0010\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.5371 - val_loss: 180.9992\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.5190 - val_loss: 179.9207\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 164.5617 - val_loss: 178.7547\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.6368 - val_loss: 177.5052\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.6979 - val_loss: 176.7644\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.2013 - val_loss: 175.8612\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.1621 - val_loss: 175.2877\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.3651 - val_loss: 173.9848\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.3515 - val_loss: 173.5509\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.8304 - val_loss: 173.1326\n",
      "10/10 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1562.8568 - val_loss: 1461.5671\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1525.2349 - val_loss: 1421.0049\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1471.8882 - val_loss: 1362.1926\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1399.8553 - val_loss: 1285.4409\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1307.6774 - val_loss: 1185.7515\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1189.8844 - val_loss: 1064.0270\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1048.7695 - val_loss: 920.0557\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 890.6027 - val_loss: 763.0408\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 724.3252 - val_loss: 606.9528\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 569.3700 - val_loss: 469.5780\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 444.7899 - val_loss: 359.4247\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 352.6683 - val_loss: 287.6221\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 292.8441 - val_loss: 246.3212\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 259.8582 - val_loss: 224.1411\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 241.8091 - val_loss: 213.9993\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 231.9337 - val_loss: 208.5385\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 225.4378 - val_loss: 204.6265\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 220.0230 - val_loss: 201.2617\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 215.6062 - val_loss: 198.2480\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 211.8921 - val_loss: 195.8573\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.6785 - val_loss: 193.2298\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.5691 - val_loss: 191.5527\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.8171 - val_loss: 189.6226\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.0925 - val_loss: 188.5463\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.0581 - val_loss: 187.4100\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.8171 - val_loss: 185.5968\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.9837 - val_loss: 184.1844\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.1181 - val_loss: 183.6894\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.0608 - val_loss: 182.4706\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.6285 - val_loss: 180.8270\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.9875 - val_loss: 180.0122\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.3006 - val_loss: 178.7873\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.8766 - val_loss: 178.0100\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.6840 - val_loss: 177.4476\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.2363 - val_loss: 177.5412\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.1990 - val_loss: 176.4049\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.1477 - val_loss: 175.9661\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.9135 - val_loss: 174.8648\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.9680 - val_loss: 174.3076\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.0088 - val_loss: 173.1144\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.2191 - val_loss: 172.7447\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.0767 - val_loss: 171.9433\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.4586 - val_loss: 171.1102\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.4218 - val_loss: 170.3879\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.7178 - val_loss: 169.6553\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.8170 - val_loss: 169.2740\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.9675 - val_loss: 168.2676\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.3369 - val_loss: 167.4085\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.5849 - val_loss: 167.1287\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.9240 - val_loss: 166.9401\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1507.2809 - val_loss: 1638.1493\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1462.7542 - val_loss: 1586.6385\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1406.9097 - val_loss: 1520.5681\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1334.6268 - val_loss: 1428.0935\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1235.8240 - val_loss: 1306.3489\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1109.4510 - val_loss: 1158.8451\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 960.6085 - val_loss: 983.8677\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 791.6379 - val_loss: 799.1026\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 621.6684 - val_loss: 616.3326\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 467.2686 - val_loss: 456.5825\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 347.4380 - val_loss: 340.1708\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 271.6555 - val_loss: 267.3701\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 231.3958 - val_loss: 233.4668\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 215.3392 - val_loss: 216.4921\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.1285 - val_loss: 206.9525\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.6841 - val_loss: 202.2490\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.7454 - val_loss: 199.3764\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.6434 - val_loss: 196.4619\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.7370 - val_loss: 192.9441\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.6949 - val_loss: 191.9098\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.8095 - val_loss: 189.6617\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.3755 - val_loss: 188.4711\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.7628 - val_loss: 187.6177\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.1696 - val_loss: 184.2547\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.7887 - val_loss: 183.0580\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.6290 - val_loss: 181.5712\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.8945 - val_loss: 180.6854\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.7336 - val_loss: 179.6797\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.6761 - val_loss: 177.8371\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.6440 - val_loss: 177.1602\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.4402 - val_loss: 175.0931\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.8493 - val_loss: 174.7531\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.8414 - val_loss: 173.1319\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.7363 - val_loss: 171.5755\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.8982 - val_loss: 169.8373\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.7935 - val_loss: 169.7488\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.6458 - val_loss: 168.4093\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.5992 - val_loss: 167.8458\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.7032 - val_loss: 167.6253\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.5884 - val_loss: 165.9729\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.8288 - val_loss: 164.5587\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.2611 - val_loss: 164.3785\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.1990 - val_loss: 162.8207\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.0406 - val_loss: 161.5749\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.4790 - val_loss: 161.4229\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.8660 - val_loss: 159.5400\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.4614 - val_loss: 160.2323\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.7597 - val_loss: 158.8858\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.0002 - val_loss: 157.5898\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.0695 - val_loss: 157.6832\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1515.0157 - val_loss: 1490.2338\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1464.7463 - val_loss: 1429.3038\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1395.9738 - val_loss: 1349.3773\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1305.6987 - val_loss: 1242.1827\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1187.6398 - val_loss: 1107.2725\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1045.8577 - val_loss: 956.5211\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 888.3879 - val_loss: 792.6470\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 721.9703 - val_loss: 624.9856\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 561.2797 - val_loss: 469.7319\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 425.0966 - val_loss: 348.4034\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 323.9698 - val_loss: 274.0088\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 265.5124 - val_loss: 232.7760\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 235.7597 - val_loss: 214.7494\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 223.5804 - val_loss: 207.6273\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 217.1682 - val_loss: 204.2549\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.5771 - val_loss: 201.6442\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.3808 - val_loss: 198.8733\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.8268 - val_loss: 195.6984\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.2537 - val_loss: 193.8092\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.3333 - val_loss: 191.8901\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.2128 - val_loss: 189.9152\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.5030 - val_loss: 188.5246\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.7367 - val_loss: 186.1536\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.9914 - val_loss: 184.7083\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.4826 - val_loss: 183.7337\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.8152 - val_loss: 182.0641\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.5171 - val_loss: 180.4037\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.9695 - val_loss: 179.5546\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.4745 - val_loss: 178.2484\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.3654 - val_loss: 176.7110\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.1350 - val_loss: 176.3450\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.0358 - val_loss: 174.3678\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.1432 - val_loss: 173.1748\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.7599 - val_loss: 173.4576\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.4773 - val_loss: 172.2524\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.2135 - val_loss: 171.1417\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.2291 - val_loss: 170.2630\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.8054 - val_loss: 169.5393\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.5860 - val_loss: 168.1608\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.4290 - val_loss: 166.0396\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.4211 - val_loss: 166.0361\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.6021 - val_loss: 164.8350\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.1459 - val_loss: 163.7006\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.0372 - val_loss: 163.0430\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.7335 - val_loss: 161.9776\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.3520 - val_loss: 161.4295\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.2378 - val_loss: 160.6421\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.3190 - val_loss: 160.2774\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.8477 - val_loss: 159.7351\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.3962 - val_loss: 158.2381\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#The code\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "\n",
    "mse_values = []\n",
    "for i in range(50):\n",
    "    #The train test split:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3) \n",
    "    #Producing the model:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape=(X.shape[1],), activation='relu'))  # Input layer with 32 neurons\n",
    "    model.add(Dense(10, activation='relu'))  # Hidden layer with 16 neurons\n",
    "    model.add(Dense(1, activation='linear'))  \n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.001))\n",
    "    model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0a4c42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average MSE over 50 runs: 169.20453158390737\n",
      "\n",
      "Average MSE standard deviations over 50 runs: 10.67267432959442\n"
     ]
    }
   ],
   "source": [
    "average_mse = np.mean(mse_values)\n",
    "std_dev_mse=np.std(mse_values)\n",
    "print(f\"\\nAverage MSE over 50 runs: {average_mse}\")\n",
    "print(f\"\\nAverage MSE standard deviations over 50 runs: {std_dev_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12b6e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### In comparison to \"model A\", both the average mse and its standard error decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120d594a",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "C. Increate the number of epochs (5 marks)\n",
    "\n",
    "Repeat Part B but use 100 epochs this time for training.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "475dd938",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1603.1791 - val_loss: 1400.1069\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1566.6011 - val_loss: 1360.2695\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1509.7095 - val_loss: 1299.9221\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1428.7750 - val_loss: 1215.5933\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1319.7186 - val_loss: 1107.3665\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1182.9255 - val_loss: 969.5172\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1016.1240 - val_loss: 809.9041\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 827.0163 - val_loss: 640.6430\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 637.6982 - val_loss: 478.5343\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 470.8393 - val_loss: 350.1269\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 346.7392 - val_loss: 268.3592\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 274.3689 - val_loss: 223.6010\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 240.9844 - val_loss: 202.9622\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 224.3786 - val_loss: 195.3281\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 217.2301 - val_loss: 190.6133\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.2253 - val_loss: 187.5724\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.5426 - val_loss: 185.2344\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.3038 - val_loss: 183.3275\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.4620 - val_loss: 181.9143\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.2329 - val_loss: 180.9015\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.9506 - val_loss: 179.2973\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.8131 - val_loss: 178.0085\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.0951 - val_loss: 177.6385\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.2780 - val_loss: 176.4888\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.5442 - val_loss: 175.7161\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.9818 - val_loss: 174.9690\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.7347 - val_loss: 174.2807\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.7137 - val_loss: 173.2594\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.9122 - val_loss: 172.9545\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.8119 - val_loss: 172.2987\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.7811 - val_loss: 171.8999\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.7170 - val_loss: 171.2518\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.7193 - val_loss: 170.4615\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.5879 - val_loss: 169.7444\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.4680 - val_loss: 169.6690\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.6742 - val_loss: 168.7290\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.7187 - val_loss: 168.2742\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.8712 - val_loss: 167.7544\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.0656 - val_loss: 166.6892\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.2276 - val_loss: 166.7551\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.5781 - val_loss: 165.9825\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.8265 - val_loss: 166.0195\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.8835 - val_loss: 165.1641\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.4244 - val_loss: 164.6936\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.6871 - val_loss: 164.3236\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.8591 - val_loss: 164.1293\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.5220 - val_loss: 163.3946\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 168.9997 - val_loss: 162.9446\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.8230 - val_loss: 163.4725\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.6047 - val_loss: 162.3566\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.3284 - val_loss: 162.0560\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.9238 - val_loss: 161.3894\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.2829 - val_loss: 161.5722\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.8526 - val_loss: 161.2047\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.7789 - val_loss: 160.4236\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.0112 - val_loss: 160.5526\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.3705 - val_loss: 160.0357\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.3064 - val_loss: 159.7729\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.6675 - val_loss: 159.5539\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.4420 - val_loss: 158.7928\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.0262 - val_loss: 158.8215\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.8739 - val_loss: 158.5090\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.0070 - val_loss: 158.4811\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.7121 - val_loss: 158.0806\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.3019 - val_loss: 157.4832\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.0010 - val_loss: 157.3387\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.5361 - val_loss: 157.2352\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.2262 - val_loss: 157.2837\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.6820 - val_loss: 156.6828\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.3932 - val_loss: 156.1209\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.1229 - val_loss: 156.3759\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.8684 - val_loss: 156.1767\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.5434 - val_loss: 155.1870\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.7482 - val_loss: 155.4589\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.5556 - val_loss: 155.0017\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.9903 - val_loss: 154.7967\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.7389 - val_loss: 155.0950\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.4057 - val_loss: 154.1615\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 155.9252 - val_loss: 153.6829\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.3692 - val_loss: 153.5900\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.1497 - val_loss: 153.3245\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.9999 - val_loss: 153.2470\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.3985 - val_loss: 153.4815\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.0240 - val_loss: 152.5846\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.1686 - val_loss: 153.8171\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.3863 - val_loss: 151.9087\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.1250 - val_loss: 152.0073\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.5731 - val_loss: 151.7439\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.1471 - val_loss: 151.8707\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.9646 - val_loss: 151.5961\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.5083 - val_loss: 151.3224\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.2425 - val_loss: 151.0713\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.9011 - val_loss: 151.0111\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.6271 - val_loss: 150.9031\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.5973 - val_loss: 150.3319\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.6404 - val_loss: 150.6022\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0899 - val_loss: 150.2305\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0694 - val_loss: 149.5452\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.1759 - val_loss: 149.8570\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.4096 - val_loss: 150.0112\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1521.4250 - val_loss: 1509.9003\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1467.4514 - val_loss: 1449.6544\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1398.5432 - val_loss: 1370.8989\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1310.2917 - val_loss: 1269.1652\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1198.9520 - val_loss: 1143.8865\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1063.4962 - val_loss: 995.7845\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 908.3129 - val_loss: 829.9379\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 741.7914 - val_loss: 658.5640\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 578.1413 - val_loss: 503.0627\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 441.0716 - val_loss: 376.6068\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 337.6716 - val_loss: 295.5822\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 276.5880 - val_loss: 249.8905\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 243.3955 - val_loss: 230.9686\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 227.2543 - val_loss: 220.8724\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 218.2056 - val_loss: 215.7727\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.7496 - val_loss: 212.0254\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.4846 - val_loss: 207.5139\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.8095 - val_loss: 205.4401\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.0944 - val_loss: 202.5943\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.2074 - val_loss: 201.9167\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.8955 - val_loss: 200.0339\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.0969 - val_loss: 197.6693\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.0020 - val_loss: 195.8436\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 191.1127 - val_loss: 193.9689\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.4312 - val_loss: 193.1059\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.0881 - val_loss: 192.0472\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.4041 - val_loss: 190.1325\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.0110 - val_loss: 189.5054\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.7894 - val_loss: 188.3711\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.5930 - val_loss: 186.6696\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.2982 - val_loss: 185.6693\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.1275 - val_loss: 184.6569\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.9724 - val_loss: 183.7840\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 177.8820 - val_loss: 182.4514\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.6599 - val_loss: 180.6115\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.8600 - val_loss: 179.8346\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.8093 - val_loss: 179.1210\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.8924 - val_loss: 177.6555\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.8309 - val_loss: 177.6132\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.0634 - val_loss: 176.3219\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.0553 - val_loss: 175.5251\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.4489 - val_loss: 174.5513\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.7567 - val_loss: 174.8459\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.8397 - val_loss: 172.9540\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.1608 - val_loss: 172.3965\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.1758 - val_loss: 170.5628\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.8636 - val_loss: 171.4963\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.4707 - val_loss: 169.7172\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.8239 - val_loss: 168.6104\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.0962 - val_loss: 167.6963\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.3909 - val_loss: 167.8216\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.6306 - val_loss: 166.6791\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.1176 - val_loss: 165.9121\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.6767 - val_loss: 164.9295\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.7189 - val_loss: 165.0125\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.0271 - val_loss: 164.7601\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.1753 - val_loss: 163.2436\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.7791 - val_loss: 162.9376\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.0478 - val_loss: 161.5779\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.6076 - val_loss: 160.6317\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.9112 - val_loss: 161.0913\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.2836 - val_loss: 159.9128\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.5558 - val_loss: 159.3082\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.1809 - val_loss: 159.7451\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.5710 - val_loss: 158.7364\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.5687 - val_loss: 157.8334\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.9455 - val_loss: 158.9009\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.3183 - val_loss: 157.1688\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.3227 - val_loss: 156.3851\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.9406 - val_loss: 156.5746\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.3869 - val_loss: 155.7322\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.9689 - val_loss: 154.8757\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.5023 - val_loss: 154.2928\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.6863 - val_loss: 156.1047\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.4536 - val_loss: 152.9810\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.6515 - val_loss: 153.3415\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.2155 - val_loss: 153.1435\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.8357 - val_loss: 152.3459\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.4340 - val_loss: 152.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.9804 - val_loss: 151.9479\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.6456 - val_loss: 151.2355\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.0025 - val_loss: 150.6307\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.6149 - val_loss: 150.3981\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.5030 - val_loss: 150.1696\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.5602 - val_loss: 149.4196\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.1575 - val_loss: 149.4434\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.9537 - val_loss: 147.9767\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.2754 - val_loss: 148.3165\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.8206 - val_loss: 147.7166\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.6449 - val_loss: 147.5194\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.2276 - val_loss: 147.4256\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.7207 - val_loss: 146.3854\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.3860 - val_loss: 146.2240\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.0431 - val_loss: 145.7682\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.5961 - val_loss: 146.6499\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.9463 - val_loss: 145.3961\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.2871 - val_loss: 146.4231\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.8978 - val_loss: 144.5880\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.0903 - val_loss: 144.6215\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 139.3262 - val_loss: 144.2790\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1532.8708 - val_loss: 1534.8569\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1479.7902 - val_loss: 1476.7975\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1411.9241 - val_loss: 1399.4059\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1323.6899 - val_loss: 1300.9434\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1211.7965 - val_loss: 1179.9454\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1078.7445 - val_loss: 1034.0381\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 921.8981 - val_loss: 871.7560\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 754.3888 - val_loss: 700.4238\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 592.1448 - val_loss: 540.0399\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 452.1098 - val_loss: 412.0544\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 349.7062 - val_loss: 325.1165\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 287.2558 - val_loss: 272.8729\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 251.1167 - val_loss: 244.8214\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 232.8637 - val_loss: 226.8212\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 220.7627 - val_loss: 217.8434\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 213.1779 - val_loss: 211.6958\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.7771 - val_loss: 206.8276\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.6521 - val_loss: 204.0070\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.4292 - val_loss: 200.3557\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.8503 - val_loss: 199.3670\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.1603 - val_loss: 197.0350\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.8878 - val_loss: 195.1202\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.4059 - val_loss: 192.9614\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.4368 - val_loss: 191.0760\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.4607 - val_loss: 190.0959\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.7273 - val_loss: 188.7228\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.2609 - val_loss: 187.7075\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.8436 - val_loss: 186.6759\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.0902 - val_loss: 185.0438\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.8205 - val_loss: 184.1710\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.6783 - val_loss: 183.8248\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.5586 - val_loss: 181.9553\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.4850 - val_loss: 181.3545\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.4039 - val_loss: 180.3720\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.5617 - val_loss: 179.7074\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.6486 - val_loss: 178.6187\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.6521 - val_loss: 178.0495\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.0186 - val_loss: 177.3023\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.3518 - val_loss: 176.6324\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.5479 - val_loss: 176.6651\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.9155 - val_loss: 176.2592\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.4837 - val_loss: 174.6032\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.5729 - val_loss: 174.5885\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.1268 - val_loss: 173.8641\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.1728 - val_loss: 173.4031\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.7810 - val_loss: 173.2287\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.3699 - val_loss: 172.0193\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.4186 - val_loss: 171.6771\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.9387 - val_loss: 171.1338\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.3241 - val_loss: 170.5889\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.6627 - val_loss: 170.2797\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.3931 - val_loss: 169.0396\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.6760 - val_loss: 169.2859\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 159.0112 - val_loss: 169.0621\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.6594 - val_loss: 168.1580\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.0403 - val_loss: 167.2406\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.5911 - val_loss: 167.2178\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.9476 - val_loss: 166.7098\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.1705 - val_loss: 166.3234\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.7796 - val_loss: 165.7492\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.1523 - val_loss: 165.4135\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.5645 - val_loss: 164.5298\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.5827 - val_loss: 164.1385\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.4489 - val_loss: 162.8725\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.2449 - val_loss: 163.1035\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.4414 - val_loss: 162.1063\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8067 - val_loss: 161.6671\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.4906 - val_loss: 160.9587\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.0620 - val_loss: 161.1023\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.4653 - val_loss: 159.7303\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.1547 - val_loss: 158.9907\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.3632 - val_loss: 158.5813\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.1771 - val_loss: 158.3548\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.5598 - val_loss: 158.1920\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.8190 - val_loss: 157.3274\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.8374 - val_loss: 156.2975\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.8539 - val_loss: 156.3465\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.4632 - val_loss: 156.2062\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 145.9360 - val_loss: 155.8561\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.7067 - val_loss: 154.3784\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.5569 - val_loss: 154.2432\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.2244 - val_loss: 153.5911\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.5469 - val_loss: 153.0795\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.0873 - val_loss: 153.2276\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.5114 - val_loss: 152.1611\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.2146 - val_loss: 152.0588\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.9954 - val_loss: 151.8821\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.3216 - val_loss: 150.9830\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.1192 - val_loss: 150.4465\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.6497 - val_loss: 150.1805\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.4926 - val_loss: 150.3873\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.7979 - val_loss: 149.4118\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.8375 - val_loss: 149.2736\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.2877 - val_loss: 148.4357\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.8609 - val_loss: 147.9839\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.8665 - val_loss: 148.4442\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.0735 - val_loss: 147.5532\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.1890 - val_loss: 147.0100\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.5645 - val_loss: 146.2272\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.5763 - val_loss: 145.9714\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1618.6628 - val_loss: 1394.4760\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1579.5602 - val_loss: 1357.5388\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1532.5983 - val_loss: 1310.1814\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1469.3136 - val_loss: 1244.2301\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1381.5991 - val_loss: 1156.2573\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1266.2539 - val_loss: 1040.4207\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1118.5059 - val_loss: 904.6378\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 952.3953 - val_loss: 750.9499\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 778.5814 - val_loss: 600.1503\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 612.2012 - val_loss: 468.0083\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 474.3420 - val_loss: 364.0843\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 374.3649 - val_loss: 290.3826\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 305.9239 - val_loss: 244.9872\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 263.8277 - val_loss: 218.3962\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 236.8133 - val_loss: 207.1559\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 221.7621 - val_loss: 202.5394\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.7157 - val_loss: 199.8379\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.0464 - val_loss: 198.4211\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.2051 - val_loss: 196.9586\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.4393 - val_loss: 195.5644\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.2364 - val_loss: 193.4686\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.7026 - val_loss: 192.6382\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.0523 - val_loss: 191.2610\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.4937 - val_loss: 189.6580\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.4275 - val_loss: 188.7547\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.7836 - val_loss: 187.7968\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.7024 - val_loss: 186.4793\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.0753 - val_loss: 185.6778\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.0557 - val_loss: 184.4526\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.3727 - val_loss: 183.7055\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.8841 - val_loss: 183.4785\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.2438 - val_loss: 181.7090\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.0101 - val_loss: 181.4892\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.9901 - val_loss: 180.4731\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.7797 - val_loss: 180.2098\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.0974 - val_loss: 180.1102\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.8053 - val_loss: 179.5625\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.8595 - val_loss: 179.0952\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.4353 - val_loss: 177.9722\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.0487 - val_loss: 178.8138\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.2265 - val_loss: 177.6763\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.6102 - val_loss: 177.6409\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 163.7185 - val_loss: 176.0925\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.7530 - val_loss: 176.1046\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.9614 - val_loss: 175.7147\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.1929 - val_loss: 175.0680\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.5794 - val_loss: 174.2593\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.6474 - val_loss: 174.3692\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.1829 - val_loss: 173.1938\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.2665 - val_loss: 173.6544\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.6689 - val_loss: 173.0209\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.0262 - val_loss: 173.1743\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.4731 - val_loss: 172.5402\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.0011 - val_loss: 171.7104\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.3265 - val_loss: 172.0102\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.1656 - val_loss: 170.9188\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.4735 - val_loss: 171.3935\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.6165 - val_loss: 170.6561\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.0020 - val_loss: 170.4986\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.4726 - val_loss: 169.7756\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.2519 - val_loss: 169.4581\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 151.6624 - val_loss: 168.7827\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.9723 - val_loss: 169.3619\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.5928 - val_loss: 168.2744\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.8658 - val_loss: 168.5379\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.6992 - val_loss: 168.1754\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.6162 - val_loss: 168.5963\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.9117 - val_loss: 167.1624\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 148.1888 - val_loss: 167.0312\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 147.8557 - val_loss: 166.9917\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.4100 - val_loss: 167.2142\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 146.9545 - val_loss: 166.7370\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.6050 - val_loss: 166.5051\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 146.5213 - val_loss: 165.8394\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 145.7848 - val_loss: 166.4751\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.4794 - val_loss: 165.7649\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.9682 - val_loss: 165.6334\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.0066 - val_loss: 166.2321\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 5ms/step - loss: 144.3258 - val_loss: 164.7497\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.0921 - val_loss: 164.6598\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.7435 - val_loss: 165.4514\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 143.1805 - val_loss: 164.1064\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.0371 - val_loss: 164.3255\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 142.6478 - val_loss: 163.1308\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.2106 - val_loss: 163.8025\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 141.7367 - val_loss: 163.5432\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.5162 - val_loss: 163.0557\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.1552 - val_loss: 162.3988\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 141.3681 - val_loss: 162.9773\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.6180 - val_loss: 163.0014\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.3848 - val_loss: 162.1539\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.9353 - val_loss: 163.0295\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.7870 - val_loss: 163.0630\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 139.6290 - val_loss: 161.9876\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 138.8946 - val_loss: 161.0863\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 138.8280 - val_loss: 161.1161\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.5227 - val_loss: 161.5303\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.0508 - val_loss: 160.8615\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.8515 - val_loss: 160.8543\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.6110 - val_loss: 161.0789\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1546.4609 - val_loss: 1531.8517\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1502.8915 - val_loss: 1483.0540\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1447.0940 - val_loss: 1417.9528\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1371.0703 - val_loss: 1329.6436\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1268.4071 - val_loss: 1210.7352\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1133.7941 - val_loss: 1059.9077\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 970.8602 - val_loss: 886.5176\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 789.2951 - val_loss: 705.4422\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 609.9052 - val_loss: 531.8102\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 450.6687 - val_loss: 394.6534\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 335.1760 - val_loss: 305.5758\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 267.0736 - val_loss: 260.3456\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 233.8657 - val_loss: 239.5978\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 218.5039 - val_loss: 230.4260\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 210.6117 - val_loss: 224.8702\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.0346 - val_loss: 221.1197\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.7723 - val_loss: 217.9948\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.7130 - val_loss: 215.4814\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.4202 - val_loss: 212.7701\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.4180 - val_loss: 211.4369\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.9736 - val_loss: 209.0338\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.5720 - val_loss: 207.3213\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.5213 - val_loss: 205.4381\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.7345 - val_loss: 204.3997\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.7016 - val_loss: 202.7680\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.1748 - val_loss: 201.1855\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.7799 - val_loss: 200.3608\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.9704 - val_loss: 199.1177\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.2691 - val_loss: 196.9977\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 172.4319 - val_loss: 196.5859\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.0414 - val_loss: 195.4541\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.4850 - val_loss: 194.7536\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.0013 - val_loss: 193.1909\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 167.9386 - val_loss: 192.9680\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.1487 - val_loss: 192.2878\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.1945 - val_loss: 190.9234\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.0115 - val_loss: 190.2782\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.4660 - val_loss: 190.1208\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.6586 - val_loss: 188.6892\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.0268 - val_loss: 188.3597\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.1368 - val_loss: 187.5131\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.4429 - val_loss: 186.6858\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 160.8706 - val_loss: 186.3045\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.2372 - val_loss: 186.2362\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.4551 - val_loss: 185.2326\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.1237 - val_loss: 184.0613\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.4151 - val_loss: 184.0981\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.9383 - val_loss: 184.1911\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.5192 - val_loss: 183.2545\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.9164 - val_loss: 183.2077\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 156.4948 - val_loss: 182.4938\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.8835 - val_loss: 181.7999\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.5928 - val_loss: 181.8132\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.8378 - val_loss: 180.7837\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.2714 - val_loss: 180.7683\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.8273 - val_loss: 180.3873\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.2935 - val_loss: 179.6806\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.9631 - val_loss: 178.7226\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.5906 - val_loss: 178.5580\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.0968 - val_loss: 178.5504\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.4999 - val_loss: 177.5110\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.4392 - val_loss: 176.7899\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.6258 - val_loss: 176.8620\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.0941 - val_loss: 176.2486\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.8486 - val_loss: 175.9831\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.6515 - val_loss: 176.0851\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.7984 - val_loss: 174.4906\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.3725 - val_loss: 174.4745\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.1049 - val_loss: 174.7434\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.4623 - val_loss: 173.4893\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.0517 - val_loss: 173.3973\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.7078 - val_loss: 173.1568\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.3083 - val_loss: 172.6106\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.0651 - val_loss: 172.4058\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.4484 - val_loss: 171.5020\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.3044 - val_loss: 170.9975\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.9003 - val_loss: 171.6087\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.7146 - val_loss: 171.2847\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.9578 - val_loss: 169.8593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.7948 - val_loss: 169.7556\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.3610 - val_loss: 169.5448\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.0978 - val_loss: 169.5817\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.8434 - val_loss: 169.3614\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.5133 - val_loss: 168.9361\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.1242 - val_loss: 168.5669\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.7429 - val_loss: 168.0307\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.6125 - val_loss: 167.7847\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.2879 - val_loss: 167.8397\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.7733 - val_loss: 167.3327\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.4585 - val_loss: 166.9973\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.0464 - val_loss: 167.3540\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.3064 - val_loss: 166.1785\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.4022 - val_loss: 166.8133\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.1916 - val_loss: 165.8088\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.8052 - val_loss: 165.4290\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.4761 - val_loss: 165.6743\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.1882 - val_loss: 165.6052\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.1603 - val_loss: 164.7968\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.9060 - val_loss: 165.4049\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.8901 - val_loss: 165.3419\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1500.4996 - val_loss: 1594.2067\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1446.8096 - val_loss: 1533.6306\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1382.4238 - val_loss: 1455.2029\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1298.6302 - val_loss: 1355.6025\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1194.3638 - val_loss: 1229.8998\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1066.3673 - val_loss: 1079.5739\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 916.1401 - val_loss: 909.9932\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 753.7195 - val_loss: 732.8893\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 592.7708 - val_loss: 567.4210\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 452.8300 - val_loss: 430.8459\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 347.7317 - val_loss: 332.8987\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 280.8607 - val_loss: 277.4803\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 245.0371 - val_loss: 246.6971\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 227.4976 - val_loss: 230.8127\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 218.4731 - val_loss: 221.8224\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.3744 - val_loss: 216.2264\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.6415 - val_loss: 211.1934\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.8044 - val_loss: 206.4851\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.2049 - val_loss: 203.3731\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.2495 - val_loss: 200.2654\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.0079 - val_loss: 197.6054\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.3800 - val_loss: 194.8875\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.4439 - val_loss: 192.8678\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.6086 - val_loss: 190.8170\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.2767 - val_loss: 188.8558\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.5600 - val_loss: 187.5162\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.3966 - val_loss: 185.7158\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.5972 - val_loss: 184.8658\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.5684 - val_loss: 183.4438\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.1486 - val_loss: 182.2888\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.9025 - val_loss: 181.2973\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.6745 - val_loss: 180.7196\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.5237 - val_loss: 179.4880\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.4636 - val_loss: 178.1444\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.4668 - val_loss: 177.1120\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.5801 - val_loss: 176.4298\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.4769 - val_loss: 175.1973\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.4765 - val_loss: 174.2149\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.3343 - val_loss: 173.2665\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.3051 - val_loss: 172.0499\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.4489 - val_loss: 171.3627\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.5737 - val_loss: 170.5853\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.5331 - val_loss: 169.9210\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.5443 - val_loss: 169.3855\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.4973 - val_loss: 168.0823\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.7676 - val_loss: 167.5469\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.9584 - val_loss: 166.5582\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.1258 - val_loss: 165.6949\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.7787 - val_loss: 165.0478\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.3975 - val_loss: 164.3824\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.6373 - val_loss: 163.4535\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.9893 - val_loss: 162.9748\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.2216 - val_loss: 162.5301\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.1053 - val_loss: 161.7858\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.3751 - val_loss: 161.1190\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.5213 - val_loss: 160.4138\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.9864 - val_loss: 159.2405\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.3127 - val_loss: 159.3098\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.3126 - val_loss: 158.6644\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.0210 - val_loss: 157.9244\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.1026 - val_loss: 157.1977\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.4164 - val_loss: 157.0748\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.7020 - val_loss: 156.7490\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.4926 - val_loss: 156.1896\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.5584 - val_loss: 155.6887\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.9093 - val_loss: 154.6339\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.5761 - val_loss: 154.3744\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.2033 - val_loss: 153.9976\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.5271 - val_loss: 154.1813\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.8780 - val_loss: 153.0574\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.7789 - val_loss: 152.5745\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.7500 - val_loss: 151.9667\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.3183 - val_loss: 152.3659\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.8286 - val_loss: 151.7375\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.3091 - val_loss: 151.0307\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.8185 - val_loss: 150.8066\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.5561 - val_loss: 150.2098\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.9572 - val_loss: 149.7713\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 141.4000 - val_loss: 149.4135\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.0370 - val_loss: 149.7018\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.6432 - val_loss: 148.8542\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.2091 - val_loss: 148.2398\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.9500 - val_loss: 148.1683\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.1894 - val_loss: 147.7172\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.3206 - val_loss: 147.5359\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.7676 - val_loss: 147.0412\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.6301 - val_loss: 147.2335\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.9087 - val_loss: 146.7786\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.6531 - val_loss: 146.6291\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.2816 - val_loss: 146.3406\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.8289 - val_loss: 146.2453\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.7630 - val_loss: 146.2289\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.0706 - val_loss: 145.7717\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.1046 - val_loss: 145.5739\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.8698 - val_loss: 145.3851\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.1767 - val_loss: 144.6269\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.8876 - val_loss: 144.9514\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.5804 - val_loss: 144.6873\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.2218 - val_loss: 144.6978\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.5679 - val_loss: 144.1013\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1527.0515 - val_loss: 1685.2526\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1492.7285 - val_loss: 1645.2670\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1452.8971 - val_loss: 1595.8193\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1401.1812 - val_loss: 1527.9360\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1329.5865 - val_loss: 1435.4476\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1233.8419 - val_loss: 1314.4382\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1113.8284 - val_loss: 1162.9025\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 967.1611 - val_loss: 987.4797\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 804.9067 - val_loss: 799.3801\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 639.3965 - val_loss: 616.1417\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 488.0534 - val_loss: 460.7119\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 369.1572 - val_loss: 346.3900\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 288.0234 - val_loss: 276.3612\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 242.1654 - val_loss: 240.5399\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 219.1907 - val_loss: 224.5324\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.8458 - val_loss: 216.5645\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.8979 - val_loss: 212.5573\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.5122 - val_loss: 210.2478\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.8895 - val_loss: 208.1413\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.4765 - val_loss: 206.7296\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.9991 - val_loss: 204.7417\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.1492 - val_loss: 203.3472\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.4287 - val_loss: 201.6333\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 186.6721 - val_loss: 200.0163\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.1576 - val_loss: 198.2442\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.7492 - val_loss: 197.3293\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.3215 - val_loss: 195.9211\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.9842 - val_loss: 194.8180\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.8812 - val_loss: 193.1346\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.8560 - val_loss: 192.1816\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.7016 - val_loss: 191.6425\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.8800 - val_loss: 191.3301\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.9987 - val_loss: 189.9952\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.8326 - val_loss: 188.8595\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.7968 - val_loss: 187.8898\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.8617 - val_loss: 186.5436\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.8847 - val_loss: 186.0237\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.0601 - val_loss: 185.1673\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.1682 - val_loss: 183.9045\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.5484 - val_loss: 183.3052\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.4961 - val_loss: 182.4154\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.7532 - val_loss: 181.9952\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.8371 - val_loss: 180.8857\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.0146 - val_loss: 180.3634\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.2137 - val_loss: 179.2171\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.4752 - val_loss: 178.3301\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.6260 - val_loss: 177.8817\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.9928 - val_loss: 176.7379\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.9725 - val_loss: 175.9498\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.3511 - val_loss: 175.5737\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.6168 - val_loss: 175.0154\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.9865 - val_loss: 174.0553\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.1527 - val_loss: 173.3337\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.4529 - val_loss: 172.7758\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.6620 - val_loss: 171.9579\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.3427 - val_loss: 171.4830\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.1001 - val_loss: 170.5212\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.0789 - val_loss: 169.7911\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.3570 - val_loss: 169.0375\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.6674 - val_loss: 168.7995\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.3583 - val_loss: 168.1205\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.6921 - val_loss: 167.5362\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.9214 - val_loss: 167.1843\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.3489 - val_loss: 166.2702\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.9457 - val_loss: 165.9902\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.7007 - val_loss: 165.0779\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.3604 - val_loss: 164.3869\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0396 - val_loss: 164.0261\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.5950 - val_loss: 163.6552\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.6962 - val_loss: 162.7567\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.7005 - val_loss: 162.4092\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.8275 - val_loss: 162.2150\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.3094 - val_loss: 161.8104\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.0762 - val_loss: 161.0835\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.5755 - val_loss: 160.8905\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.2852 - val_loss: 160.8027\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.6497 - val_loss: 160.1275\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.0322 - val_loss: 159.5130\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 144.4340 - val_loss: 159.2023\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.9573 - val_loss: 158.6762\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.7384 - val_loss: 158.1157\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.1977 - val_loss: 158.1602\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.0498 - val_loss: 157.4742\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.4717 - val_loss: 157.0900\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.1192 - val_loss: 157.3034\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.8006 - val_loss: 156.4518\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.3994 - val_loss: 156.3431\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.0163 - val_loss: 155.9779\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.7094 - val_loss: 155.7680\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.3385 - val_loss: 155.2534\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.2565 - val_loss: 155.4166\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.8057 - val_loss: 154.7374\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 139.3428 - val_loss: 154.5998\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.5382 - val_loss: 154.1146\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.5522 - val_loss: 154.4195\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.7662 - val_loss: 154.2020\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.9696 - val_loss: 154.0610\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.8232 - val_loss: 153.5721\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.5174 - val_loss: 153.0890\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.0618 - val_loss: 153.3692\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1501.8689 - val_loss: 1432.8799\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1439.3247 - val_loss: 1359.0897\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1353.5726 - val_loss: 1258.4297\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1234.3011 - val_loss: 1121.2084\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1080.2352 - val_loss: 946.8170\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 891.0657 - val_loss: 754.4376\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 691.3220 - val_loss: 560.2628\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 504.2203 - val_loss: 399.4938\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 361.2488 - val_loss: 290.4557\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 272.8880 - val_loss: 239.2375\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 232.5804 - val_loss: 221.7834\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 220.0744 - val_loss: 214.9633\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.9989 - val_loss: 211.0318\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 210.3447 - val_loss: 208.0342\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.4811 - val_loss: 204.8500\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.5352 - val_loss: 202.2106\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.0192 - val_loss: 199.8572\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.3537 - val_loss: 197.7234\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.2726 - val_loss: 195.8600\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.9563 - val_loss: 193.8295\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.9145 - val_loss: 191.9312\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.3280 - val_loss: 190.5281\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 189.6742 - val_loss: 189.7973\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 188.4808 - val_loss: 187.1502\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 186.8802 - val_loss: 187.0947\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.3975 - val_loss: 185.7242\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.2744 - val_loss: 184.3488\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.1643 - val_loss: 183.3086\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.5876 - val_loss: 182.5418\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.5815 - val_loss: 181.2805\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.3041 - val_loss: 180.9031\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.5279 - val_loss: 180.3218\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.1853 - val_loss: 178.7510\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 175.8788 - val_loss: 177.7999\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.9148 - val_loss: 176.6310\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 173.8558 - val_loss: 176.4167\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.0188 - val_loss: 175.1309\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.9050 - val_loss: 174.6147\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.9599 - val_loss: 173.3322\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 169.6329 - val_loss: 172.3939\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.9624 - val_loss: 172.3089\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.8490 - val_loss: 170.9266\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.9908 - val_loss: 170.4567\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.9516 - val_loss: 169.6655\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.1223 - val_loss: 169.0838\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.0862 - val_loss: 169.1214\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.2397 - val_loss: 168.2633\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.3872 - val_loss: 166.6766\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.6528 - val_loss: 166.4910\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.8912 - val_loss: 165.3191\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.9189 - val_loss: 164.5321\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.2969 - val_loss: 164.2018\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.2008 - val_loss: 163.5013\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.5925 - val_loss: 162.2743\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4276 - val_loss: 161.9522\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.4456 - val_loss: 161.2875\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.5020 - val_loss: 160.1904\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.6248 - val_loss: 160.3995\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.9840 - val_loss: 159.7771\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.3653 - val_loss: 158.6637\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.7733 - val_loss: 158.6830\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.0276 - val_loss: 158.2271\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.4254 - val_loss: 156.1656\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.7193 - val_loss: 156.1395\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.3465 - val_loss: 156.1178\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0874 - val_loss: 156.7492\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.1580 - val_loss: 154.4494\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.5532 - val_loss: 154.3938\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.9878 - val_loss: 153.5699\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.4982 - val_loss: 153.6386\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.9136 - val_loss: 152.5748\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.2518 - val_loss: 152.0319\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.8275 - val_loss: 152.4876\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.3524 - val_loss: 151.9068\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.8304 - val_loss: 150.6388\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.4063 - val_loss: 151.3776\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.6129 - val_loss: 149.7579\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.5693 - val_loss: 149.5030\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.0137 - val_loss: 148.8452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.5417 - val_loss: 148.9031\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.5253 - val_loss: 148.7240\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.7348 - val_loss: 148.0200\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.2338 - val_loss: 147.8450\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.0183 - val_loss: 146.9805\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.4615 - val_loss: 146.5005\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.1896 - val_loss: 146.5424\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.6658 - val_loss: 146.4420\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.3684 - val_loss: 145.3950\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.5074 - val_loss: 145.3522\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.4547 - val_loss: 144.7988\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.3770 - val_loss: 144.2611\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.9846 - val_loss: 144.2007\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.6252 - val_loss: 143.7784\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.2336 - val_loss: 143.3484\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.8685 - val_loss: 143.4695\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.8907 - val_loss: 142.7343\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.3425 - val_loss: 143.0709\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.6369 - val_loss: 142.4284\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.0190 - val_loss: 141.8013\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.8180 - val_loss: 141.9944\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1496.3153 - val_loss: 1478.3782\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1437.9760 - val_loss: 1413.5428\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1363.7845 - val_loss: 1331.1382\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1270.4056 - val_loss: 1227.8594\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1154.9016 - val_loss: 1101.9443\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1016.0580 - val_loss: 956.6826\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 861.8369 - val_loss: 794.9214\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 698.0052 - val_loss: 635.0911\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 542.1852 - val_loss: 490.9105\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 411.0083 - val_loss: 375.5063\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 316.6679 - val_loss: 294.1162\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 255.0634 - val_loss: 250.2748\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 224.9786 - val_loss: 226.5877\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.9643 - val_loss: 216.3654\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.3722 - val_loss: 210.6858\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.6505 - val_loss: 208.2044\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.0289 - val_loss: 205.6818\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.0478 - val_loss: 203.6247\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.3898 - val_loss: 201.7743\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.8714 - val_loss: 200.6535\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.1479 - val_loss: 198.7448\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.6342 - val_loss: 197.4634\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.4265 - val_loss: 196.6243\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.1692 - val_loss: 195.0372\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.9520 - val_loss: 193.9051\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.1089 - val_loss: 192.8161\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.9940 - val_loss: 192.0621\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.0698 - val_loss: 191.1689\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.0056 - val_loss: 189.8591\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.0777 - val_loss: 188.5620\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.6985 - val_loss: 187.6250\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.9260 - val_loss: 186.9766\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.0069 - val_loss: 186.1726\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.2012 - val_loss: 184.7303\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.2591 - val_loss: 183.8766\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.3260 - val_loss: 183.0363\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.5947 - val_loss: 182.1716\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.5643 - val_loss: 181.5790\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.7021 - val_loss: 180.7807\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.0663 - val_loss: 180.2592\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.3038 - val_loss: 179.0468\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.6198 - val_loss: 178.3982\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.7881 - val_loss: 177.7634\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.2507 - val_loss: 176.6217\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.3933 - val_loss: 175.9662\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.7771 - val_loss: 175.3558\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.1165 - val_loss: 174.9448\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.1824 - val_loss: 173.8288\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.7298 - val_loss: 173.1655\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.0323 - val_loss: 172.5098\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.2617 - val_loss: 171.6810\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.8466 - val_loss: 171.1363\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.0410 - val_loss: 170.4741\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.4893 - val_loss: 169.8087\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.9602 - val_loss: 168.9360\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.3613 - val_loss: 168.7663\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.7827 - val_loss: 167.6491\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.3061 - val_loss: 166.6284\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.3928 - val_loss: 166.6263\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.7538 - val_loss: 165.7288\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.9799 - val_loss: 164.7515\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.7536 - val_loss: 164.3594\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.9741 - val_loss: 163.4098\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.6690 - val_loss: 163.4187\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.8049 - val_loss: 162.0286\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.3102 - val_loss: 161.4682\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.8117 - val_loss: 160.8486\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.2861 - val_loss: 160.0645\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.8719 - val_loss: 159.5308\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.3852 - val_loss: 158.5300\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.9975 - val_loss: 158.0725\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.0772 - val_loss: 157.7211\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.6445 - val_loss: 157.1106\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.0613 - val_loss: 156.6988\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.6095 - val_loss: 155.3542\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.9883 - val_loss: 155.6505\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.4948 - val_loss: 153.9824\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.2926 - val_loss: 154.4016\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.7089 - val_loss: 153.3695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.2389 - val_loss: 152.3804\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.4861 - val_loss: 152.1609\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.6533 - val_loss: 150.7828\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.1402 - val_loss: 150.7332\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.7286 - val_loss: 149.3514\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.4302 - val_loss: 149.7046\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.7137 - val_loss: 149.2643\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.1504 - val_loss: 148.0720\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.4880 - val_loss: 147.4209\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.2751 - val_loss: 146.9086\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.8921 - val_loss: 146.3449\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.0055 - val_loss: 145.8952\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.6276 - val_loss: 145.9891\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.1447 - val_loss: 144.8170\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.6009 - val_loss: 143.6688\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.3440 - val_loss: 144.1398\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.8116 - val_loss: 143.4176\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.6391 - val_loss: 142.6259\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.7616 - val_loss: 142.2857\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.3210 - val_loss: 141.2241\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.2896 - val_loss: 141.3787\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1570.3615 - val_loss: 1488.1938\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1522.9622 - val_loss: 1437.6450\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1462.3099 - val_loss: 1369.8988\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1381.1207 - val_loss: 1280.2592\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1273.2142 - val_loss: 1161.5897\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1134.7843 - val_loss: 1017.8206\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 972.7289 - val_loss: 854.1418\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 795.7374 - val_loss: 683.1220\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 620.3143 - val_loss: 525.3193\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 462.1285 - val_loss: 402.7842\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 343.5757 - val_loss: 317.9681\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 268.4107 - val_loss: 272.4367\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 229.7917 - val_loss: 252.2252\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.9006 - val_loss: 243.5260\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.0887 - val_loss: 238.7411\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.0090 - val_loss: 234.8730\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.1071 - val_loss: 230.8627\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.8992 - val_loss: 228.0453\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.6766 - val_loss: 226.3177\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.5757 - val_loss: 222.6298\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.1951 - val_loss: 220.5246\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.2386 - val_loss: 218.9030\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.4117 - val_loss: 216.5322\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.5811 - val_loss: 215.0740\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.4043 - val_loss: 213.4384\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.5189 - val_loss: 211.7165\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.1541 - val_loss: 210.8802\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.7725 - val_loss: 209.3976\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.6506 - val_loss: 208.2073\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.5567 - val_loss: 207.5095\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.3059 - val_loss: 206.7527\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.4371 - val_loss: 205.8721\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.1914 - val_loss: 204.3741\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.3012 - val_loss: 202.7860\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.5576 - val_loss: 202.9397\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.5560 - val_loss: 202.0301\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.6810 - val_loss: 200.9603\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.8460 - val_loss: 200.2037\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.8356 - val_loss: 199.4735\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.9942 - val_loss: 198.4765\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.2073 - val_loss: 197.3091\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.4535 - val_loss: 196.7010\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.9530 - val_loss: 196.3090\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.4921 - val_loss: 195.3664\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.3765 - val_loss: 195.9214\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.6864 - val_loss: 193.8828\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.7733 - val_loss: 193.2885\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.3190 - val_loss: 193.4068\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.2935 - val_loss: 192.3015\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.0058 - val_loss: 191.4635\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.1948 - val_loss: 190.4247\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.4949 - val_loss: 190.0746\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.2191 - val_loss: 189.3616\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.3596 - val_loss: 188.7331\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.4837 - val_loss: 187.5533\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.2285 - val_loss: 186.7859\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.6209 - val_loss: 186.5968\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.9047 - val_loss: 186.0140\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.2275 - val_loss: 185.7560\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.5877 - val_loss: 184.3266\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.2146 - val_loss: 184.2760\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.6578 - val_loss: 183.4006\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.1705 - val_loss: 183.2458\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.6207 - val_loss: 183.6220\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.8391 - val_loss: 181.8124\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.2112 - val_loss: 181.6030\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.6783 - val_loss: 180.2839\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.2158 - val_loss: 180.6937\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.5716 - val_loss: 179.4490\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.1827 - val_loss: 179.2369\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.4144 - val_loss: 178.7309\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.8967 - val_loss: 177.4155\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.4825 - val_loss: 176.5928\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.0589 - val_loss: 177.3265\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.6425 - val_loss: 176.1083\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.9019 - val_loss: 176.2824\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.4537 - val_loss: 175.0782\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.2937 - val_loss: 173.9412\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.5552 - val_loss: 174.3002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.4632 - val_loss: 174.7207\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.4088 - val_loss: 171.7306\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.7612 - val_loss: 171.9302\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.8048 - val_loss: 172.5193\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.6154 - val_loss: 171.0916\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.9119 - val_loss: 170.7854\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.9304 - val_loss: 171.0891\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.3259 - val_loss: 169.1593\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.8267 - val_loss: 169.5241\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.3943 - val_loss: 169.0975\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.0837 - val_loss: 168.5928\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.5795 - val_loss: 168.2819\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.4118 - val_loss: 167.5697\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.9277 - val_loss: 167.8107\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.4923 - val_loss: 166.6297\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.6869 - val_loss: 166.0558\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.9555 - val_loss: 165.8268\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.7409 - val_loss: 166.5413\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.4422 - val_loss: 165.2736\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.9712 - val_loss: 164.9073\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.1226 - val_loss: 164.2079\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1506.4463 - val_loss: 1545.0435\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1467.2913 - val_loss: 1496.8217\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1413.7280 - val_loss: 1430.7740\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1340.3414 - val_loss: 1343.9360\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1245.7538 - val_loss: 1231.8707\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1126.2321 - val_loss: 1095.7288\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 983.7040 - val_loss: 933.2357\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 818.0067 - val_loss: 753.9421\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 641.3871 - val_loss: 575.5779\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 477.2581 - val_loss: 422.8325\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 347.0868 - val_loss: 317.6936\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 267.3369 - val_loss: 261.7366\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 229.3935 - val_loss: 239.0594\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.6693 - val_loss: 231.3266\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.6417 - val_loss: 227.2577\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.8662 - val_loss: 224.3886\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.9430 - val_loss: 221.7664\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.5212 - val_loss: 219.3027\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.1359 - val_loss: 217.2970\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.4751 - val_loss: 215.0382\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.4574 - val_loss: 213.2916\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.5157 - val_loss: 211.2191\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.8717 - val_loss: 209.5149\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.4863 - val_loss: 207.7227\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.6746 - val_loss: 206.2492\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.3336 - val_loss: 204.5876\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.9215 - val_loss: 203.4582\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.4245 - val_loss: 201.8521\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.1894 - val_loss: 200.3229\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.7690 - val_loss: 198.9779\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 177.6403 - val_loss: 197.7881\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.2571 - val_loss: 196.4014\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.9675 - val_loss: 195.2405\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.9532 - val_loss: 194.0837\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.5038 - val_loss: 192.9329\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.4023 - val_loss: 191.5488\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.1918 - val_loss: 190.3066\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.8746 - val_loss: 188.6394\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.6078 - val_loss: 187.6292\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.5302 - val_loss: 186.0637\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.5957 - val_loss: 184.5477\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.5641 - val_loss: 183.7090\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.3586 - val_loss: 182.5735\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.4253 - val_loss: 181.5475\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.5165 - val_loss: 180.6551\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.4983 - val_loss: 179.2566\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.8010 - val_loss: 178.3413\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.9015 - val_loss: 177.2346\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.3388 - val_loss: 176.7318\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.3610 - val_loss: 176.1801\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.6054 - val_loss: 174.5202\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.8285 - val_loss: 174.5618\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.1425 - val_loss: 173.1439\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.3246 - val_loss: 172.6575\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.8751 - val_loss: 172.2229\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.0782 - val_loss: 171.2891\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.2091 - val_loss: 170.6633\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.9027 - val_loss: 170.2545\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.0557 - val_loss: 169.7036\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.2886 - val_loss: 168.9467\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.7034 - val_loss: 167.6480\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 149.2073 - val_loss: 167.2558\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 148.6021 - val_loss: 166.8277\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 148.3931 - val_loss: 166.0866\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.9058 - val_loss: 165.5596\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 146.8504 - val_loss: 165.8553\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 146.2893 - val_loss: 164.1386\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.1488 - val_loss: 163.7256\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.7343 - val_loss: 163.5236\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.9551 - val_loss: 163.0111\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.7986 - val_loss: 163.0278\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.8887 - val_loss: 162.1352\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.5503 - val_loss: 161.6796\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.0365 - val_loss: 161.0235\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 142.5862 - val_loss: 160.9240\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 142.1726 - val_loss: 159.8895\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.8614 - val_loss: 159.8120\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.3654 - val_loss: 159.6564\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 140.8282 - val_loss: 158.6295\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.3266 - val_loss: 158.8332\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.0836 - val_loss: 158.0136\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 139.9067 - val_loss: 157.2126\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 139.3828 - val_loss: 158.2695\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 138.8188 - val_loss: 156.7633\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.2480 - val_loss: 156.1757\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.9514 - val_loss: 156.5406\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.2556 - val_loss: 155.4449\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 137.4311 - val_loss: 154.9748\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.1066 - val_loss: 154.7597\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 136.9493 - val_loss: 155.5440\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 136.5435 - val_loss: 153.5738\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.0846 - val_loss: 153.6150\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 136.2068 - val_loss: 153.7593\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.3761 - val_loss: 152.4128\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 135.3464 - val_loss: 152.4521\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.0065 - val_loss: 151.3339\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.8098 - val_loss: 151.9083\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.1849 - val_loss: 151.0782\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.1631 - val_loss: 151.6723\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.0110 - val_loss: 150.5807\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1551.4586 - val_loss: 1398.7709\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1499.2649 - val_loss: 1342.7656\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1428.3972 - val_loss: 1265.1907\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1329.9968 - val_loss: 1164.0818\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1207.5298 - val_loss: 1042.8671\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1063.7761 - val_loss: 905.2455\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 905.0662 - val_loss: 755.4919\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 738.0093 - val_loss: 609.3457\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 579.9948 - val_loss: 478.2129\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 444.2412 - val_loss: 374.8216\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 344.0813 - val_loss: 305.1461\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 281.1310 - val_loss: 265.7781\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 246.4457 - val_loss: 245.6572\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 228.3437 - val_loss: 235.2939\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 217.6886 - val_loss: 228.7369\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.0901 - val_loss: 224.0804\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 206.4433 - val_loss: 220.3912\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.2044 - val_loss: 216.9344\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.4904 - val_loss: 213.6211\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.7332 - val_loss: 210.4926\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.8862 - val_loss: 208.1949\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.4728 - val_loss: 206.1270\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.2163 - val_loss: 204.0395\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.4437 - val_loss: 202.2561\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.8056 - val_loss: 200.0435\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.6453 - val_loss: 198.8150\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.0570 - val_loss: 197.0740\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.7045 - val_loss: 195.7626\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.0992 - val_loss: 194.0804\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.8360 - val_loss: 192.9978\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.5738 - val_loss: 191.8532\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.4682 - val_loss: 190.9308\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.4532 - val_loss: 189.8182\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.4357 - val_loss: 189.0805\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.6913 - val_loss: 187.8085\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.5832 - val_loss: 186.6025\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.5778 - val_loss: 186.0376\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.9368 - val_loss: 185.4971\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.1317 - val_loss: 184.2354\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.1502 - val_loss: 183.5765\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.4839 - val_loss: 182.6955\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.7121 - val_loss: 181.8751\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 165.0276 - val_loss: 181.6671\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.4215 - val_loss: 180.7751\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.8830 - val_loss: 180.0279\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.2668 - val_loss: 179.8646\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.8766 - val_loss: 178.8863\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.2171 - val_loss: 178.5255\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.8442 - val_loss: 177.8118\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.3477 - val_loss: 177.1318\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.8439 - val_loss: 176.6450\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.3739 - val_loss: 176.8597\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.8989 - val_loss: 175.4169\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.3481 - val_loss: 175.3368\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.0715 - val_loss: 174.9010\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.8163 - val_loss: 173.8234\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.2556 - val_loss: 173.9951\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4861 - val_loss: 173.1127\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.1705 - val_loss: 172.2065\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.6672 - val_loss: 171.8998\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.4813 - val_loss: 172.1030\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.6286 - val_loss: 170.6465\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.1022 - val_loss: 170.4023\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.5213 - val_loss: 169.8917\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.0066 - val_loss: 169.5083\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.3448 - val_loss: 168.9346\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.8141 - val_loss: 168.1628\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.4851 - val_loss: 167.8508\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8372 - val_loss: 167.1853\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.2973 - val_loss: 166.7476\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.8654 - val_loss: 166.3517\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.4272 - val_loss: 165.7828\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0028 - val_loss: 165.3985\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.5819 - val_loss: 164.4899\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.0962 - val_loss: 164.7199\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.5115 - val_loss: 163.7195\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.0812 - val_loss: 163.4942\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.2028 - val_loss: 163.8170\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.1071 - val_loss: 162.5815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.0672 - val_loss: 162.4649\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.5023 - val_loss: 161.9773\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.8212 - val_loss: 161.2705\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.5129 - val_loss: 160.9306\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.0464 - val_loss: 160.9882\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.0730 - val_loss: 160.5059\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.0452 - val_loss: 160.5641\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.3025 - val_loss: 159.6647\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.2518 - val_loss: 159.0557\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.4344 - val_loss: 159.4688\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.5934 - val_loss: 158.3349\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.6159 - val_loss: 158.8659\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.2073 - val_loss: 158.2474\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.9578 - val_loss: 158.0211\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.7479 - val_loss: 157.1317\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.2943 - val_loss: 157.7283\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.9499 - val_loss: 157.3363\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.7163 - val_loss: 156.7901\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.6341 - val_loss: 156.4998\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.1986 - val_loss: 156.2628\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.9219 - val_loss: 155.7881\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1562.9855 - val_loss: 1515.1931\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1525.3250 - val_loss: 1474.0133\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1475.9128 - val_loss: 1412.7921\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1401.0553 - val_loss: 1324.0653\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1298.0325 - val_loss: 1206.5052\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1167.5352 - val_loss: 1058.6925\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1005.2240 - val_loss: 890.1025\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 823.8495 - val_loss: 703.5370\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 637.8198 - val_loss: 527.1012\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 470.8835 - val_loss: 386.2757\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 348.3439 - val_loss: 290.4107\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 274.3426 - val_loss: 236.0924\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 236.6935 - val_loss: 213.2151\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 222.2098 - val_loss: 202.7413\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 214.4799 - val_loss: 198.4185\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 209.8045 - val_loss: 194.6950\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 206.4717 - val_loss: 192.3328\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.7802 - val_loss: 189.9892\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.8284 - val_loss: 188.1135\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.4192 - val_loss: 186.5394\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.2310 - val_loss: 185.0665\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.4004 - val_loss: 183.4656\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.3422 - val_loss: 182.3828\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.1042 - val_loss: 181.2685\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.3533 - val_loss: 180.0277\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.6893 - val_loss: 179.2349\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.1440 - val_loss: 178.4166\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.0218 - val_loss: 177.4689\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.5384 - val_loss: 176.1778\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.3942 - val_loss: 175.4494\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.1005 - val_loss: 174.5691\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 180.1426 - val_loss: 173.9921\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.6402 - val_loss: 172.6864\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.5978 - val_loss: 171.7850\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.5629 - val_loss: 171.2994\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.5045 - val_loss: 170.5296\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.4009 - val_loss: 169.6602\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.6712 - val_loss: 168.7737\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.3867 - val_loss: 168.2326\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.5072 - val_loss: 167.7350\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.6261 - val_loss: 166.8528\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.6582 - val_loss: 166.1890\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 168.6419 - val_loss: 165.3692\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.9512 - val_loss: 164.8642\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.2261 - val_loss: 164.4742\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.0450 - val_loss: 163.8546\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.4113 - val_loss: 162.9611\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.7498 - val_loss: 162.5350\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.7468 - val_loss: 161.8562\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.0977 - val_loss: 161.3037\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.4393 - val_loss: 161.0618\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.6696 - val_loss: 160.3270\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.8295 - val_loss: 159.5582\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.1887 - val_loss: 159.1600\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 159.4956 - val_loss: 158.4998\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.8603 - val_loss: 158.2795\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.3974 - val_loss: 157.5115\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.5893 - val_loss: 157.1085\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.0009 - val_loss: 156.4489\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.3078 - val_loss: 155.8860\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.0550 - val_loss: 155.5976\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.0662 - val_loss: 154.7482\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.4220 - val_loss: 154.4058\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.7448 - val_loss: 153.7396\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.0589 - val_loss: 153.4681\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.4686 - val_loss: 152.9759\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8546 - val_loss: 152.0807\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.3326 - val_loss: 151.6699\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.8869 - val_loss: 151.0189\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0862 - val_loss: 150.7652\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.6350 - val_loss: 150.3165\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.1445 - val_loss: 149.8062\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.6362 - val_loss: 149.2992\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.9575 - val_loss: 149.0761\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.4425 - val_loss: 148.4630\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.9315 - val_loss: 148.2516\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.4439 - val_loss: 148.1002\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.9628 - val_loss: 147.6242\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 145.5404 - val_loss: 147.1690\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.4904 - val_loss: 146.8039\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.8859 - val_loss: 146.0546\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.2859 - val_loss: 146.5938\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.8357 - val_loss: 145.8255\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.4620 - val_loss: 145.3445\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.0460 - val_loss: 145.2685\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.6849 - val_loss: 144.9649\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.9294 - val_loss: 144.1413\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.8005 - val_loss: 143.8972\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.9993 - val_loss: 143.7352\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.2177 - val_loss: 143.5154\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.8263 - val_loss: 143.2270\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.5973 - val_loss: 142.9932\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.8128 - val_loss: 142.8366\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.8968 - val_loss: 142.5046\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.5102 - val_loss: 142.7201\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.0236 - val_loss: 142.0713\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.2520 - val_loss: 141.8366\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.4766 - val_loss: 141.4944\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.1721 - val_loss: 141.5186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.1461 - val_loss: 141.5776\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1521.2344 - val_loss: 1615.9410\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1482.6023 - val_loss: 1571.5587\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1440.3578 - val_loss: 1517.9908\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1386.2732 - val_loss: 1443.1963\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1310.6589 - val_loss: 1346.5769\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1211.7635 - val_loss: 1222.4054\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1089.3087 - val_loss: 1069.5431\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 943.5627 - val_loss: 899.1292\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 784.8065 - val_loss: 721.7899\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 622.7053 - val_loss: 553.5087\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 474.2362 - val_loss: 410.4009\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 351.6553 - val_loss: 312.0160\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 271.0836 - val_loss: 257.5772\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 228.7194 - val_loss: 235.7301\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 210.1722 - val_loss: 228.4131\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.8751 - val_loss: 225.1765\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.8460 - val_loss: 222.5603\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.9719 - val_loss: 219.8403\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.3504 - val_loss: 217.5139\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.4789 - val_loss: 215.6322\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.4751 - val_loss: 213.4073\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.9466 - val_loss: 211.6516\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.3294 - val_loss: 210.1098\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.8958 - val_loss: 208.4035\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.6024 - val_loss: 206.6060\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.4951 - val_loss: 204.8713\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.1770 - val_loss: 203.2794\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.9693 - val_loss: 201.5802\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.7695 - val_loss: 200.0577\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.6791 - val_loss: 198.6561\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.9019 - val_loss: 196.8590\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.9587 - val_loss: 195.8659\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.5947 - val_loss: 194.4637\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.6944 - val_loss: 192.8412\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.9343 - val_loss: 191.9938\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.9040 - val_loss: 190.5792\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.1355 - val_loss: 189.5475\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.5818 - val_loss: 188.4420\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.6294 - val_loss: 187.6605\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.7878 - val_loss: 186.6069\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.9354 - val_loss: 185.3884\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.3116 - val_loss: 184.3376\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.6068 - val_loss: 183.3384\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.3878 - val_loss: 182.7405\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.2790 - val_loss: 181.6844\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.5749 - val_loss: 180.9916\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.8291 - val_loss: 179.9206\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.2865 - val_loss: 179.2880\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.8518 - val_loss: 178.3881\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.2092 - val_loss: 177.9512\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.6333 - val_loss: 176.9845\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.0276 - val_loss: 175.8770\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.9018 - val_loss: 175.5479\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.9911 - val_loss: 174.3745\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.5238 - val_loss: 174.4256\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.0793 - val_loss: 173.4295\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.2733 - val_loss: 172.0781\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.0482 - val_loss: 171.4391\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.3375 - val_loss: 171.6851\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.8224 - val_loss: 170.5581\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.1793 - val_loss: 170.0557\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 155.8547 - val_loss: 169.6081\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.2583 - val_loss: 168.8745\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.9950 - val_loss: 167.6704\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.3441 - val_loss: 167.7849\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.7693 - val_loss: 167.1149\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 153.8048 - val_loss: 166.3689\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.0041 - val_loss: 165.0591\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.3223 - val_loss: 164.6699\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.7570 - val_loss: 164.5497\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.4087 - val_loss: 163.9412\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.9759 - val_loss: 163.3594\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.5939 - val_loss: 161.7648\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.8085 - val_loss: 162.6712\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.5041 - val_loss: 162.0522\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.5481 - val_loss: 160.3458\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.7410 - val_loss: 160.9065\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.8904 - val_loss: 160.1335\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 147.4379 - val_loss: 159.1265\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.3692 - val_loss: 158.4868\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.9532 - val_loss: 158.7582\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.4096 - val_loss: 157.9725\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.2408 - val_loss: 155.6777\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.7637 - val_loss: 156.9385\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.7935 - val_loss: 155.8967\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.3732 - val_loss: 156.2023\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.0128 - val_loss: 154.3852\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.7442 - val_loss: 154.5304\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.0396 - val_loss: 154.4422\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.3450 - val_loss: 153.3953\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 142.3462 - val_loss: 153.2961\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.5827 - val_loss: 154.4017\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.3662 - val_loss: 152.7299\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.8601 - val_loss: 151.5205\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 140.4105 - val_loss: 152.5106\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.9717 - val_loss: 152.2055\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.5055 - val_loss: 150.5795\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.2897 - val_loss: 150.9251\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.3086 - val_loss: 150.4420\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.6842 - val_loss: 151.0317\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1522.4917 - val_loss: 1559.3628\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1482.6895 - val_loss: 1518.0107\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1440.4709 - val_loss: 1470.5518\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1389.0055 - val_loss: 1412.4965\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1324.3126 - val_loss: 1339.5070\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1242.6843 - val_loss: 1248.5038\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1143.6302 - val_loss: 1138.1141\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1024.7313 - val_loss: 1012.4478\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 894.4069 - val_loss: 871.1508\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 751.4951 - val_loss: 722.9476\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 609.7798 - val_loss: 574.6377\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 477.3575 - val_loss: 446.8463\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 373.9150 - val_loss: 346.7166\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 301.7294 - val_loss: 279.6311\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 257.8946 - val_loss: 241.8210\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 235.5802 - val_loss: 220.4236\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 223.1348 - val_loss: 210.0714\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 215.5484 - val_loss: 204.6708\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 210.4333 - val_loss: 201.5806\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.9493 - val_loss: 199.1821\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.4189 - val_loss: 197.1749\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.6004 - val_loss: 195.4240\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.0149 - val_loss: 194.8794\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.4748 - val_loss: 193.3979\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.5544 - val_loss: 191.7869\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.4098 - val_loss: 192.1232\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.3267 - val_loss: 190.7307\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.6531 - val_loss: 189.6667\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.7978 - val_loss: 188.1926\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.4656 - val_loss: 187.5936\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.0851 - val_loss: 186.5289\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.5421 - val_loss: 185.9641\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.5003 - val_loss: 185.4842\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.0874 - val_loss: 184.2733\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.9207 - val_loss: 184.2336\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.0023 - val_loss: 183.0575\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.8766 - val_loss: 183.3547\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.4395 - val_loss: 182.0571\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 172.4391 - val_loss: 181.2839\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.5298 - val_loss: 181.1905\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.4586 - val_loss: 180.6589\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.4064 - val_loss: 179.5992\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.9350 - val_loss: 179.2043\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.0502 - val_loss: 178.8098\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.9834 - val_loss: 178.3607\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.0756 - val_loss: 177.5412\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.1532 - val_loss: 177.0552\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.2797 - val_loss: 176.7787\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.5321 - val_loss: 177.4198\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.7985 - val_loss: 175.6832\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.7961 - val_loss: 175.6285\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.0683 - val_loss: 174.8288\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.3047 - val_loss: 174.6111\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.3906 - val_loss: 174.2760\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.7579 - val_loss: 174.5307\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.4224 - val_loss: 172.6570\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.2456 - val_loss: 172.9991\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8850 - val_loss: 171.9177\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.2123 - val_loss: 172.1335\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.5367 - val_loss: 170.7322\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.7420 - val_loss: 171.4814\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.1503 - val_loss: 170.1920\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.3408 - val_loss: 169.9370\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.7191 - val_loss: 168.8426\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.1587 - val_loss: 168.6091\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8557 - val_loss: 169.5035\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.9223 - val_loss: 167.8884\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.5053 - val_loss: 167.5910\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.7717 - val_loss: 166.7671\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.3163 - val_loss: 166.4172\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.5328 - val_loss: 166.6922\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.8690 - val_loss: 165.7274\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.4684 - val_loss: 165.4428\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.6792 - val_loss: 165.1165\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.3406 - val_loss: 165.2940\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.6683 - val_loss: 163.9124\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.0667 - val_loss: 163.3542\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.5146 - val_loss: 163.4116\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 143.8589 - val_loss: 163.1740\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.3528 - val_loss: 162.7323\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.8999 - val_loss: 162.3784\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.2755 - val_loss: 161.8202\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.1073 - val_loss: 161.2717\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.6569 - val_loss: 161.7507\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.8554 - val_loss: 161.2908\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.4414 - val_loss: 160.4555\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.1215 - val_loss: 160.8860\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.5816 - val_loss: 160.9060\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.0737 - val_loss: 159.4973\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.9110 - val_loss: 159.9540\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.3392 - val_loss: 159.5936\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.6622 - val_loss: 159.1911\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.1917 - val_loss: 159.0070\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.1916 - val_loss: 158.3597\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.5686 - val_loss: 159.5811\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.9881 - val_loss: 158.1740\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.5704 - val_loss: 158.2828\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.3770 - val_loss: 158.3123\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.7208 - val_loss: 157.8441\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.6042 - val_loss: 157.0793\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1546.0945 - val_loss: 1587.6927\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1500.0729 - val_loss: 1536.5404\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1446.4104 - val_loss: 1472.1882\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1376.5895 - val_loss: 1387.9243\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1287.1544 - val_loss: 1277.0852\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1168.1501 - val_loss: 1132.9747\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1019.8397 - val_loss: 962.2891\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 854.4276 - val_loss: 777.8798\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 680.4119 - val_loss: 598.3533\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 521.2776 - val_loss: 437.2777\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 390.2098 - val_loss: 320.6080\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 301.2776 - val_loss: 251.5817\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 250.7784 - val_loss: 219.3999\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 228.4699 - val_loss: 205.5431\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 217.5674 - val_loss: 200.0032\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.0066 - val_loss: 196.7480\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.9707 - val_loss: 194.4728\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.2930 - val_loss: 193.1659\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.4593 - val_loss: 190.5558\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.5483 - val_loss: 188.9321\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.7288 - val_loss: 187.4809\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.6940 - val_loss: 186.0300\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.5792 - val_loss: 184.6579\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.8419 - val_loss: 183.2945\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.8825 - val_loss: 181.8027\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.9899 - val_loss: 180.4375\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.2424 - val_loss: 179.0395\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.6080 - val_loss: 177.7828\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.1756 - val_loss: 176.5616\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.5638 - val_loss: 175.2193\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.0263 - val_loss: 174.2819\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.5056 - val_loss: 173.2206\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.4087 - val_loss: 172.2502\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.6729 - val_loss: 171.1937\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.4802 - val_loss: 170.3655\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.4597 - val_loss: 169.3165\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.2016 - val_loss: 168.7179\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.0857 - val_loss: 167.9149\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.4000 - val_loss: 166.7026\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.9052 - val_loss: 166.1727\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.9236 - val_loss: 165.2240\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.3756 - val_loss: 164.6902\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.1047 - val_loss: 164.1149\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.5336 - val_loss: 163.1384\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.5011 - val_loss: 162.9134\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.4865 - val_loss: 162.0551\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.3355 - val_loss: 161.5619\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.9166 - val_loss: 161.1549\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 160.1120 - val_loss: 160.3810\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.9720 - val_loss: 159.4525\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 158.4862 - val_loss: 158.4799\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.1306 - val_loss: 158.2656\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.1600 - val_loss: 157.6640\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 155.5395 - val_loss: 157.6040\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.0111 - val_loss: 156.1820\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 153.9863 - val_loss: 156.3974\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 153.5607 - val_loss: 155.7018\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.4331 - val_loss: 155.1478\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.0285 - val_loss: 154.6824\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.1533 - val_loss: 154.7341\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 150.5018 - val_loss: 153.9728\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.7392 - val_loss: 153.7993\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.1746 - val_loss: 153.0759\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 148.4010 - val_loss: 152.7529\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.1788 - val_loss: 152.3373\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.1684 - val_loss: 152.2349\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.0397 - val_loss: 151.9028\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.1365 - val_loss: 151.7734\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 145.4782 - val_loss: 151.1078\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.0257 - val_loss: 151.2070\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.3739 - val_loss: 151.0671\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.7680 - val_loss: 150.4270\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.5078 - val_loss: 150.9771\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.7451 - val_loss: 149.9362\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.1239 - val_loss: 149.7267\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.7888 - val_loss: 149.2178\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.4603 - val_loss: 148.9731\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.5414 - val_loss: 149.5060\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 140.7325 - val_loss: 148.7688\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.0789 - val_loss: 148.6170\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 139.4544 - val_loss: 148.8227\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 138.9038 - val_loss: 148.3102\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.7205 - val_loss: 148.1180\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.0483 - val_loss: 147.8955\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.6001 - val_loss: 147.1894\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.1189 - val_loss: 147.3344\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.8020 - val_loss: 147.0475\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.3530 - val_loss: 147.0309\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.1179 - val_loss: 147.3367\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.6359 - val_loss: 146.9057\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.3597 - val_loss: 146.8442\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.8734 - val_loss: 146.5320\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.7979 - val_loss: 146.7429\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.5886 - val_loss: 146.0542\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.9865 - val_loss: 146.4463\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.5662 - val_loss: 146.1062\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.4948 - val_loss: 146.3418\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.9869 - val_loss: 145.8130\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.2289 - val_loss: 146.2030\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.3961 - val_loss: 145.9089\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1581.8910 - val_loss: 1525.4187\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1541.0430 - val_loss: 1486.0492\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1497.2635 - val_loss: 1439.3131\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1441.8635 - val_loss: 1377.9434\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1369.5925 - val_loss: 1298.9906\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1277.0842 - val_loss: 1194.7285\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1153.4729 - val_loss: 1064.0275\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1002.3540 - val_loss: 909.3208\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 831.3762 - val_loss: 740.8754\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 655.2764 - val_loss: 578.3837\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 494.0713 - val_loss: 441.6861\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 368.2211 - val_loss: 342.9416\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 284.3158 - val_loss: 283.4425\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 239.3776 - val_loss: 256.0953\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 216.7682 - val_loss: 246.2015\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.2096 - val_loss: 240.6049\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.4135 - val_loss: 235.5631\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.9962 - val_loss: 233.1134\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.1193 - val_loss: 229.1416\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.5160 - val_loss: 225.9843\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.7127 - val_loss: 223.1146\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.7586 - val_loss: 221.4196\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.8044 - val_loss: 219.4283\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.1511 - val_loss: 217.3873\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.8123 - val_loss: 215.4140\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.3227 - val_loss: 214.4565\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.1353 - val_loss: 212.6014\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.9850 - val_loss: 211.1470\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.7497 - val_loss: 208.9968\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.0392 - val_loss: 207.3193\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.3689 - val_loss: 206.4551\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.6318 - val_loss: 205.8851\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.2900 - val_loss: 204.2330\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.0242 - val_loss: 202.6957\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.7748 - val_loss: 201.3526\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.9142 - val_loss: 199.9290\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.9129 - val_loss: 199.3522\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.0860 - val_loss: 197.8981\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.2384 - val_loss: 196.8913\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.3877 - val_loss: 196.0951\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.5734 - val_loss: 195.2973\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.6863 - val_loss: 194.5271\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.1031 - val_loss: 193.2815\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.1029 - val_loss: 192.5703\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.5092 - val_loss: 191.4721\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.5652 - val_loss: 190.4504\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.8066 - val_loss: 189.4673\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.2334 - val_loss: 188.7063\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.5427 - val_loss: 188.0635\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.6959 - val_loss: 187.3758\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.0606 - val_loss: 186.1649\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.3605 - val_loss: 185.4634\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.7844 - val_loss: 184.7741\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.4312 - val_loss: 184.3285\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.6496 - val_loss: 182.6803\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.9014 - val_loss: 182.2212\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4110 - val_loss: 181.5089\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.6599 - val_loss: 181.0357\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.3355 - val_loss: 179.8371\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.9022 - val_loss: 179.6313\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.2654 - val_loss: 178.7183\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.6165 - val_loss: 178.6806\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.0894 - val_loss: 178.2003\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.5492 - val_loss: 177.2580\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.0308 - val_loss: 176.2174\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.5927 - val_loss: 176.2626\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.1318 - val_loss: 175.1493\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.4319 - val_loss: 174.0597\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.0873 - val_loss: 173.6985\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.5532 - val_loss: 173.7279\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.0806 - val_loss: 172.8089\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.8928 - val_loss: 172.1142\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.4649 - val_loss: 172.0749\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.9490 - val_loss: 170.9900\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.3991 - val_loss: 170.5609\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.0452 - val_loss: 170.1485\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.6294 - val_loss: 169.3324\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.4265 - val_loss: 169.0476\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 146.8587 - val_loss: 168.5183\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.6928 - val_loss: 167.3930\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.7102 - val_loss: 167.8192\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.7297 - val_loss: 167.1228\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.5644 - val_loss: 166.9797\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.0981 - val_loss: 165.7059\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.7668 - val_loss: 165.2790\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.3341 - val_loss: 164.8178\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.3087 - val_loss: 164.4147\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.6813 - val_loss: 163.6113\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.6709 - val_loss: 163.9179\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.1272 - val_loss: 163.4354\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.9798 - val_loss: 162.8974\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.5227 - val_loss: 162.5844\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.1955 - val_loss: 161.9857\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.0373 - val_loss: 161.4739\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.4347 - val_loss: 161.0034\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.3611 - val_loss: 160.9433\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.8607 - val_loss: 160.3052\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.7064 - val_loss: 159.8919\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.5473 - val_loss: 159.6019\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.1898 - val_loss: 159.5686\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1492.9530 - val_loss: 1460.7654\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1432.5804 - val_loss: 1391.5999\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1353.4733 - val_loss: 1302.7576\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1251.6530 - val_loss: 1190.5098\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1126.9176 - val_loss: 1057.0891\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 980.7597 - val_loss: 906.2771\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 818.3760 - val_loss: 745.8154\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 651.7763 - val_loss: 585.8200\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 496.5071 - val_loss: 447.8672\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 373.4955 - val_loss: 342.9041\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 292.1576 - val_loss: 274.9245\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 246.9072 - val_loss: 239.2942\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 226.6928 - val_loss: 222.0273\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 217.7941 - val_loss: 212.7363\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.9190 - val_loss: 206.2030\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.8309 - val_loss: 202.2943\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.2821 - val_loss: 199.3903\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.0589 - val_loss: 197.6095\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.6076 - val_loss: 194.0251\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.2944 - val_loss: 191.0148\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.1412 - val_loss: 189.2334\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.2876 - val_loss: 186.2931\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.3926 - val_loss: 185.0106\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.9736 - val_loss: 183.7381\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.5383 - val_loss: 183.3728\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.1533 - val_loss: 180.7147\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.3791 - val_loss: 179.9920\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.4274 - val_loss: 179.0669\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.2585 - val_loss: 177.9400\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.1820 - val_loss: 176.6125\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.5252 - val_loss: 175.6554\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.3345 - val_loss: 174.1226\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.1900 - val_loss: 173.8053\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.5044 - val_loss: 173.2657\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.7926 - val_loss: 172.1986\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.5281 - val_loss: 170.5117\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.7052 - val_loss: 169.9897\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.9045 - val_loss: 169.7085\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.2035 - val_loss: 168.9583\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.5738 - val_loss: 168.1126\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.1784 - val_loss: 167.4179\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.2739 - val_loss: 166.4457\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.6599 - val_loss: 166.6531\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 170.7103 - val_loss: 165.2155\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.1285 - val_loss: 164.1841\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.7328 - val_loss: 164.6619\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.0886 - val_loss: 162.9609\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.5186 - val_loss: 162.8600\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.6343 - val_loss: 162.3229\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.2706 - val_loss: 161.3379\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.5795 - val_loss: 160.6223\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.5623 - val_loss: 160.8696\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.5257 - val_loss: 158.3437\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.9644 - val_loss: 158.8128\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.5377 - val_loss: 159.4355\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.9358 - val_loss: 157.5647\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.5408 - val_loss: 156.4523\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 162.9628 - val_loss: 156.4782\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.3786 - val_loss: 155.8507\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.2336 - val_loss: 156.6356\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.4325 - val_loss: 155.2785\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.2231 - val_loss: 154.8541\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.9141 - val_loss: 154.5897\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.0785 - val_loss: 153.5325\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.7096 - val_loss: 153.1399\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.5721 - val_loss: 152.8139\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.0500 - val_loss: 152.9529\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 158.8375 - val_loss: 152.5898\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.0569 - val_loss: 151.6063\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.8237 - val_loss: 150.4905\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.6051 - val_loss: 151.4857\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.7951 - val_loss: 149.7443\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.5903 - val_loss: 149.2475\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.1692 - val_loss: 149.6391\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.0005 - val_loss: 149.1469\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.5118 - val_loss: 149.4863\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.1688 - val_loss: 148.5134\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.9860 - val_loss: 147.3307\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.3955 - val_loss: 147.4650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.1603 - val_loss: 147.4214\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.8986 - val_loss: 147.5661\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.2252 - val_loss: 146.0706\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.5164 - val_loss: 146.0906\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.6332 - val_loss: 145.7705\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.4929 - val_loss: 146.0342\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.1370 - val_loss: 145.0085\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.9568 - val_loss: 145.3080\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.2732 - val_loss: 145.2113\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.2119 - val_loss: 144.0600\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.9504 - val_loss: 144.1254\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.9250 - val_loss: 143.4306\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.5232 - val_loss: 143.4654\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0907 - val_loss: 142.6430\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.8774 - val_loss: 142.2879\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.2892 - val_loss: 142.6101\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.0984 - val_loss: 141.7088\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.7013 - val_loss: 141.4543\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.5611 - val_loss: 140.8692\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.5223 - val_loss: 141.3141\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.3762 - val_loss: 140.1480\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1463.2911 - val_loss: 1581.0640\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1411.6876 - val_loss: 1517.0686\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1346.1375 - val_loss: 1434.2787\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1258.4191 - val_loss: 1325.8405\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1148.5129 - val_loss: 1189.5465\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1012.8192 - val_loss: 1029.1787\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 856.3226 - val_loss: 850.7705\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 689.6582 - val_loss: 667.1630\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 528.1352 - val_loss: 501.9376\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 393.5346 - val_loss: 377.5641\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 302.1728 - val_loss: 300.7657\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 249.9847 - val_loss: 264.9876\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 226.2043 - val_loss: 250.0826\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 216.1583 - val_loss: 243.4686\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.4812 - val_loss: 239.7453\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 206.2365 - val_loss: 235.7190\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.0964 - val_loss: 232.0308\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.7760 - val_loss: 228.5326\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.1741 - val_loss: 225.3184\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.7984 - val_loss: 222.9399\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.5263 - val_loss: 219.5596\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.4100 - val_loss: 216.9825\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.7030 - val_loss: 214.8703\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.8740 - val_loss: 212.2898\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.5123 - val_loss: 210.5870\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.1152 - val_loss: 208.4260\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.4746 - val_loss: 205.9022\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.0891 - val_loss: 205.0565\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.1293 - val_loss: 203.7087\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.7470 - val_loss: 200.9048\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.5826 - val_loss: 199.8770\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.6005 - val_loss: 197.9478\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.5467 - val_loss: 197.1468\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.7430 - val_loss: 196.2195\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.8623 - val_loss: 194.5961\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.0744 - val_loss: 193.1187\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.9770 - val_loss: 191.5529\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.8772 - val_loss: 189.8196\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.9702 - val_loss: 189.2026\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.9559 - val_loss: 188.4524\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.2640 - val_loss: 187.0039\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.4848 - val_loss: 186.8747\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.8627 - val_loss: 185.9297\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.2596 - val_loss: 184.2751\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.5968 - val_loss: 183.4603\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.1320 - val_loss: 182.2183\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.6449 - val_loss: 181.3976\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.8550 - val_loss: 181.4985\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.2594 - val_loss: 180.0897\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.7656 - val_loss: 178.9672\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.8181 - val_loss: 179.1221\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.8380 - val_loss: 177.7861\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.2289 - val_loss: 176.7050\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.9868 - val_loss: 176.5142\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.3330 - val_loss: 176.2022\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.7708 - val_loss: 175.5983\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 160.4362 - val_loss: 175.1498\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.0356 - val_loss: 174.3250\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.5338 - val_loss: 173.2652\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.2285 - val_loss: 172.8416\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.0621 - val_loss: 171.9813\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.3201 - val_loss: 171.8951\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.9760 - val_loss: 170.3863\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.6880 - val_loss: 170.4594\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.3625 - val_loss: 170.0851\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.4227 - val_loss: 168.8928\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.0996 - val_loss: 168.2961\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.8692 - val_loss: 168.3496\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.3222 - val_loss: 167.1679\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.7917 - val_loss: 166.4889\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.7119 - val_loss: 166.7828\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.9735 - val_loss: 165.7638\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.6499 - val_loss: 165.9296\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.3046 - val_loss: 164.6260\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.8379 - val_loss: 164.0835\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.7002 - val_loss: 163.7783\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.4368 - val_loss: 162.8778\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8590 - val_loss: 162.8830\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 151.4520 - val_loss: 162.5412\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.0806 - val_loss: 161.6152\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.7535 - val_loss: 161.1312\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.7077 - val_loss: 161.2831\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.1665 - val_loss: 161.1512\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.9548 - val_loss: 159.9595\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.5464 - val_loss: 159.5701\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.1048 - val_loss: 159.6215\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.0737 - val_loss: 158.9811\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.6167 - val_loss: 158.2573\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.7273 - val_loss: 158.8400\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.0555 - val_loss: 157.4779\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.8415 - val_loss: 157.9556\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.4541 - val_loss: 157.4824\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.2236 - val_loss: 157.3643\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.1075 - val_loss: 157.4957\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.0118 - val_loss: 156.4825\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.7056 - val_loss: 156.0129\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.0622 - val_loss: 156.0879\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.1876 - val_loss: 155.8374\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.0241 - val_loss: 155.6653\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.3854 - val_loss: 154.9111\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1453.5271 - val_loss: 1475.4150\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1378.1832 - val_loss: 1385.2115\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1279.8234 - val_loss: 1270.4437\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1156.8873 - val_loss: 1135.2528\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1014.2707 - val_loss: 979.3359\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 854.7432 - val_loss: 811.7568\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 690.5421 - val_loss: 645.2215\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 533.8651 - val_loss: 496.2892\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 403.2347 - val_loss: 379.2433\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 310.8527 - val_loss: 301.3736\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 257.6626 - val_loss: 258.8366\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 230.3690 - val_loss: 239.3871\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 218.4807 - val_loss: 229.9275\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.7216 - val_loss: 225.7205\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.6376 - val_loss: 221.0561\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.5234 - val_loss: 217.9945\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.6897 - val_loss: 216.0359\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.9685 - val_loss: 213.4879\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.7612 - val_loss: 211.8289\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.8481 - val_loss: 209.9116\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.9501 - val_loss: 207.5683\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.2729 - val_loss: 207.0463\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.1395 - val_loss: 204.6886\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.9260 - val_loss: 203.0017\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.1565 - val_loss: 201.1851\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.5376 - val_loss: 200.3122\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.1845 - val_loss: 199.5057\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.0235 - val_loss: 198.9446\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 180.6519 - val_loss: 197.3800\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.8176 - val_loss: 196.0175\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.4024 - val_loss: 194.8649\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.0921 - val_loss: 193.7454\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 176.0295 - val_loss: 193.1719\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.0556 - val_loss: 192.1080\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.1768 - val_loss: 191.1940\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.4444 - val_loss: 190.6007\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.2533 - val_loss: 189.7243\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.3476 - val_loss: 187.8633\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.2259 - val_loss: 187.9278\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.6318 - val_loss: 187.7081\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 168.7775 - val_loss: 186.6214\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.1080 - val_loss: 185.6852\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.3460 - val_loss: 184.7673\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.5172 - val_loss: 183.9302\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.8969 - val_loss: 183.0403\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.1372 - val_loss: 182.9378\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.4350 - val_loss: 182.5996\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.4881 - val_loss: 180.8509\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.0614 - val_loss: 180.7369\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.3271 - val_loss: 179.2380\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.6315 - val_loss: 178.9787\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.2427 - val_loss: 178.6062\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.4544 - val_loss: 179.2129\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.7535 - val_loss: 177.6833\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.3148 - val_loss: 176.4641\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.9308 - val_loss: 177.3529\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.6249 - val_loss: 175.4910\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.6172 - val_loss: 174.2753\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.5565 - val_loss: 173.8967\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.9841 - val_loss: 174.2980\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.5267 - val_loss: 173.2088\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.9635 - val_loss: 172.2504\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.5204 - val_loss: 172.6033\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.7849 - val_loss: 171.2342\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 153.2788 - val_loss: 170.8880\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.9095 - val_loss: 170.4249\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.0206 - val_loss: 169.2153\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.3913 - val_loss: 169.2247\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.1694 - val_loss: 168.9160\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.1654 - val_loss: 168.1151\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0262 - val_loss: 167.1780\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.1394 - val_loss: 167.3390\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.8168 - val_loss: 166.9134\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.1031 - val_loss: 165.8665\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.5537 - val_loss: 165.5553\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.9624 - val_loss: 164.3988\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.9596 - val_loss: 163.8886\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.9162 - val_loss: 163.9629\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.5001 - val_loss: 163.7019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.3806 - val_loss: 163.0451\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.6226 - val_loss: 162.1551\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.1999 - val_loss: 162.1412\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.8525 - val_loss: 160.9898\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.3039 - val_loss: 160.8177\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.0157 - val_loss: 159.8385\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.0886 - val_loss: 161.2356\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.0736 - val_loss: 159.4689\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.4906 - val_loss: 158.9588\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.1289 - val_loss: 158.1940\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.7785 - val_loss: 158.4521\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.0150 - val_loss: 157.5435\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.9215 - val_loss: 157.6867\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.4688 - val_loss: 156.4036\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.1194 - val_loss: 156.0895\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.4447 - val_loss: 157.1283\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.1497 - val_loss: 155.8991\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.0712 - val_loss: 155.8783\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.7906 - val_loss: 154.2501\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.2237 - val_loss: 154.4212\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.9350 - val_loss: 153.9780\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1566.6172 - val_loss: 1428.4431\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1522.9856 - val_loss: 1378.6549\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1459.3289 - val_loss: 1307.2756\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1369.1517 - val_loss: 1205.4677\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1243.6451 - val_loss: 1073.1378\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1084.4396 - val_loss: 911.5805\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 896.6690 - val_loss: 735.9641\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 704.7645 - val_loss: 559.3686\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 526.5780 - val_loss: 411.7895\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 386.9608 - val_loss: 312.8855\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 302.0438 - val_loss: 252.5570\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 256.5930 - val_loss: 225.7711\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 236.7057 - val_loss: 214.5342\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 225.6504 - val_loss: 208.0666\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 217.8246 - val_loss: 204.1947\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.0600 - val_loss: 201.1150\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.4638 - val_loss: 198.3778\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.6687 - val_loss: 196.3307\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.1628 - val_loss: 194.2299\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.9937 - val_loss: 192.6535\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.2227 - val_loss: 191.4045\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.7659 - val_loss: 189.7894\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.7054 - val_loss: 188.2493\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.5289 - val_loss: 187.3841\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.8234 - val_loss: 186.2159\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.9388 - val_loss: 184.9112\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.4250 - val_loss: 184.0947\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.0524 - val_loss: 183.0130\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.7605 - val_loss: 181.8534\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.6143 - val_loss: 181.1012\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.5369 - val_loss: 179.7159\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.4513 - val_loss: 179.9208\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.2612 - val_loss: 178.5351\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.4965 - val_loss: 178.0436\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.2026 - val_loss: 177.3411\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.5033 - val_loss: 176.9696\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.4503 - val_loss: 176.1188\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.7183 - val_loss: 175.0952\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.8060 - val_loss: 174.6068\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.2858 - val_loss: 174.6319\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.2794 - val_loss: 174.1420\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.8562 - val_loss: 173.3532\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 166.9442 - val_loss: 172.5838\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 166.4590 - val_loss: 172.0002\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.5186 - val_loss: 171.3106\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.2436 - val_loss: 171.2539\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.5113 - val_loss: 171.0810\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.7054 - val_loss: 170.3656\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.2894 - val_loss: 169.8546\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.0881 - val_loss: 169.6734\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.0144 - val_loss: 169.3221\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.5152 - val_loss: 168.6143\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.9112 - val_loss: 167.9808\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.2655 - val_loss: 168.3376\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.8661 - val_loss: 167.8316\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.4039 - val_loss: 167.3058\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 158.8575 - val_loss: 167.6258\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.2908 - val_loss: 166.4153\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.9640 - val_loss: 166.7422\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.1414 - val_loss: 165.6360\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.6844 - val_loss: 165.6418\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.0479 - val_loss: 165.2112\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.3204 - val_loss: 164.7834\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.6010 - val_loss: 164.9393\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.1083 - val_loss: 165.0688\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.6941 - val_loss: 163.6004\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.8168 - val_loss: 163.8198\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.5844 - val_loss: 163.7181\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.4499 - val_loss: 162.5979\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.2061 - val_loss: 162.1429\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.4756 - val_loss: 162.3725\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.8056 - val_loss: 161.9669\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.6888 - val_loss: 161.9091\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.8823 - val_loss: 161.9116\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.6423 - val_loss: 161.6554\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.8532 - val_loss: 161.3251\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.5404 - val_loss: 160.5282\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.3826 - val_loss: 160.7832\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.6104 - val_loss: 159.6300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.3855 - val_loss: 159.9666\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.3466 - val_loss: 159.7732\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.0222 - val_loss: 159.2938\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.6449 - val_loss: 158.8320\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.0968 - val_loss: 158.7118\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.1072 - val_loss: 158.0312\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.4233 - val_loss: 158.3630\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.2393 - val_loss: 157.3911\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.5293 - val_loss: 157.4587\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.5696 - val_loss: 157.7656\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.8227 - val_loss: 157.6426\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.4955 - val_loss: 156.8735\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.8853 - val_loss: 157.3502\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.6679 - val_loss: 156.9158\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.3721 - val_loss: 156.9664\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.2079 - val_loss: 156.5052\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.7665 - val_loss: 155.8909\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.1931 - val_loss: 155.6661\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.8557 - val_loss: 156.4624\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.2697 - val_loss: 155.4428\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.5487 - val_loss: 155.1521\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 9ms/step - loss: 1599.8646 - val_loss: 1422.4080\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1566.5839 - val_loss: 1390.1985\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1526.1387 - val_loss: 1347.6949\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1471.2585 - val_loss: 1289.7628\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1399.7292 - val_loss: 1217.5267\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1311.6417 - val_loss: 1130.4030\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1206.7101 - val_loss: 1027.7556\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1084.8168 - val_loss: 910.6515\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 950.4312 - val_loss: 783.1636\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 806.5499 - val_loss: 656.7620\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 666.8726 - val_loss: 537.3771\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 540.1812 - val_loss: 434.0192\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 432.4866 - val_loss: 354.6930\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 351.7237 - val_loss: 299.1368\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 297.0329 - val_loss: 266.2915\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 263.6008 - val_loss: 249.1346\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 244.0980 - val_loss: 240.6335\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 232.2637 - val_loss: 236.4590\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 224.9831 - val_loss: 234.0453\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 219.6181 - val_loss: 231.8010\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 215.1766 - val_loss: 229.6538\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 211.6112 - val_loss: 227.1342\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 208.4556 - val_loss: 225.5230\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.5843 - val_loss: 223.5868\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.6629 - val_loss: 221.4678\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.9151 - val_loss: 219.6609\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.4878 - val_loss: 217.3773\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.1484 - val_loss: 215.7296\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.1159 - val_loss: 213.5822\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.8181 - val_loss: 212.0627\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.9214 - val_loss: 210.6433\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.1064 - val_loss: 209.1453\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.3369 - val_loss: 207.3764\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.7446 - val_loss: 206.1886\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.1962 - val_loss: 205.3458\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.7211 - val_loss: 203.8818\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.4314 - val_loss: 202.8801\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.2006 - val_loss: 201.8257\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.5842 - val_loss: 201.0869\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.4446 - val_loss: 199.5695\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.4965 - val_loss: 198.4284\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.4053 - val_loss: 198.7129\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.3531 - val_loss: 198.1830\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.2383 - val_loss: 196.6499\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.4231 - val_loss: 195.3775\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.6123 - val_loss: 195.9156\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.4259 - val_loss: 194.4920\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.5908 - val_loss: 193.5795\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.0703 - val_loss: 193.8297\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.1283 - val_loss: 192.3936\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 165.2827 - val_loss: 191.7582\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.5737 - val_loss: 190.9165\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.8851 - val_loss: 190.5777\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.0444 - val_loss: 189.9296\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.2816 - val_loss: 188.9185\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.7085 - val_loss: 189.2847\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.8943 - val_loss: 188.2039\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.3120 - val_loss: 187.1870\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.7491 - val_loss: 187.1100\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.2455 - val_loss: 186.4966\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.2503 - val_loss: 186.4487\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.5747 - val_loss: 185.5716\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.2264 - val_loss: 184.5311\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.3398 - val_loss: 184.3421\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.7263 - val_loss: 183.9650\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 155.0304 - val_loss: 182.5334\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.5532 - val_loss: 182.4270\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.8344 - val_loss: 181.5631\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.1707 - val_loss: 181.0357\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.6517 - val_loss: 180.6522\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.3397 - val_loss: 179.9295\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.5533 - val_loss: 180.2906\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.8623 - val_loss: 178.7099\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.5319 - val_loss: 178.2643\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.8768 - val_loss: 177.9964\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.2810 - val_loss: 177.1120\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.5377 - val_loss: 176.4323\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.0887 - val_loss: 176.3828\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 147.5854 - val_loss: 176.1705\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.6500 - val_loss: 175.1975\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.3679 - val_loss: 174.8306\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.8092 - val_loss: 174.9260\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.0898 - val_loss: 174.1544\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.5230 - val_loss: 173.5400\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.1085 - val_loss: 173.2816\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.5844 - val_loss: 172.3827\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.0857 - val_loss: 172.8290\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.6723 - val_loss: 171.8913\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.3047 - val_loss: 171.4413\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.8669 - val_loss: 171.0807\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.2922 - val_loss: 171.4295\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.8302 - val_loss: 170.3244\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.3563 - val_loss: 170.2849\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.8796 - val_loss: 169.6894\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.4317 - val_loss: 170.2786\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.1460 - val_loss: 169.4966\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 138.4792 - val_loss: 169.5267\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.0848 - val_loss: 168.6827\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.6441 - val_loss: 168.6495\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.2041 - val_loss: 167.6995\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1546.7534 - val_loss: 1599.7662\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1510.4690 - val_loss: 1564.5228\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1476.3644 - val_loss: 1527.5166\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1436.4656 - val_loss: 1478.5797\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1381.3054 - val_loss: 1410.9684\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1304.0449 - val_loss: 1317.6406\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1202.0024 - val_loss: 1193.6678\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1069.5421 - val_loss: 1046.4532\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 916.1211 - val_loss: 875.9963\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 748.0078 - val_loss: 701.2535\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 581.3737 - val_loss: 541.4435\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 437.6298 - val_loss: 413.4869\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 329.8933 - val_loss: 324.9699\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 262.5966 - val_loss: 274.5138\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 226.5447 - val_loss: 250.8809\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.1319 - val_loss: 240.0496\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.6200 - val_loss: 234.1761\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.8797 - val_loss: 230.4933\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.1563 - val_loss: 227.6487\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.4406 - val_loss: 224.6387\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.1082 - val_loss: 222.1675\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.9056 - val_loss: 219.5688\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.8688 - val_loss: 217.9301\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.9174 - val_loss: 216.1279\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.9877 - val_loss: 214.6248\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.4529 - val_loss: 212.4668\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.1740 - val_loss: 211.5712\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.6342 - val_loss: 209.5911\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.2884 - val_loss: 208.3612\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.7635 - val_loss: 206.9742\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.5137 - val_loss: 205.7912\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.5135 - val_loss: 204.6738\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.5894 - val_loss: 203.6498\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.5472 - val_loss: 202.6055\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.7262 - val_loss: 201.8120\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.9966 - val_loss: 200.8270\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.3039 - val_loss: 199.9659\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.5227 - val_loss: 199.5347\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.8068 - val_loss: 198.6817\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.9934 - val_loss: 197.7421\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.2948 - val_loss: 196.8281\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.7408 - val_loss: 196.0393\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.1268 - val_loss: 195.0643\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.6416 - val_loss: 194.7696\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.9633 - val_loss: 194.3622\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.3844 - val_loss: 193.4876\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.8620 - val_loss: 193.1432\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.3836 - val_loss: 192.1634\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.8129 - val_loss: 191.6601\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.3441 - val_loss: 190.9261\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.8725 - val_loss: 190.4714\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.5141 - val_loss: 189.7793\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.2141 - val_loss: 189.3891\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.5921 - val_loss: 189.0322\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.4526 - val_loss: 188.6766\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.9497 - val_loss: 188.2454\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.9827 - val_loss: 187.1831\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.2933 - val_loss: 187.3351\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.7555 - val_loss: 187.0829\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.6755 - val_loss: 186.4293\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.1169 - val_loss: 186.0546\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.8045 - val_loss: 185.5934\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.5916 - val_loss: 184.8621\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.1139 - val_loss: 184.3850\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.9129 - val_loss: 184.0206\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.6795 - val_loss: 183.8323\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.6767 - val_loss: 183.1216\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.8984 - val_loss: 182.4072\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.4293 - val_loss: 182.2365\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.1899 - val_loss: 181.9696\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.9386 - val_loss: 181.9505\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.4297 - val_loss: 180.8370\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.1660 - val_loss: 180.5948\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.7675 - val_loss: 179.9978\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.5732 - val_loss: 179.8948\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.3195 - val_loss: 179.4556\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.8419 - val_loss: 178.8738\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.9049 - val_loss: 178.8901\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 146.2350 - val_loss: 178.0959\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.1357 - val_loss: 178.1529\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.6036 - val_loss: 177.4787\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.5233 - val_loss: 176.8011\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 145.0846 - val_loss: 176.2709\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 144.7840 - val_loss: 176.2733\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 144.4671 - val_loss: 175.7025\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 144.2011 - val_loss: 175.1449\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.0621 - val_loss: 174.8040\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.5826 - val_loss: 175.1720\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 143.4448 - val_loss: 173.9711\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 143.1494 - val_loss: 173.4479\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 143.8354 - val_loss: 174.0820\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.4710 - val_loss: 173.2966\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 142.2710 - val_loss: 172.8745\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 142.1084 - val_loss: 172.6660\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.8779 - val_loss: 171.9433\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 141.4494 - val_loss: 171.8103\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.3743 - val_loss: 171.2783\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.8775 - val_loss: 170.6374\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.7520 - val_loss: 170.7817\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.4100 - val_loss: 170.1117\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1542.1061 - val_loss: 1543.4006\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1511.9142 - val_loss: 1510.7854\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1475.0243 - val_loss: 1467.3192\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1422.9081 - val_loss: 1403.8348\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1345.2554 - val_loss: 1312.8062\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1240.2664 - val_loss: 1192.2573\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1103.8611 - val_loss: 1043.6125\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 940.2828 - val_loss: 870.0226\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 756.6163 - val_loss: 687.8690\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 577.6807 - val_loss: 520.6977\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 421.6876 - val_loss: 395.1242\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 312.0621 - val_loss: 314.0394\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 248.1595 - val_loss: 273.8031\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 219.3262 - val_loss: 258.0520\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.5381 - val_loss: 250.3847\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.4705 - val_loss: 245.0752\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.0909 - val_loss: 241.2679\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.8119 - val_loss: 238.0337\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.9865 - val_loss: 234.7311\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.7453 - val_loss: 232.2149\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.7083 - val_loss: 230.2486\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.4802 - val_loss: 227.5248\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.9155 - val_loss: 225.6149\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.8521 - val_loss: 222.9257\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.5359 - val_loss: 221.2980\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.6453 - val_loss: 219.4869\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.4901 - val_loss: 217.8454\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.1861 - val_loss: 217.0036\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.0658 - val_loss: 215.4498\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.0560 - val_loss: 214.1754\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.1041 - val_loss: 212.8396\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.1392 - val_loss: 211.9435\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.2655 - val_loss: 210.6287\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.3811 - val_loss: 209.0222\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 166.8289 - val_loss: 209.0910\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.6241 - val_loss: 207.6124\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.7985 - val_loss: 206.9451\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.2548 - val_loss: 205.4121\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.4237 - val_loss: 204.8375\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.8437 - val_loss: 204.2369\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.2713 - val_loss: 203.0162\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.6700 - val_loss: 202.8896\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.0088 - val_loss: 201.7889\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.4341 - val_loss: 200.9372\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.7408 - val_loss: 200.9306\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.2267 - val_loss: 200.1325\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.5776 - val_loss: 199.1825\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.9807 - val_loss: 198.0726\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.7749 - val_loss: 198.3062\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.9808 - val_loss: 197.8963\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.5528 - val_loss: 196.7310\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.6775 - val_loss: 195.8640\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.4113 - val_loss: 195.4684\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.7910 - val_loss: 195.1282\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.1388 - val_loss: 194.4893\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.2159 - val_loss: 193.8948\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.2607 - val_loss: 192.9291\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.9989 - val_loss: 192.1330\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.4407 - val_loss: 192.2417\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.9959 - val_loss: 191.0357\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.2907 - val_loss: 190.5157\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.9739 - val_loss: 190.2499\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.3606 - val_loss: 189.5815\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.8925 - val_loss: 189.2268\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.7462 - val_loss: 188.8796\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.7605 - val_loss: 188.8463\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 148.8879 - val_loss: 187.1835\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.3725 - val_loss: 187.4990\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 148.2775 - val_loss: 186.6519\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.9978 - val_loss: 186.3719\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.4916 - val_loss: 186.0718\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.0603 - val_loss: 185.5828\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.9431 - val_loss: 184.8770\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 146.4404 - val_loss: 184.6603\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.1831 - val_loss: 184.5105\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.5759 - val_loss: 184.3509\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.6006 - val_loss: 183.6565\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.2243 - val_loss: 184.1802\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 144.7774 - val_loss: 183.3505\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.4334 - val_loss: 182.6745\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.0656 - val_loss: 182.6730\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.1747 - val_loss: 182.7851\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.5141 - val_loss: 182.0381\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.3914 - val_loss: 182.4151\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.9484 - val_loss: 181.5627\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.7581 - val_loss: 181.1659\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.5490 - val_loss: 181.6861\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.1003 - val_loss: 180.7702\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.4654 - val_loss: 180.5249\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.5276 - val_loss: 180.5239\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.4887 - val_loss: 179.9693\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.2240 - val_loss: 179.9059\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.7766 - val_loss: 179.6569\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.5275 - val_loss: 179.3234\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.2374 - val_loss: 180.0773\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.1880 - val_loss: 178.7992\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.6918 - val_loss: 179.1056\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 139.6748 - val_loss: 179.0790\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.6743 - val_loss: 178.9803\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.1701 - val_loss: 178.4820\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1526.1066 - val_loss: 1530.1884\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1469.3816 - val_loss: 1472.5745\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1399.0793 - val_loss: 1394.0862\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1304.6863 - val_loss: 1289.5255\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1184.6257 - val_loss: 1157.4091\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1039.6064 - val_loss: 1007.1829\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 879.7941 - val_loss: 841.8191\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 711.7601 - val_loss: 674.2927\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 553.6327 - val_loss: 520.1008\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 417.9500 - val_loss: 398.9925\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 320.3528 - val_loss: 310.1678\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 259.4071 - val_loss: 258.6445\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 229.1792 - val_loss: 231.3324\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 216.1216 - val_loss: 217.1684\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 209.3369 - val_loss: 211.0053\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.9894 - val_loss: 207.0475\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.4640 - val_loss: 203.5993\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.9696 - val_loss: 201.0544\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.1160 - val_loss: 197.8495\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.0555 - val_loss: 196.6667\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.1885 - val_loss: 194.7737\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.4261 - val_loss: 193.3126\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.4173 - val_loss: 191.3314\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.6516 - val_loss: 191.2702\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.8827 - val_loss: 188.6700\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.6485 - val_loss: 187.7887\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.1050 - val_loss: 186.7859\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.8737 - val_loss: 184.6953\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.5589 - val_loss: 183.1329\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.3739 - val_loss: 182.2584\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.3983 - val_loss: 181.3263\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.2493 - val_loss: 180.0457\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.8356 - val_loss: 179.6977\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.2393 - val_loss: 178.6097\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.9187 - val_loss: 177.7647\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.8190 - val_loss: 176.9135\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.0030 - val_loss: 176.1561\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.0903 - val_loss: 175.7087\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.0417 - val_loss: 174.4888\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.0570 - val_loss: 173.0160\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.2976 - val_loss: 172.0122\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.4892 - val_loss: 171.4975\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.5567 - val_loss: 171.2182\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.7010 - val_loss: 170.0311\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.8610 - val_loss: 168.7238\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.7503 - val_loss: 169.1619\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.1443 - val_loss: 167.8640\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.4433 - val_loss: 167.1199\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.8533 - val_loss: 165.8718\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.8711 - val_loss: 165.8809\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.4042 - val_loss: 165.0511\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 162.7930 - val_loss: 163.9757\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.8810 - val_loss: 163.9353\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.2085 - val_loss: 164.1544\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.9872 - val_loss: 162.5548\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.1302 - val_loss: 162.7364\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.3823 - val_loss: 161.3831\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.6436 - val_loss: 161.1287\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.9929 - val_loss: 160.4028\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.6623 - val_loss: 159.9478\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8989 - val_loss: 159.8273\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.4846 - val_loss: 158.3750\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.7781 - val_loss: 158.7282\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.0361 - val_loss: 157.7211\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.4357 - val_loss: 157.1805\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 153.8521 - val_loss: 156.6359\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.4983 - val_loss: 156.8743\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.2492 - val_loss: 155.9898\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.3684 - val_loss: 156.2284\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.2683 - val_loss: 154.5813\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.5283 - val_loss: 155.6151\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.9988 - val_loss: 155.1158\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.6020 - val_loss: 154.1720\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.3718 - val_loss: 153.2285\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.6121 - val_loss: 153.5136\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.5675 - val_loss: 152.8930\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.8457 - val_loss: 153.2713\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.3396 - val_loss: 152.4318\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 148.0785 - val_loss: 151.6962\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.0263 - val_loss: 152.1846\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.0641 - val_loss: 151.1653\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.8183 - val_loss: 151.4173\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.4874 - val_loss: 151.2104\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.1376 - val_loss: 149.9685\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.5658 - val_loss: 149.8236\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.3416 - val_loss: 149.6274\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.7522 - val_loss: 149.5323\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.6513 - val_loss: 148.4994\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.0414 - val_loss: 149.2701\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.7986 - val_loss: 148.9242\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.7068 - val_loss: 147.8335\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.6728 - val_loss: 147.9003\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.0822 - val_loss: 147.9922\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.5211 - val_loss: 147.2536\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.3114 - val_loss: 147.1165\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.7248 - val_loss: 146.8421\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.8852 - val_loss: 146.3914\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.3238 - val_loss: 146.4335\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.0979 - val_loss: 146.3236\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.7589 - val_loss: 145.7422\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1496.7897 - val_loss: 1454.1754\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1440.5281 - val_loss: 1384.3971\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1356.7902 - val_loss: 1280.2689\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1237.2214 - val_loss: 1142.2018\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1085.7301 - val_loss: 975.5503\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 908.1136 - val_loss: 790.3251\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 721.1416 - val_loss: 606.9275\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 541.6837 - val_loss: 456.9461\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 398.6940 - val_loss: 348.4372\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 301.8100 - val_loss: 289.3108\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 249.3250 - val_loss: 262.5085\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 225.2334 - val_loss: 251.0906\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 214.3110 - val_loss: 242.6063\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.8648 - val_loss: 236.4642\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.7150 - val_loss: 230.9875\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.0826 - val_loss: 226.8108\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.5276 - val_loss: 222.6730\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.9007 - val_loss: 219.1245\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.5886 - val_loss: 216.8531\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.7519 - val_loss: 213.5154\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.0544 - val_loss: 212.9346\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.8431 - val_loss: 209.6005\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.3910 - val_loss: 208.0405\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.7777 - val_loss: 206.9478\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.7405 - val_loss: 206.2233\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.7804 - val_loss: 204.5761\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.1995 - val_loss: 201.9419\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.3559 - val_loss: 201.2509\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.6039 - val_loss: 199.8744\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.5912 - val_loss: 198.9075\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.7909 - val_loss: 198.5285\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.2135 - val_loss: 195.9691\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.9924 - val_loss: 195.0329\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.2781 - val_loss: 194.2025\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.4640 - val_loss: 193.9630\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.5919 - val_loss: 192.4964\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.0227 - val_loss: 191.2466\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.4626 - val_loss: 190.1535\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.3694 - val_loss: 189.3123\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.7660 - val_loss: 189.1722\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.2920 - val_loss: 187.6756\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.1413 - val_loss: 187.4483\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.6829 - val_loss: 185.7516\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.0178 - val_loss: 185.5425\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.0138 - val_loss: 184.2636\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.2631 - val_loss: 183.5150\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.6420 - val_loss: 182.8079\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.8512 - val_loss: 182.0982\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.1542 - val_loss: 181.7238\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.4808 - val_loss: 180.3442\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.8262 - val_loss: 180.1032\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.1652 - val_loss: 178.7674\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.4045 - val_loss: 178.9310\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.9894 - val_loss: 177.9343\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.8646 - val_loss: 176.6708\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.3360 - val_loss: 175.9950\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.5752 - val_loss: 175.0530\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.9502 - val_loss: 174.7604\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.2383 - val_loss: 174.3468\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.5563 - val_loss: 173.2868\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.0146 - val_loss: 172.9823\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.1782 - val_loss: 171.8777\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.7043 - val_loss: 171.8430\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.1125 - val_loss: 170.8766\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.7821 - val_loss: 169.5489\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.2708 - val_loss: 170.0852\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.4698 - val_loss: 170.2737\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.8922 - val_loss: 168.6911\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8071 - val_loss: 168.7592\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.9169 - val_loss: 168.3248\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.3523 - val_loss: 168.0259\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.8969 - val_loss: 166.6655\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.4710 - val_loss: 166.8781\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.8609 - val_loss: 165.6871\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.2276 - val_loss: 164.9679\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.9408 - val_loss: 165.7949\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.4616 - val_loss: 165.4854\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.4651 - val_loss: 163.2263\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.2138 - val_loss: 164.2945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.3018 - val_loss: 163.2224\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.9603 - val_loss: 163.0997\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.2959 - val_loss: 163.2501\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.7817 - val_loss: 163.2270\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.7728 - val_loss: 162.0486\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.0176 - val_loss: 161.6766\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.6910 - val_loss: 161.2817\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.5401 - val_loss: 161.6983\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.8240 - val_loss: 160.7863\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.7316 - val_loss: 161.2771\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.1338 - val_loss: 159.9461\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.8591 - val_loss: 160.4602\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.5692 - val_loss: 159.8274\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.5764 - val_loss: 159.5632\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.3012 - val_loss: 160.4446\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.4698 - val_loss: 159.4645\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.5614 - val_loss: 158.4792\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.0549 - val_loss: 158.8031\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.6960 - val_loss: 159.7744\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.2950 - val_loss: 158.0419\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.2043 - val_loss: 157.3802\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1536.7330 - val_loss: 1510.3232\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1503.8630 - val_loss: 1471.9037\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1454.2878 - val_loss: 1410.7644\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1376.7460 - val_loss: 1317.9181\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1264.6403 - val_loss: 1194.3010\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1122.0454 - val_loss: 1038.5898\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 948.7634 - val_loss: 860.4872\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 760.2806 - val_loss: 672.8101\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 574.9348 - val_loss: 502.1822\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 420.3835 - val_loss: 368.1507\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 310.9440 - val_loss: 283.9207\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 252.2910 - val_loss: 240.3760\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 225.6208 - val_loss: 221.3107\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 215.8802 - val_loss: 212.0998\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.8919 - val_loss: 207.0946\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.3709 - val_loss: 203.5359\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.5872 - val_loss: 200.5069\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.2125 - val_loss: 197.9645\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.8507 - val_loss: 196.2610\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.9234 - val_loss: 193.6524\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.0392 - val_loss: 191.6756\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.6794 - val_loss: 189.8635\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.9186 - val_loss: 187.6451\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.4559 - val_loss: 186.0400\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.0985 - val_loss: 184.5417\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.9974 - val_loss: 182.5972\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.7080 - val_loss: 181.5978\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.6213 - val_loss: 180.6357\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.4962 - val_loss: 178.7295\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.7507 - val_loss: 177.8488\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.6467 - val_loss: 175.9478\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.5425 - val_loss: 175.4929\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.5303 - val_loss: 174.1765\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.9134 - val_loss: 173.1831\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.8243 - val_loss: 172.0987\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.9980 - val_loss: 171.0611\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.4664 - val_loss: 169.8881\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.4682 - val_loss: 168.5843\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.5784 - val_loss: 168.0647\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.1293 - val_loss: 167.3918\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.2850 - val_loss: 165.8988\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.5176 - val_loss: 165.3458\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.9176 - val_loss: 164.2128\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.3868 - val_loss: 164.4021\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 172.5300 - val_loss: 163.2940\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.1158 - val_loss: 162.3509\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.1122 - val_loss: 161.5282\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.7070 - val_loss: 161.1821\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.9557 - val_loss: 160.1032\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.9745 - val_loss: 160.4537\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.9193 - val_loss: 158.7576\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.5538 - val_loss: 159.2414\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.7295 - val_loss: 157.7637\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.1978 - val_loss: 157.4793\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.9205 - val_loss: 157.0738\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.5460 - val_loss: 156.3533\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.5612 - val_loss: 156.2262\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.0952 - val_loss: 154.7721\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 164.5060 - val_loss: 154.3265\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.9388 - val_loss: 153.7386\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.4910 - val_loss: 153.7262\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.1321 - val_loss: 153.0633\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.5428 - val_loss: 152.8617\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.2131 - val_loss: 151.7599\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.5303 - val_loss: 151.2082\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.9152 - val_loss: 150.7061\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.6389 - val_loss: 150.3996\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.0135 - val_loss: 150.5180\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.6877 - val_loss: 149.3422\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.9468 - val_loss: 149.6911\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.3863 - val_loss: 148.2282\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.8848 - val_loss: 148.5734\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.7355 - val_loss: 147.6484\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.0000 - val_loss: 147.0401\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8617 - val_loss: 146.6575\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.2246 - val_loss: 146.2722\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.8573 - val_loss: 145.9978\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.6087 - val_loss: 145.5619\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 155.1206 - val_loss: 145.0167\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.5435 - val_loss: 144.3385\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.0411 - val_loss: 145.2367\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.1206 - val_loss: 144.2918\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.0646 - val_loss: 143.9133\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.0806 - val_loss: 143.7397\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.5232 - val_loss: 143.8740\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.6098 - val_loss: 142.6109\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.3474 - val_loss: 142.9541\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.4201 - val_loss: 142.6841\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.9380 - val_loss: 142.3168\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.7251 - val_loss: 142.7954\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.1942 - val_loss: 141.4701\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.7252 - val_loss: 140.7208\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.3965 - val_loss: 141.1341\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.2177 - val_loss: 140.5602\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.8902 - val_loss: 140.6559\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.4450 - val_loss: 140.1064\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.1470 - val_loss: 140.2468\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.1016 - val_loss: 139.7032\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.9070 - val_loss: 139.7312\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.2234 - val_loss: 139.2640\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1515.0829 - val_loss: 1559.1996\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1463.7872 - val_loss: 1503.4644\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1400.8820 - val_loss: 1430.2290\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1318.5389 - val_loss: 1334.3145\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1211.2091 - val_loss: 1214.7676\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1079.1882 - val_loss: 1067.0900\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 924.5316 - val_loss: 896.0243\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 753.8528 - val_loss: 721.2296\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 585.8468 - val_loss: 559.4568\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 436.3959 - val_loss: 432.6887\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 326.8227 - val_loss: 344.8497\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 258.8206 - val_loss: 297.7686\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 223.8241 - val_loss: 275.9476\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.3212 - val_loss: 264.5065\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.5709 - val_loss: 258.0599\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.8985 - val_loss: 253.5945\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.5782 - val_loss: 249.0201\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.8889 - val_loss: 246.4469\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.7442 - val_loss: 244.0502\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.4280 - val_loss: 241.9076\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.8571 - val_loss: 238.7293\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.7167 - val_loss: 237.0653\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.2813 - val_loss: 235.2724\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.8128 - val_loss: 232.4639\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.1923 - val_loss: 230.7906\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.0911 - val_loss: 229.7454\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.0801 - val_loss: 227.7740\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.8105 - val_loss: 226.9067\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.9127 - val_loss: 224.7308\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.8145 - val_loss: 223.3001\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.7218 - val_loss: 222.2108\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.9026 - val_loss: 221.1241\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.0106 - val_loss: 219.9040\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.0036 - val_loss: 218.4328\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.4052 - val_loss: 217.3755\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.4507 - val_loss: 215.7358\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.9511 - val_loss: 214.3824\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.3008 - val_loss: 213.5558\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.7151 - val_loss: 213.3042\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.1509 - val_loss: 212.1852\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.8183 - val_loss: 210.6589\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.2126 - val_loss: 210.5268\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.4021 - val_loss: 209.6454\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.9841 - val_loss: 208.6591\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.4829 - val_loss: 208.2239\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.7779 - val_loss: 206.6511\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.3976 - val_loss: 205.0922\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.8455 - val_loss: 205.3683\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.3682 - val_loss: 204.1538\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.9163 - val_loss: 203.3442\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.3026 - val_loss: 202.8936\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.0471 - val_loss: 202.7795\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.3332 - val_loss: 202.2908\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.0239 - val_loss: 200.5321\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.6711 - val_loss: 200.5023\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.1433 - val_loss: 200.0120\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.8375 - val_loss: 199.4716\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.5731 - val_loss: 199.5905\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.8459 - val_loss: 198.2137\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.3553 - val_loss: 197.1770\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.9476 - val_loss: 196.0565\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.4627 - val_loss: 196.3682\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.1187 - val_loss: 196.1305\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.7435 - val_loss: 195.0890\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.3259 - val_loss: 194.2177\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.1764 - val_loss: 193.9224\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.1498 - val_loss: 191.9065\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.1250 - val_loss: 192.5545\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 151.0662 - val_loss: 192.1008\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.3585 - val_loss: 191.6200\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 150.1005 - val_loss: 191.1655\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.9739 - val_loss: 190.4061\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.5116 - val_loss: 190.1040\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 149.4014 - val_loss: 189.3139\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.9246 - val_loss: 188.7825\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.5355 - val_loss: 187.8607\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.6236 - val_loss: 187.7514\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.1743 - val_loss: 188.2278\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 147.6123 - val_loss: 186.5598\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.6156 - val_loss: 185.9028\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 147.0488 - val_loss: 186.5090\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.6781 - val_loss: 185.8645\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.3465 - val_loss: 185.1617\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.8067 - val_loss: 185.2648\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.3028 - val_loss: 183.6066\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.5198 - val_loss: 183.1831\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.2361 - val_loss: 183.0417\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.2656 - val_loss: 182.7065\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.8969 - val_loss: 182.7776\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 144.6911 - val_loss: 181.9987\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.8325 - val_loss: 182.8658\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.2646 - val_loss: 180.9381\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.9511 - val_loss: 181.5683\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.9384 - val_loss: 180.7186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.7150 - val_loss: 180.9302\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.3934 - val_loss: 179.9211\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 143.3286 - val_loss: 179.9918\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.0054 - val_loss: 179.7582\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.8821 - val_loss: 179.8212\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.5214 - val_loss: 178.4893\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1496.6890 - val_loss: 1679.0281\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1464.8020 - val_loss: 1644.6506\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1430.9631 - val_loss: 1603.3363\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1390.1577 - val_loss: 1553.4331\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1339.6614 - val_loss: 1491.8297\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1275.2864 - val_loss: 1409.2373\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1192.0256 - val_loss: 1303.2705\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1088.2798 - val_loss: 1169.8256\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 959.4349 - val_loss: 1017.6354\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 817.8378 - val_loss: 848.4552\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 669.3922 - val_loss: 678.4741\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 527.6168 - val_loss: 525.9337\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 408.4554 - val_loss: 403.5167\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 319.5968 - val_loss: 319.3138\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 264.0355 - val_loss: 265.8431\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 231.4079 - val_loss: 237.8476\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 216.3047 - val_loss: 221.2821\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.3641 - val_loss: 214.6940\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.9587 - val_loss: 208.3054\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.2001 - val_loss: 205.3969\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.0216 - val_loss: 202.7301\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.5133 - val_loss: 199.9107\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.4367 - val_loss: 197.5890\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.3465 - val_loss: 197.0171\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.5712 - val_loss: 194.0177\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.5895 - val_loss: 192.6779\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.8075 - val_loss: 190.1308\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.2224 - val_loss: 189.0283\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.7620 - val_loss: 188.6618\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.4824 - val_loss: 186.0006\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.9471 - val_loss: 184.5230\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.8348 - val_loss: 184.6711\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.5865 - val_loss: 183.1572\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.2739 - val_loss: 181.3050\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.5236 - val_loss: 179.4966\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.7525 - val_loss: 180.4592\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.2042 - val_loss: 178.2884\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.5344 - val_loss: 176.3115\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.6979 - val_loss: 176.8573\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.5206 - val_loss: 175.6964\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.6597 - val_loss: 174.4654\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.9094 - val_loss: 173.7405\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.9552 - val_loss: 172.8284\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.2462 - val_loss: 172.0840\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.6176 - val_loss: 171.3434\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.6771 - val_loss: 170.3525\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.0175 - val_loss: 169.8934\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.1228 - val_loss: 168.7657\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.4607 - val_loss: 168.5019\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.7644 - val_loss: 167.2905\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.0238 - val_loss: 167.1169\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.3141 - val_loss: 165.7555\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.7381 - val_loss: 165.0424\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.2109 - val_loss: 165.4730\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.5225 - val_loss: 163.5087\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.6562 - val_loss: 164.1602\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.0577 - val_loss: 163.1096\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.3396 - val_loss: 162.3046\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.7081 - val_loss: 162.2583\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.2201 - val_loss: 161.2777\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.6837 - val_loss: 160.6965\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.0590 - val_loss: 159.8154\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.6060 - val_loss: 159.5034\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.9465 - val_loss: 158.5358\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.1821 - val_loss: 159.4597\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.6598 - val_loss: 158.3483\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 150.1916 - val_loss: 156.4703\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.8707 - val_loss: 156.9822\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 148.9877 - val_loss: 157.6270\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.3233 - val_loss: 155.3846\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.7936 - val_loss: 154.7330\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.4628 - val_loss: 155.1101\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.8369 - val_loss: 154.3717\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.6000 - val_loss: 154.1275\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.2142 - val_loss: 153.2468\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.2251 - val_loss: 153.4382\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.8142 - val_loss: 153.0960\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 144.2255 - val_loss: 151.7071\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 143.7685 - val_loss: 150.9071\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.5614 - val_loss: 151.8193\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.8330 - val_loss: 151.4211\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.5128 - val_loss: 150.0199\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.9428 - val_loss: 150.4607\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.6353 - val_loss: 150.2946\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.1045 - val_loss: 149.0711\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.8744 - val_loss: 150.0496\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.4500 - val_loss: 148.8476\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.9383 - val_loss: 148.5337\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.4099 - val_loss: 148.4945\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.9668 - val_loss: 147.5577\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.6494 - val_loss: 147.5582\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.4755 - val_loss: 147.3498\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.8721 - val_loss: 147.0122\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.5427 - val_loss: 146.8499\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.1480 - val_loss: 146.0893\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.9711 - val_loss: 145.6396\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.2047 - val_loss: 145.8985\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.2326 - val_loss: 144.7104\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.1824 - val_loss: 145.8424\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.4341 - val_loss: 145.6827\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1575.6003 - val_loss: 1528.5840\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1526.0962 - val_loss: 1478.9550\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1474.0510 - val_loss: 1421.9885\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1408.3920 - val_loss: 1348.4384\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1322.2201 - val_loss: 1253.6313\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1215.0410 - val_loss: 1134.9824\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1086.9867 - val_loss: 996.8599\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 937.6613 - val_loss: 848.5819\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 780.0082 - val_loss: 691.3027\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 622.7015 - val_loss: 543.3830\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 480.5822 - val_loss: 419.4967\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 369.0051 - val_loss: 327.3234\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 288.7254 - val_loss: 271.7186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 242.1431 - val_loss: 241.0548\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 217.6412 - val_loss: 227.2273\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 206.1664 - val_loss: 220.6165\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.2103 - val_loss: 217.2231\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.6943 - val_loss: 214.8168\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.1408 - val_loss: 212.7151\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.8358 - val_loss: 211.0073\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.8974 - val_loss: 209.7263\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.9893 - val_loss: 208.0683\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.4309 - val_loss: 206.6363\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.0883 - val_loss: 205.6440\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.3524 - val_loss: 204.3957\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.2576 - val_loss: 202.9902\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.8564 - val_loss: 202.3263\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.5003 - val_loss: 201.4255\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.6702 - val_loss: 200.5929\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.4422 - val_loss: 199.6526\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.4268 - val_loss: 199.0188\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.4118 - val_loss: 198.4555\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.3493 - val_loss: 197.6726\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.5729 - val_loss: 196.7836\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.7049 - val_loss: 196.3111\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.7454 - val_loss: 195.7292\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.9176 - val_loss: 195.1609\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.1046 - val_loss: 194.0823\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.3533 - val_loss: 193.9305\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.2030 - val_loss: 193.1648\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.4904 - val_loss: 192.6509\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.5454 - val_loss: 191.4558\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.6595 - val_loss: 191.0930\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.9250 - val_loss: 190.5935\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.2657 - val_loss: 189.9091\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.9809 - val_loss: 189.1475\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.0687 - val_loss: 188.3048\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.3398 - val_loss: 187.9079\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.5541 - val_loss: 187.3333\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.8978 - val_loss: 186.3804\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.0070 - val_loss: 186.1057\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.2318 - val_loss: 185.2324\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4735 - val_loss: 184.7458\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8091 - val_loss: 183.8450\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.0743 - val_loss: 183.6406\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.2994 - val_loss: 182.8471\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.2989 - val_loss: 181.8547\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.4424 - val_loss: 181.3381\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.8302 - val_loss: 180.5179\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.8105 - val_loss: 180.0393\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.2202 - val_loss: 178.9762\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.4989 - val_loss: 178.7828\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0822 - val_loss: 178.0133\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.0491 - val_loss: 177.2508\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.9149 - val_loss: 176.3665\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.7239 - val_loss: 176.3105\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.9519 - val_loss: 175.4461\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.7439 - val_loss: 175.0602\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.7745 - val_loss: 174.5738\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.1727 - val_loss: 174.1301\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.7111 - val_loss: 173.2265\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.8714 - val_loss: 172.3986\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.3394 - val_loss: 171.6441\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.9301 - val_loss: 171.3801\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.2907 - val_loss: 170.7605\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.0296 - val_loss: 170.4971\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.1714 - val_loss: 169.8134\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.4808 - val_loss: 168.9282\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 139.7848 - val_loss: 168.9359\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.6803 - val_loss: 168.0175\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.7385 - val_loss: 167.7111\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.2715 - val_loss: 167.1379\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.8425 - val_loss: 166.6729\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.4300 - val_loss: 165.7488\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.9855 - val_loss: 165.4691\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.3596 - val_loss: 165.0315\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.2081 - val_loss: 164.3681\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.7316 - val_loss: 164.9232\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.4131 - val_loss: 163.6192\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.0814 - val_loss: 163.2759\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.3926 - val_loss: 162.6387\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.2700 - val_loss: 162.2899\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.3905 - val_loss: 162.5525\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.1571 - val_loss: 160.9826\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.2225 - val_loss: 161.4051\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.4978 - val_loss: 160.7080\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.1391 - val_loss: 160.2902\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.7872 - val_loss: 160.2945\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.4363 - val_loss: 159.8722\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.1971 - val_loss: 159.6629\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1591.0602 - val_loss: 1540.8098\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1552.2858 - val_loss: 1509.3075\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1519.5088 - val_loss: 1475.4384\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1481.9558 - val_loss: 1435.5557\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1437.5836 - val_loss: 1388.2627\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1384.4766 - val_loss: 1330.3872\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1319.2134 - val_loss: 1260.3982\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1240.9161 - val_loss: 1175.9111\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1148.0487 - val_loss: 1077.5426\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1041.9108 - val_loss: 967.5425\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 925.9662 - val_loss: 849.3293\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 803.1720 - val_loss: 727.0797\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 679.1366 - val_loss: 608.0721\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 562.0654 - val_loss: 499.4488\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 457.9571 - val_loss: 406.8014\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 374.6617 - val_loss: 332.4681\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 312.3638 - val_loss: 279.7711\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 270.1215 - val_loss: 246.4393\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 243.7094 - val_loss: 226.8899\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 228.6772 - val_loss: 213.9977\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 219.1132 - val_loss: 206.5783\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.5848 - val_loss: 200.6302\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.8926 - val_loss: 197.2031\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.1224 - val_loss: 194.4585\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 201.9138 - val_loss: 191.6815\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.2905 - val_loss: 189.7786\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.5964 - val_loss: 187.6379\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.2276 - val_loss: 186.0296\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.3343 - val_loss: 184.5169\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.4379 - val_loss: 183.1017\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.5831 - val_loss: 181.8146\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.7786 - val_loss: 180.9864\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.4125 - val_loss: 179.7759\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.7427 - val_loss: 178.2701\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.3943 - val_loss: 177.1561\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 180.9364 - val_loss: 176.4927\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.8556 - val_loss: 175.6589\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.3335 - val_loss: 173.9070\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.1349 - val_loss: 173.3595\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.7811 - val_loss: 172.4094\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.8311 - val_loss: 171.3018\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.5986 - val_loss: 171.0024\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.4366 - val_loss: 170.2671\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.3615 - val_loss: 169.5577\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.2433 - val_loss: 168.7608\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.1981 - val_loss: 167.9121\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.2999 - val_loss: 167.4344\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.2802 - val_loss: 166.8066\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.2148 - val_loss: 166.2474\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.3141 - val_loss: 165.8785\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.5266 - val_loss: 165.4508\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.6680 - val_loss: 164.5997\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.7542 - val_loss: 164.4513\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.0504 - val_loss: 163.5985\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.3300 - val_loss: 163.0992\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.3517 - val_loss: 163.1066\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.6367 - val_loss: 162.6322\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.9059 - val_loss: 162.2042\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.0779 - val_loss: 161.5928\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.2363 - val_loss: 161.0806\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.5865 - val_loss: 160.6266\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.8607 - val_loss: 160.2855\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.1695 - val_loss: 159.5349\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.3146 - val_loss: 159.2110\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.5798 - val_loss: 159.4325\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.0240 - val_loss: 158.7887\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.1389 - val_loss: 158.2873\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.5569 - val_loss: 157.8262\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.8929 - val_loss: 157.2178\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.1098 - val_loss: 157.4594\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.6797 - val_loss: 157.5031\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.9880 - val_loss: 156.2059\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.2861 - val_loss: 156.7512\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.6434 - val_loss: 156.2057\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.3895 - val_loss: 155.5119\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.7054 - val_loss: 155.4437\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.8414 - val_loss: 155.2533\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.3818 - val_loss: 155.0188\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 145.0336 - val_loss: 154.7596\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.1838 - val_loss: 154.0430\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.7927 - val_loss: 154.0015\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.1609 - val_loss: 154.1565\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.6262 - val_loss: 153.4575\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.2436 - val_loss: 152.9742\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.6874 - val_loss: 152.7492\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.1365 - val_loss: 153.2996\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.4618 - val_loss: 152.6231\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.2374 - val_loss: 152.3285\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.4625 - val_loss: 152.4904\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.1069 - val_loss: 152.1056\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.4939 - val_loss: 152.1988\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.1283 - val_loss: 151.8491\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.8917 - val_loss: 152.0765\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.3785 - val_loss: 152.0661\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.0842 - val_loss: 150.7599\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.5256 - val_loss: 151.4286\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.4113 - val_loss: 151.1621\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 135.7236 - val_loss: 151.4379\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.2176 - val_loss: 151.0348\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.9136 - val_loss: 151.6551\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1539.1609 - val_loss: 1577.6249\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1491.1526 - val_loss: 1528.4739\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1435.2395 - val_loss: 1464.8871\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1364.6117 - val_loss: 1387.6608\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1277.7487 - val_loss: 1294.4437\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1174.1344 - val_loss: 1181.1973\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 1053.1602 - val_loss: 1049.7141\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 917.0189 - val_loss: 906.5685\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 772.1865 - val_loss: 759.4429\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 629.6762 - val_loss: 614.4471\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 498.5966 - val_loss: 489.0291\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 394.2568 - val_loss: 385.9542\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 316.0077 - val_loss: 315.2996\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 267.4244 - val_loss: 268.2007\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 239.8559 - val_loss: 241.5962\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 225.0273 - val_loss: 226.0281\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 216.4500 - val_loss: 216.7656\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 210.6330 - val_loss: 211.2270\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 206.4904 - val_loss: 207.2624\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.1325 - val_loss: 204.8219\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.7889 - val_loss: 201.9974\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 197.0138 - val_loss: 199.5751\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 194.6612 - val_loss: 197.4593\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.2501 - val_loss: 195.4062\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.3563 - val_loss: 194.1701\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 188.4771 - val_loss: 192.1875\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 186.8394 - val_loss: 190.8767\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 185.0339 - val_loss: 189.8431\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 183.5985 - val_loss: 188.8616\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.4148 - val_loss: 187.1727\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.0800 - val_loss: 186.4314\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 179.8559 - val_loss: 185.7788\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 178.5396 - val_loss: 183.8633\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 177.4985 - val_loss: 182.9891\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.5190 - val_loss: 182.1429\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 175.7114 - val_loss: 181.0929\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 174.5521 - val_loss: 180.9962\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.8055 - val_loss: 179.8758\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.7964 - val_loss: 178.9532\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.8610 - val_loss: 178.4757\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.9945 - val_loss: 177.5335\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 170.0338 - val_loss: 177.1344\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.4059 - val_loss: 176.7614\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.7372 - val_loss: 175.0741\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 167.7837 - val_loss: 175.0497\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.9805 - val_loss: 174.8989\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.3266 - val_loss: 173.1825\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.5758 - val_loss: 173.2548\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.9043 - val_loss: 172.2587\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.2767 - val_loss: 171.6750\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.7766 - val_loss: 170.5760\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.9309 - val_loss: 170.6250\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.0280 - val_loss: 169.4003\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.3712 - val_loss: 168.3215\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.7063 - val_loss: 167.5988\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.0479 - val_loss: 166.9243\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.2981 - val_loss: 167.2098\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.7261 - val_loss: 166.3253\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.0955 - val_loss: 165.2763\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.7814 - val_loss: 164.4458\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.7681 - val_loss: 163.8695\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.2000 - val_loss: 163.4078\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.8133 - val_loss: 162.2146\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.3368 - val_loss: 161.5522\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.1361 - val_loss: 160.3852\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.5390 - val_loss: 160.3311\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.9309 - val_loss: 159.3542\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.3048 - val_loss: 159.2095\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.6930 - val_loss: 158.2102\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.1353 - val_loss: 157.4785\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.2434 - val_loss: 156.7467\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.7500 - val_loss: 155.8456\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.9693 - val_loss: 155.6112\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.4709 - val_loss: 154.6555\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.9280 - val_loss: 154.0541\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.2148 - val_loss: 153.7875\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.6156 - val_loss: 152.6007\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.0894 - val_loss: 152.2536\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 145.5321 - val_loss: 151.9722\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.8827 - val_loss: 151.2110\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 144.5098 - val_loss: 150.7625\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.9860 - val_loss: 149.6882\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.6322 - val_loss: 149.8610\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.1603 - val_loss: 149.4939\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.3408 - val_loss: 148.0592\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.9479 - val_loss: 148.0393\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.2031 - val_loss: 147.6197\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.6992 - val_loss: 146.8538\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.4655 - val_loss: 146.8037\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.0558 - val_loss: 146.4951\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.6877 - val_loss: 145.5426\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.1746 - val_loss: 144.8232\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.6033 - val_loss: 144.7542\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.4221 - val_loss: 144.1553\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.0063 - val_loss: 143.4637\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.6453 - val_loss: 144.1257\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.0514 - val_loss: 143.3109\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.7955 - val_loss: 142.5886\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.7399 - val_loss: 142.7442\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.2397 - val_loss: 141.9136\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1546.0227 - val_loss: 1502.3628\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1511.1085 - val_loss: 1458.7780\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1454.8230 - val_loss: 1391.5532\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1373.0128 - val_loss: 1297.1782\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1262.4576 - val_loss: 1167.4065\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1114.4078 - val_loss: 999.1783\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 929.7079 - val_loss: 802.5961\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 727.4772 - val_loss: 604.6956\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 537.1509 - val_loss: 434.2814\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 387.5237 - val_loss: 312.9444\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 288.0078 - val_loss: 251.5120\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 237.7830 - val_loss: 230.4506\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 217.3913 - val_loss: 223.5124\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 209.2511 - val_loss: 221.2039\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.3411 - val_loss: 219.0240\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 201.4135 - val_loss: 216.0886\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.8098 - val_loss: 212.3866\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.2284 - val_loss: 210.9139\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.4426 - val_loss: 208.0036\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.2231 - val_loss: 205.7717\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.3336 - val_loss: 205.1460\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.3576 - val_loss: 202.7718\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.4014 - val_loss: 201.1625\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.8620 - val_loss: 199.7243\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.6541 - val_loss: 197.4587\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.9531 - val_loss: 197.0363\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.2814 - val_loss: 196.3924\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.9554 - val_loss: 195.0477\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.9292 - val_loss: 193.8776\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.7791 - val_loss: 192.7427\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.8502 - val_loss: 190.8179\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.3086 - val_loss: 190.2824\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.0051 - val_loss: 191.6583\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.3302 - val_loss: 188.0473\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.4870 - val_loss: 187.6960\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.3235 - val_loss: 187.1211\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.6029 - val_loss: 186.9183\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.6364 - val_loss: 185.0993\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.3522 - val_loss: 184.8622\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.2353 - val_loss: 183.9863\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.3891 - val_loss: 184.6521\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.0679 - val_loss: 183.0195\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.4445 - val_loss: 181.9860\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.4172 - val_loss: 182.1068\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.9944 - val_loss: 180.0705\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 162.6709 - val_loss: 180.3954\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.7431 - val_loss: 179.5512\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 161.1817 - val_loss: 179.1976\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.7930 - val_loss: 179.0206\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.1679 - val_loss: 178.7390\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.5235 - val_loss: 177.8052\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.1033 - val_loss: 177.2480\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.5830 - val_loss: 175.9300\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.0855 - val_loss: 177.0306\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.5708 - val_loss: 175.6656\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.1295 - val_loss: 175.5243\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.0257 - val_loss: 174.3338\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.4732 - val_loss: 176.6166\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.1571 - val_loss: 173.0562\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.5392 - val_loss: 172.7990\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.2141 - val_loss: 174.0545\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.7482 - val_loss: 172.9905\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.2903 - val_loss: 171.8557\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.8705 - val_loss: 172.6184\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.8249 - val_loss: 171.6013\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.2919 - val_loss: 172.6007\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 152.6416 - val_loss: 170.4180\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.8923 - val_loss: 169.0040\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.1222 - val_loss: 170.5697\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.8595 - val_loss: 169.8615\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.2990 - val_loss: 169.7307\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.9003 - val_loss: 169.0561\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.1375 - val_loss: 169.5810\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 150.4694 - val_loss: 167.7048\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.9905 - val_loss: 168.9110\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.6906 - val_loss: 167.8768\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.4670 - val_loss: 167.4569\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.9777 - val_loss: 166.6931\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.8373 - val_loss: 167.3709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.9061 - val_loss: 168.1135\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.1182 - val_loss: 165.5826\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.7001 - val_loss: 166.8419\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.2572 - val_loss: 165.5972\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.1721 - val_loss: 166.1303\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.7822 - val_loss: 165.8580\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.7497 - val_loss: 164.7393\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.5155 - val_loss: 163.7788\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.8872 - val_loss: 165.0143\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.6385 - val_loss: 165.8843\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.2997 - val_loss: 164.0306\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.3637 - val_loss: 163.5881\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.7811 - val_loss: 164.8959\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.5554 - val_loss: 164.4298\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.2529 - val_loss: 163.6653\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.6153 - val_loss: 161.8448\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.6886 - val_loss: 163.1694\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.2715 - val_loss: 163.9936\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.3544 - val_loss: 162.8451\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.6689 - val_loss: 161.8419\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.3540 - val_loss: 162.7011\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 10ms/step - loss: 1578.6718 - val_loss: 1571.1851\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1541.9314 - val_loss: 1531.9083\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1502.0250 - val_loss: 1482.8008\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1446.3762 - val_loss: 1409.8904\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1367.1864 - val_loss: 1311.1600\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1263.4758 - val_loss: 1187.8552\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1137.3688 - val_loss: 1039.4399\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 989.5052 - val_loss: 874.5271\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 828.0167 - val_loss: 703.3018\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 667.7095 - val_loss: 535.9838\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 515.2979 - val_loss: 403.6251\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 396.9525 - val_loss: 305.1481\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 313.6970 - val_loss: 249.6511\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 264.1103 - val_loss: 225.8960\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 241.2935 - val_loss: 217.0589\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 229.7333 - val_loss: 213.7677\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 224.6777 - val_loss: 211.7987\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 219.7205 - val_loss: 208.5689\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 215.8979 - val_loss: 205.4194\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.6791 - val_loss: 202.9551\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 209.8890 - val_loss: 200.1594\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.1158 - val_loss: 197.3134\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.4673 - val_loss: 195.2547\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.2884 - val_loss: 193.5421\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.3546 - val_loss: 191.1378\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.0395 - val_loss: 189.1525\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.8545 - val_loss: 188.5013\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.6599 - val_loss: 185.9729\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.3752 - val_loss: 184.4120\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.2793 - val_loss: 182.3823\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.2967 - val_loss: 181.4303\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.9901 - val_loss: 180.3488\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.4712 - val_loss: 179.1364\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.5401 - val_loss: 177.7583\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.3096 - val_loss: 176.7347\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.8901 - val_loss: 175.3373\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.9513 - val_loss: 173.9709\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.7293 - val_loss: 173.2330\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.7903 - val_loss: 172.9169\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.6783 - val_loss: 171.7871\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.3727 - val_loss: 171.1142\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.6957 - val_loss: 170.1269\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.8837 - val_loss: 168.3532\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.8510 - val_loss: 168.4235\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.3237 - val_loss: 168.2662\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.1646 - val_loss: 166.6260\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.0425 - val_loss: 166.1580\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.3931 - val_loss: 165.7543\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.6728 - val_loss: 165.3358\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.1205 - val_loss: 163.7256\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.9848 - val_loss: 163.6473\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.2290 - val_loss: 163.1118\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.3617 - val_loss: 162.1204\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.5875 - val_loss: 161.7114\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.5457 - val_loss: 161.1573\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.8456 - val_loss: 160.2537\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.8977 - val_loss: 159.8878\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.3870 - val_loss: 159.2756\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.5578 - val_loss: 158.8750\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.4578 - val_loss: 158.1782\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.8755 - val_loss: 157.7575\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.3244 - val_loss: 157.0891\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.2095 - val_loss: 156.7898\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.4731 - val_loss: 156.0109\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.7203 - val_loss: 154.9873\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.8875 - val_loss: 154.7381\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.2410 - val_loss: 154.2216\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.3529 - val_loss: 154.1485\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.8024 - val_loss: 153.3108\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.9975 - val_loss: 152.5361\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.4768 - val_loss: 152.1895\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.8707 - val_loss: 151.9019\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.2218 - val_loss: 151.2461\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.6799 - val_loss: 150.3089\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8703 - val_loss: 150.3969\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.4038 - val_loss: 149.8445\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.1583 - val_loss: 149.2290\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.2907 - val_loss: 148.9762\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 149.4438 - val_loss: 148.2052\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.1587 - val_loss: 148.1453\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.6169 - val_loss: 148.1210\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.2792 - val_loss: 147.1035\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.6146 - val_loss: 147.1602\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.8354 - val_loss: 146.5823\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.4522 - val_loss: 146.3508\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.9833 - val_loss: 145.8599\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.5180 - val_loss: 145.6869\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.0263 - val_loss: 145.2932\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.4088 - val_loss: 145.0096\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.1150 - val_loss: 145.0146\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.5773 - val_loss: 144.3969\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.1710 - val_loss: 144.3971\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.7278 - val_loss: 144.1550\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.2473 - val_loss: 143.9029\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.2314 - val_loss: 144.1414\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.4940 - val_loss: 143.3301\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.8740 - val_loss: 143.0424\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.8347 - val_loss: 143.1124\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.7311 - val_loss: 142.5948\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.9957 - val_loss: 142.7347\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1567.4434 - val_loss: 1464.3900\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1534.7311 - val_loss: 1426.2346\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1487.8713 - val_loss: 1370.2372\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1418.5347 - val_loss: 1287.0386\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1316.6599 - val_loss: 1170.9624\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1180.2035 - val_loss: 1027.8389\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1017.5989 - val_loss: 867.3218\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 838.4060 - val_loss: 697.0972\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 656.9570 - val_loss: 538.1864\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 495.0361 - val_loss: 405.6283\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 369.9568 - val_loss: 311.8910\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 290.1138 - val_loss: 257.0917\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 250.2577 - val_loss: 226.6169\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 230.3494 - val_loss: 213.4387\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 222.0439 - val_loss: 205.2456\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 215.8432 - val_loss: 200.3981\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.2636 - val_loss: 196.8363\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 208.1108 - val_loss: 193.2813\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.4771 - val_loss: 191.0737\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 201.7913 - val_loss: 188.1436\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.1263 - val_loss: 186.1324\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.8289 - val_loss: 183.7018\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.6794 - val_loss: 181.7663\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.8537 - val_loss: 180.2191\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.9388 - val_loss: 178.8500\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.2114 - val_loss: 176.9529\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.6830 - val_loss: 176.0621\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.3362 - val_loss: 174.7800\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.9445 - val_loss: 173.2152\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.3095 - val_loss: 172.2539\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.2086 - val_loss: 170.9966\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.2823 - val_loss: 170.3179\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.0391 - val_loss: 168.7193\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.1151 - val_loss: 168.2614\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 178.4436 - val_loss: 167.4935\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.1818 - val_loss: 166.8878\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.8152 - val_loss: 165.7824\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.7850 - val_loss: 165.2960\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.2077 - val_loss: 164.2802\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 174.1412 - val_loss: 163.7323\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 173.4548 - val_loss: 163.2803\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.8359 - val_loss: 162.5303\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.3355 - val_loss: 161.7371\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.3809 - val_loss: 161.1654\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.8633 - val_loss: 160.7307\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.2157 - val_loss: 159.9646\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 169.5805 - val_loss: 159.5769\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 168.8421 - val_loss: 158.8026\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.1926 - val_loss: 158.1579\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.6733 - val_loss: 157.4449\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.9813 - val_loss: 157.0590\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 166.3594 - val_loss: 156.9887\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 166.0661 - val_loss: 156.1362\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 165.2597 - val_loss: 155.7739\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 164.6561 - val_loss: 155.0822\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.1483 - val_loss: 154.4925\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.7451 - val_loss: 154.2633\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.3293 - val_loss: 153.3268\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 162.9289 - val_loss: 153.1394\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 162.4757 - val_loss: 152.9616\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 161.9011 - val_loss: 152.5327\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.3954 - val_loss: 152.0711\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 161.0184 - val_loss: 151.9982\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 160.6052 - val_loss: 151.1505\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.5739 - val_loss: 150.6532\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.7169 - val_loss: 150.5932\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.2407 - val_loss: 149.8809\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 159.7994 - val_loss: 149.4216\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 158.5373 - val_loss: 149.4196\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.3596 - val_loss: 148.9112\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.0421 - val_loss: 148.5353\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4648 - val_loss: 147.9258\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.1349 - val_loss: 147.7536\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.5281 - val_loss: 147.5148\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.3333 - val_loss: 146.9230\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.1046 - val_loss: 147.1575\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.7635 - val_loss: 146.5784\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.4021 - val_loss: 145.9485\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 155.1912 - val_loss: 145.8626\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.4945 - val_loss: 145.1711\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.1973 - val_loss: 145.1965\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.7471 - val_loss: 144.7562\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.4538 - val_loss: 144.4326\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.0075 - val_loss: 143.9904\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.8833 - val_loss: 144.2198\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.7554 - val_loss: 143.2932\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.0553 - val_loss: 143.3634\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.7371 - val_loss: 142.4268\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.6568 - val_loss: 142.6597\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.9097 - val_loss: 141.9522\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.5628 - val_loss: 141.5727\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.4153 - val_loss: 141.6655\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.6999 - val_loss: 141.2643\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.6073 - val_loss: 140.8520\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.2874 - val_loss: 140.2525\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.7749 - val_loss: 140.6856\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.5498 - val_loss: 139.8064\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.1033 - val_loss: 139.6364\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.5996 - val_loss: 139.8317\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.2493 - val_loss: 138.6847\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1481.8772 - val_loss: 1618.3500\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1436.9908 - val_loss: 1559.0289\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1370.7657 - val_loss: 1472.3522\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1277.6375 - val_loss: 1352.7986\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1153.4554 - val_loss: 1201.1455\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 999.0757 - val_loss: 1018.3852\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 820.8104 - val_loss: 819.0421\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 636.9393 - val_loss: 624.6107\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 473.1629 - val_loss: 461.9763\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 351.4870 - val_loss: 352.0732\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 277.5756 - val_loss: 293.9599\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 241.6939 - val_loss: 264.7663\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 225.6629 - val_loss: 249.9519\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 217.0513 - val_loss: 241.1117\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.2478 - val_loss: 234.6676\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 206.4650 - val_loss: 229.7600\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.6789 - val_loss: 225.5730\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.2145 - val_loss: 221.1740\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.2832 - val_loss: 217.3779\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.6580 - val_loss: 214.5053\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.2536 - val_loss: 211.4982\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.0883 - val_loss: 209.6193\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.3948 - val_loss: 207.2424\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.5747 - val_loss: 204.6869\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.7888 - val_loss: 202.3240\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.1491 - val_loss: 200.3154\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.8948 - val_loss: 198.6974\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.5493 - val_loss: 197.1906\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.0813 - val_loss: 194.6622\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.9287 - val_loss: 194.0731\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.9006 - val_loss: 192.7642\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.6803 - val_loss: 191.1401\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.6802 - val_loss: 189.5833\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.6879 - val_loss: 188.3662\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.9268 - val_loss: 187.4697\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.9046 - val_loss: 185.7078\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.0477 - val_loss: 185.3339\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.0501 - val_loss: 183.8858\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.2581 - val_loss: 182.7808\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.7840 - val_loss: 182.0824\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 166.7805 - val_loss: 181.4641\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.1890 - val_loss: 179.9679\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.3072 - val_loss: 179.2716\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.5475 - val_loss: 178.1231\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.4244 - val_loss: 177.5564\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.6747 - val_loss: 176.4543\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.7646 - val_loss: 175.8523\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 162.1125 - val_loss: 175.0053\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.7922 - val_loss: 174.8301\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.6683 - val_loss: 173.6966\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.3062 - val_loss: 172.5645\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.6343 - val_loss: 172.1081\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.0931 - val_loss: 171.6647\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.3812 - val_loss: 170.7682\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.0140 - val_loss: 169.8848\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.3668 - val_loss: 169.2103\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.0927 - val_loss: 168.5803\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.5262 - val_loss: 168.5227\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.7574 - val_loss: 167.6503\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.3065 - val_loss: 166.9040\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.7773 - val_loss: 166.3378\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.4491 - val_loss: 166.1027\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.8877 - val_loss: 165.4000\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.5198 - val_loss: 165.2707\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.0125 - val_loss: 164.3383\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 152.7273 - val_loss: 163.7794\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 152.2753 - val_loss: 163.6721\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8955 - val_loss: 163.9402\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.3312 - val_loss: 162.6171\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.9172 - val_loss: 162.2733\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.4440 - val_loss: 161.8348\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.0760 - val_loss: 161.1759\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.6500 - val_loss: 161.0348\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.3308 - val_loss: 160.1845\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.0544 - val_loss: 159.6701\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.4734 - val_loss: 159.3129\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.6599 - val_loss: 157.9444\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.0053 - val_loss: 158.8468\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.3332 - val_loss: 158.2195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.3296 - val_loss: 157.0454\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.1780 - val_loss: 157.3445\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.2033 - val_loss: 156.4501\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.1940 - val_loss: 156.4735\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.3127 - val_loss: 155.4785\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.9897 - val_loss: 155.4200\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.3219 - val_loss: 155.2671\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.3792 - val_loss: 154.9955\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.8439 - val_loss: 154.5959\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.3105 - val_loss: 153.8384\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.1751 - val_loss: 153.4040\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.7518 - val_loss: 152.9163\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.3168 - val_loss: 153.2254\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.8443 - val_loss: 152.3442\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.8124 - val_loss: 152.0306\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.2049 - val_loss: 151.1300\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.2172 - val_loss: 151.1287\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.8124 - val_loss: 151.1864\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.3395 - val_loss: 150.8916\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.0296 - val_loss: 150.8446\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.1765 - val_loss: 150.4084\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1534.8098 - val_loss: 1523.3156\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1491.8246 - val_loss: 1474.9540\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1439.8420 - val_loss: 1409.7788\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1365.8969 - val_loss: 1321.1342\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1269.9281 - val_loss: 1207.7297\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1150.3411 - val_loss: 1071.4827\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1009.4951 - val_loss: 915.2292\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 851.4806 - val_loss: 751.8497\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 692.2647 - val_loss: 590.2069\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 541.7969 - val_loss: 451.2703\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 423.5895 - val_loss: 344.9999\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 333.9188 - val_loss: 281.9501\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 284.1897 - val_loss: 245.7976\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 254.3055 - val_loss: 229.3171\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 239.3212 - val_loss: 220.5929\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 230.7978 - val_loss: 215.3693\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 224.7543 - val_loss: 211.0881\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 219.4409 - val_loss: 207.6969\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 215.2438 - val_loss: 204.5485\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.8310 - val_loss: 202.1075\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.0554 - val_loss: 199.5458\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.7072 - val_loss: 197.1908\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.6110 - val_loss: 194.7391\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.9456 - val_loss: 192.8873\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.9349 - val_loss: 191.0864\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.1580 - val_loss: 189.4684\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.7614 - val_loss: 187.7401\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.7920 - val_loss: 186.2320\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.7537 - val_loss: 185.1451\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.7941 - val_loss: 183.9804\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.3089 - val_loss: 183.2234\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.6642 - val_loss: 181.8273\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.1081 - val_loss: 180.9463\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.5200 - val_loss: 179.6250\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.3407 - val_loss: 179.3530\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.9350 - val_loss: 178.3728\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.0909 - val_loss: 177.3344\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.7622 - val_loss: 177.1155\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.8086 - val_loss: 176.3765\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.9492 - val_loss: 175.5905\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.9261 - val_loss: 174.9417\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.9480 - val_loss: 174.4945\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.2277 - val_loss: 174.0819\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.4824 - val_loss: 173.5507\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.6265 - val_loss: 172.7242\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.9757 - val_loss: 172.3944\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.1798 - val_loss: 172.1863\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.4262 - val_loss: 171.4283\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.6197 - val_loss: 170.9335\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.9670 - val_loss: 170.8515\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.3276 - val_loss: 170.0544\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.8860 - val_loss: 169.8293\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.0938 - val_loss: 169.4257\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.3557 - val_loss: 168.8754\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.9361 - val_loss: 168.2845\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.3956 - val_loss: 168.0701\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.5824 - val_loss: 167.7056\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.2773 - val_loss: 167.2528\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.4600 - val_loss: 166.8464\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.1573 - val_loss: 166.3948\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.4269 - val_loss: 166.0603\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.9223 - val_loss: 165.8385\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 155.3323 - val_loss: 165.4160\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.0813 - val_loss: 165.1534\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.4563 - val_loss: 164.5103\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.3299 - val_loss: 164.3420\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.3863 - val_loss: 163.9458\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.8826 - val_loss: 163.4657\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.3544 - val_loss: 163.4602\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8665 - val_loss: 162.6828\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.4341 - val_loss: 162.4621\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.0083 - val_loss: 162.3768\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.7400 - val_loss: 161.6695\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.2167 - val_loss: 161.7891\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.8289 - val_loss: 161.4819\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.0848 - val_loss: 161.0416\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.7715 - val_loss: 160.5071\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.3997 - val_loss: 160.2183\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 147.9843 - val_loss: 160.0031\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.3201 - val_loss: 159.5063\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.9479 - val_loss: 159.2694\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.4906 - val_loss: 158.8493\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.3874 - val_loss: 159.0476\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.1413 - val_loss: 158.1816\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.7691 - val_loss: 158.1221\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.8067 - val_loss: 157.6474\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.5995 - val_loss: 157.4374\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.4130 - val_loss: 157.1240\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.7781 - val_loss: 156.7790\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.3568 - val_loss: 156.4245\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.1904 - val_loss: 156.1868\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.3080 - val_loss: 155.8847\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.1415 - val_loss: 155.5333\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.7408 - val_loss: 155.5910\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.7837 - val_loss: 155.2969\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.2954 - val_loss: 155.1999\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.6701 - val_loss: 154.5164\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.1710 - val_loss: 154.0722\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.5852 - val_loss: 154.1760\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.3956 - val_loss: 153.5725\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1523.2355 - val_loss: 1516.5590\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1481.7672 - val_loss: 1469.8557\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1426.0691 - val_loss: 1402.5057\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1342.6655 - val_loss: 1302.6570\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1221.8861 - val_loss: 1163.5968\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1061.8966 - val_loss: 989.3766\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 871.7336 - val_loss: 789.8609\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 669.3694 - val_loss: 595.1355\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 488.4941 - val_loss: 433.0179\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 355.0743 - val_loss: 323.9491\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 275.4784 - val_loss: 264.8416\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 237.9301 - val_loss: 234.9186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 219.6982 - val_loss: 220.0329\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.5670 - val_loss: 210.8202\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.8758 - val_loss: 204.7116\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.6696 - val_loss: 199.9877\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.8760 - val_loss: 197.7558\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.2951 - val_loss: 195.0473\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.0080 - val_loss: 193.2899\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.0549 - val_loss: 191.3644\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.3889 - val_loss: 190.3251\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.7278 - val_loss: 189.2780\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.3861 - val_loss: 188.2915\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.9331 - val_loss: 187.7446\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.9556 - val_loss: 186.8522\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.8282 - val_loss: 185.4194\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.9426 - val_loss: 184.6134\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.1460 - val_loss: 184.2671\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.2200 - val_loss: 183.8250\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 176.9690 - val_loss: 183.1740\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.0078 - val_loss: 183.2260\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.5800 - val_loss: 181.8835\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.5755 - val_loss: 181.6923\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.6806 - val_loss: 181.8481\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.1056 - val_loss: 181.1732\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.2619 - val_loss: 180.3109\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.5527 - val_loss: 179.3873\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.9333 - val_loss: 179.2303\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.2713 - val_loss: 178.9205\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.8570 - val_loss: 177.9346\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.9061 - val_loss: 177.7711\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.4897 - val_loss: 177.8504\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.4756 - val_loss: 177.1129\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.9986 - val_loss: 177.4493\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.2474 - val_loss: 176.7411\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.7326 - val_loss: 177.3418\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.0325 - val_loss: 175.6771\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.6137 - val_loss: 175.6854\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.2659 - val_loss: 174.1701\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.1470 - val_loss: 175.6628\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.9698 - val_loss: 175.1578\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.9664 - val_loss: 174.5131\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.4216 - val_loss: 173.9940\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.9401 - val_loss: 174.0837\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.9531 - val_loss: 173.2196\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.2727 - val_loss: 171.7188\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.3114 - val_loss: 172.5605\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.9272 - val_loss: 172.2657\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.5983 - val_loss: 172.3465\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.1293 - val_loss: 170.8650\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4409 - val_loss: 170.8960\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.9631 - val_loss: 170.4318\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8224 - val_loss: 170.3858\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.2921 - val_loss: 170.1775\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.8444 - val_loss: 169.5954\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.0430 - val_loss: 168.8566\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.7141 - val_loss: 169.1086\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.2941 - val_loss: 169.0213\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.1175 - val_loss: 167.0850\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.3875 - val_loss: 168.0247\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.0395 - val_loss: 167.5227\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.7830 - val_loss: 167.4937\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.4176 - val_loss: 166.6070\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.6416 - val_loss: 166.7158\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.4026 - val_loss: 166.4536\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.9731 - val_loss: 166.7938\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.9262 - val_loss: 165.5531\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.1840 - val_loss: 165.1705\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0549 - val_loss: 166.1378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.4889 - val_loss: 165.1066\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.2901 - val_loss: 164.4442\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.6656 - val_loss: 164.0318\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.3710 - val_loss: 163.3177\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.8351 - val_loss: 163.5984\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.7672 - val_loss: 163.1140\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.4433 - val_loss: 163.2251\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.9862 - val_loss: 164.0361\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.4533 - val_loss: 162.8572\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.2504 - val_loss: 162.6255\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.5022 - val_loss: 161.6161\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.3812 - val_loss: 162.0859\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.0091 - val_loss: 162.2891\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.9595 - val_loss: 161.9462\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.2795 - val_loss: 162.2632\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.2164 - val_loss: 161.8542\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.6915 - val_loss: 161.3408\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.8835 - val_loss: 160.9065\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.2122 - val_loss: 161.6247\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.2846 - val_loss: 161.0817\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.5782 - val_loss: 160.4792\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1525.8202 - val_loss: 1438.3700\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1469.9469 - val_loss: 1372.8053\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1394.4849 - val_loss: 1284.4119\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1295.6971 - val_loss: 1170.9128\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1173.8075 - val_loss: 1032.9120\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1030.0465 - val_loss: 878.1141\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 870.0667 - val_loss: 714.8589\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 706.4273 - val_loss: 552.6940\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 547.5197 - val_loss: 409.9527\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 412.8878 - val_loss: 302.6388\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 315.9212 - val_loss: 238.3333\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 256.4060 - val_loss: 208.6126\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 227.5789 - val_loss: 198.5568\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 213.9074 - val_loss: 195.6175\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.0144 - val_loss: 194.0341\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.5367 - val_loss: 192.7413\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.2560 - val_loss: 191.4011\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.8226 - val_loss: 190.1785\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.5979 - val_loss: 188.6062\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.6253 - val_loss: 187.6213\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.0058 - val_loss: 186.6772\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.7133 - val_loss: 185.0092\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.9674 - val_loss: 184.3279\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.5667 - val_loss: 183.4201\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.4002 - val_loss: 182.2612\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.4121 - val_loss: 181.7048\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.2302 - val_loss: 180.2218\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.1255 - val_loss: 179.7884\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.0796 - val_loss: 178.6532\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.2999 - val_loss: 178.3367\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.3412 - val_loss: 177.2625\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.5067 - val_loss: 176.9393\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.6403 - val_loss: 175.9794\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.9330 - val_loss: 174.9194\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.9133 - val_loss: 174.8551\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.3642 - val_loss: 173.6660\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.1075 - val_loss: 172.9721\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 173.4426 - val_loss: 172.5723\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.7816 - val_loss: 171.4966\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.0425 - val_loss: 170.9367\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.2975 - val_loss: 170.4072\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.4390 - val_loss: 169.3981\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.7815 - val_loss: 168.6438\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.7963 - val_loss: 167.8206\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.2758 - val_loss: 167.0001\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.4164 - val_loss: 167.0001\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.8973 - val_loss: 166.0829\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.4385 - val_loss: 165.7766\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.7947 - val_loss: 164.5080\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 164.7111 - val_loss: 164.2733\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.0845 - val_loss: 163.9258\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.3148 - val_loss: 162.7075\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.8170 - val_loss: 162.2861\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.0378 - val_loss: 161.2988\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.6818 - val_loss: 161.4334\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.6713 - val_loss: 160.7287\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.2599 - val_loss: 159.8801\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.3507 - val_loss: 158.9673\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.8800 - val_loss: 159.1849\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.1231 - val_loss: 158.0130\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.9855 - val_loss: 157.6939\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.0923 - val_loss: 156.9765\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.3266 - val_loss: 156.8924\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.4535 - val_loss: 156.0721\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.8207 - val_loss: 155.4567\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.5331 - val_loss: 155.4366\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.5177 - val_loss: 154.1200\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.6644 - val_loss: 153.5449\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.2932 - val_loss: 153.5640\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.6652 - val_loss: 152.7500\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.0693 - val_loss: 152.3163\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.7994 - val_loss: 151.9697\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.1363 - val_loss: 151.2696\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.4812 - val_loss: 150.9620\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.9775 - val_loss: 149.7993\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.2253 - val_loss: 149.3531\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.5642 - val_loss: 149.3254\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.5327 - val_loss: 148.4194\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.5867 - val_loss: 147.6036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.2160 - val_loss: 147.1894\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.4247 - val_loss: 146.6191\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.4397 - val_loss: 146.5483\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.4852 - val_loss: 146.0266\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.1095 - val_loss: 145.1200\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.3099 - val_loss: 145.2038\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.9339 - val_loss: 144.9393\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.7034 - val_loss: 143.8205\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.9558 - val_loss: 143.6642\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.2028 - val_loss: 143.2004\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.9139 - val_loss: 142.2952\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.5613 - val_loss: 141.9107\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.8230 - val_loss: 141.6291\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.7916 - val_loss: 140.9840\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.9982 - val_loss: 141.0466\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.7324 - val_loss: 141.0034\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.2649 - val_loss: 139.7943\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.8181 - val_loss: 140.0275\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.7301 - val_loss: 139.1989\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.1720 - val_loss: 139.0365\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.7554 - val_loss: 138.5358\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1507.8190 - val_loss: 1632.9410\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1473.2714 - val_loss: 1595.7738\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1432.5382 - val_loss: 1546.2588\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1377.5757 - val_loss: 1480.9467\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1304.7220 - val_loss: 1395.4316\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1208.1647 - val_loss: 1282.4828\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1088.8867 - val_loss: 1146.1338\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 949.7952 - val_loss: 995.2378\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 802.1529 - val_loss: 832.8876\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 650.2237 - val_loss: 677.3161\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 510.7476 - val_loss: 538.1788\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 397.2162 - val_loss: 423.1491\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 311.7429 - val_loss: 345.0364\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 258.8462 - val_loss: 294.2769\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 228.5712 - val_loss: 266.2229\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.7254 - val_loss: 250.5325\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 206.9832 - val_loss: 241.2346\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.0683 - val_loss: 234.1348\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.4972 - val_loss: 229.8818\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.7494 - val_loss: 225.2041\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.4326 - val_loss: 221.5397\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.4184 - val_loss: 218.9101\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.0716 - val_loss: 215.5360\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.2240 - val_loss: 212.8227\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.2890 - val_loss: 210.2173\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.6744 - val_loss: 208.0395\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.1740 - val_loss: 205.9988\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.8537 - val_loss: 203.6159\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.2939 - val_loss: 201.8384\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.0242 - val_loss: 200.0372\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.6839 - val_loss: 198.2578\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.5122 - val_loss: 196.5093\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.2374 - val_loss: 194.9463\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.1409 - val_loss: 193.6044\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.7725 - val_loss: 192.0413\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.8402 - val_loss: 190.4386\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.0592 - val_loss: 188.6395\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.0504 - val_loss: 188.7482\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.7493 - val_loss: 187.3848\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.1016 - val_loss: 186.2130\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.4524 - val_loss: 184.6615\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.3129 - val_loss: 183.6532\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.3227 - val_loss: 182.9044\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.5101 - val_loss: 181.7322\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.5446 - val_loss: 180.5682\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.1288 - val_loss: 179.3437\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.1494 - val_loss: 179.0983\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.5627 - val_loss: 177.5335\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.5332 - val_loss: 177.5214\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.6818 - val_loss: 176.0140\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.2042 - val_loss: 174.9736\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.1201 - val_loss: 174.4696\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.8998 - val_loss: 173.9153\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.5445 - val_loss: 172.7799\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.9930 - val_loss: 171.8568\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.2624 - val_loss: 171.2314\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.5093 - val_loss: 170.6512\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.0063 - val_loss: 169.8783\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.1072 - val_loss: 168.9035\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.7995 - val_loss: 168.4853\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8921 - val_loss: 168.1651\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.4719 - val_loss: 167.0671\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.0587 - val_loss: 167.6104\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.4166 - val_loss: 166.0659\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.7561 - val_loss: 165.2632\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.1106 - val_loss: 164.7716\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.5101 - val_loss: 164.0845\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.8777 - val_loss: 163.6525\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.4568 - val_loss: 163.3916\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.8756 - val_loss: 162.2967\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.2775 - val_loss: 161.4897\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.6817 - val_loss: 161.6024\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.1474 - val_loss: 160.8870\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.4968 - val_loss: 160.2802\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.2152 - val_loss: 160.1976\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.8748 - val_loss: 159.6327\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 143.1767 - val_loss: 158.8566\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.6153 - val_loss: 158.3573\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 142.0479 - val_loss: 158.0891\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.6286 - val_loss: 157.7227\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.1618 - val_loss: 157.1296\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.6862 - val_loss: 156.8333\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 140.2347 - val_loss: 156.6492\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 139.8092 - val_loss: 155.7808\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.5122 - val_loss: 155.7985\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.9951 - val_loss: 155.3993\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 138.5821 - val_loss: 155.5077\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.3244 - val_loss: 155.6066\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.8615 - val_loss: 154.0239\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.5168 - val_loss: 154.1589\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.0553 - val_loss: 154.1496\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.3452 - val_loss: 153.2474\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.0564 - val_loss: 153.1117\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.6564 - val_loss: 152.9852\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.3051 - val_loss: 152.5000\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 135.0726 - val_loss: 152.1733\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.5754 - val_loss: 151.4221\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.5860 - val_loss: 151.6784\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.9630 - val_loss: 150.7963\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.8138 - val_loss: 150.9883\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1538.6654 - val_loss: 1467.7487\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1486.5912 - val_loss: 1411.1783\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1420.2288 - val_loss: 1337.4419\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1334.0690 - val_loss: 1244.1177\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1227.0690 - val_loss: 1126.5817\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1096.7750 - val_loss: 987.8321\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 948.0456 - val_loss: 830.0169\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 783.2240 - val_loss: 668.7258\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 619.0642 - val_loss: 515.5442\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 471.8575 - val_loss: 386.9938\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 354.1913 - val_loss: 298.0164\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 274.3793 - val_loss: 247.5448\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 228.9707 - val_loss: 226.8728\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.3333 - val_loss: 221.3608\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.0783 - val_loss: 220.7276\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.1445 - val_loss: 220.2281\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.9248 - val_loss: 217.6767\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.2399 - val_loss: 215.6992\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.6579 - val_loss: 213.9014\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.2527 - val_loss: 211.4721\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.5661 - val_loss: 209.0188\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.3698 - val_loss: 208.1740\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.0573 - val_loss: 206.2971\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.2786 - val_loss: 204.9677\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.9652 - val_loss: 202.2942\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.4967 - val_loss: 201.0801\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.4264 - val_loss: 199.9512\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.5012 - val_loss: 197.9271\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.2144 - val_loss: 197.8276\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.1577 - val_loss: 195.4243\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.9850 - val_loss: 194.3399\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.2370 - val_loss: 193.2570\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.0482 - val_loss: 192.2759\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.0813 - val_loss: 191.0018\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.0238 - val_loss: 188.5373\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.4757 - val_loss: 188.7395\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.1519 - val_loss: 187.0675\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.5466 - val_loss: 185.3248\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.5380 - val_loss: 184.5279\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.5836 - val_loss: 184.1597\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.9672 - val_loss: 184.1029\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.9210 - val_loss: 182.1989\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.2817 - val_loss: 180.6448\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 164.6206 - val_loss: 179.9591\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.8450 - val_loss: 178.5530\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.3191 - val_loss: 178.5663\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.3518 - val_loss: 177.2302\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.6961 - val_loss: 177.0312\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.0637 - val_loss: 176.5086\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.5045 - val_loss: 175.6100\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.8808 - val_loss: 174.2470\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.2501 - val_loss: 172.8705\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.5522 - val_loss: 172.6815\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.9747 - val_loss: 172.5506\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.3497 - val_loss: 171.2897\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.9287 - val_loss: 170.6839\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.1366 - val_loss: 170.4706\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.6416 - val_loss: 169.6338\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.1366 - val_loss: 168.7516\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.5529 - val_loss: 168.9104\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.9352 - val_loss: 167.8043\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.4921 - val_loss: 166.8226\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.0619 - val_loss: 165.9922\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.3063 - val_loss: 165.8980\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.4207 - val_loss: 166.1444\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.7651 - val_loss: 164.1312\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.8693 - val_loss: 163.9035\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.3325 - val_loss: 163.7682\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0326 - val_loss: 163.4008\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.5596 - val_loss: 162.5105\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.9844 - val_loss: 161.8362\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.5078 - val_loss: 161.3791\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.3533 - val_loss: 161.0339\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.9564 - val_loss: 160.8616\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.1997 - val_loss: 160.0161\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.1485 - val_loss: 158.9025\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.6239 - val_loss: 158.4307\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.2277 - val_loss: 158.9853\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.7733 - val_loss: 157.6682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.0944 - val_loss: 157.9137\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.0458 - val_loss: 156.1337\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.3724 - val_loss: 157.0865\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.7234 - val_loss: 155.8979\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.5335 - val_loss: 155.9163\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.9749 - val_loss: 155.2428\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.8909 - val_loss: 154.2688\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.3890 - val_loss: 153.2574\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 142.0096 - val_loss: 154.3667\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.5981 - val_loss: 154.2180\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.2215 - val_loss: 153.0697\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.9721 - val_loss: 152.4104\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.5311 - val_loss: 152.0903\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 140.3612 - val_loss: 152.1018\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.1369 - val_loss: 152.2079\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.7126 - val_loss: 150.5245\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.4406 - val_loss: 150.7485\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.4937 - val_loss: 150.1842\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.9770 - val_loss: 150.2220\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.5807 - val_loss: 149.5170\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.3930 - val_loss: 149.7912\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 9ms/step - loss: 1503.2379 - val_loss: 1450.1077\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1449.5226 - val_loss: 1389.4841\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1380.4114 - val_loss: 1309.9680\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1290.2573 - val_loss: 1205.1595\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1171.8666 - val_loss: 1074.5559\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1029.6628 - val_loss: 917.0902\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 864.6099 - val_loss: 744.7051\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 695.0770 - val_loss: 573.0720\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 532.2544 - val_loss: 421.9169\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 400.3604 - val_loss: 309.3729\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 311.7931 - val_loss: 238.7173\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 261.8243 - val_loss: 203.6090\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 238.1490 - val_loss: 188.2086\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 226.6987 - val_loss: 182.8079\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 220.9229 - val_loss: 178.5915\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 216.2215 - val_loss: 177.1367\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.6797 - val_loss: 176.0773\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 210.3675 - val_loss: 174.6464\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.5012 - val_loss: 173.4539\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.9549 - val_loss: 170.9396\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.5918 - val_loss: 169.8007\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.7354 - val_loss: 168.7465\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.8383 - val_loss: 167.0896\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.2628 - val_loss: 166.7719\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.7015 - val_loss: 165.3896\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.0971 - val_loss: 163.6461\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.8418 - val_loss: 163.1906\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.8624 - val_loss: 162.7724\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.0986 - val_loss: 160.6735\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.1249 - val_loss: 159.8429\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.0329 - val_loss: 159.3801\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.2770 - val_loss: 158.8224\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.1759 - val_loss: 158.5072\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.2146 - val_loss: 157.6980\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.3609 - val_loss: 156.2220\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.4578 - val_loss: 156.3201\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.5424 - val_loss: 155.5070\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.7912 - val_loss: 154.5281\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.1564 - val_loss: 154.3598\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.4441 - val_loss: 153.8349\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.2456 - val_loss: 153.3259\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.2155 - val_loss: 152.0321\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.5035 - val_loss: 152.4754\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.6775 - val_loss: 151.4550\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.2055 - val_loss: 150.7291\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.8565 - val_loss: 149.7350\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.7981 - val_loss: 150.7249\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.2719 - val_loss: 149.7025\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.0359 - val_loss: 148.7577\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.5309 - val_loss: 149.3659\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.6722 - val_loss: 148.3120\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.1962 - val_loss: 147.6139\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.6446 - val_loss: 147.7651\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.1178 - val_loss: 146.8349\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.3513 - val_loss: 146.2086\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.0436 - val_loss: 145.5863\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.4814 - val_loss: 145.6216\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.9592 - val_loss: 145.0446\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.1631 - val_loss: 146.0431\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.8357 - val_loss: 143.7728\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.4235 - val_loss: 143.4518\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 168.2158 - val_loss: 143.1261\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.7835 - val_loss: 143.1880\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.9459 - val_loss: 142.7280\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.6418 - val_loss: 143.4893\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.3521 - val_loss: 142.4597\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.9795 - val_loss: 142.2429\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.5585 - val_loss: 141.4845\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 165.0504 - val_loss: 141.7934\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.0587 - val_loss: 140.6419\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.4468 - val_loss: 141.5209\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.1200 - val_loss: 141.1028\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.6422 - val_loss: 139.3996\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.7208 - val_loss: 139.3155\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.2166 - val_loss: 139.6378\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.8709 - val_loss: 139.4597\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.3873 - val_loss: 139.4015\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.3892 - val_loss: 139.6309\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.9068 - val_loss: 138.4449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.7534 - val_loss: 139.1898\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.2784 - val_loss: 137.5394\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.4145 - val_loss: 137.5620\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.9072 - val_loss: 138.7635\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.9104 - val_loss: 138.6323\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.2695 - val_loss: 137.1862\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.1913 - val_loss: 137.6334\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.8364 - val_loss: 137.3871\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.7007 - val_loss: 137.2864\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.3884 - val_loss: 136.6405\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.2387 - val_loss: 136.7965\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.9140 - val_loss: 136.6401\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.9120 - val_loss: 137.1577\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.5722 - val_loss: 136.7065\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.1744 - val_loss: 135.9952\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.8393 - val_loss: 135.8612\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.8407 - val_loss: 135.6786\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.5287 - val_loss: 136.4874\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.9029 - val_loss: 135.5605\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.0139 - val_loss: 135.0853\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.5764 - val_loss: 134.6595\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1594.1798 - val_loss: 1494.9987\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1565.5234 - val_loss: 1469.6305\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1538.5867 - val_loss: 1440.7557\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1503.7546 - val_loss: 1400.1942\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1453.0032 - val_loss: 1341.9952\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1381.5809 - val_loss: 1261.4402\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1284.1213 - val_loss: 1157.0203\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1160.3365 - val_loss: 1025.2736\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1006.4558 - val_loss: 866.2858\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 829.0707 - val_loss: 694.2031\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 647.4402 - val_loss: 530.4157\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 486.9659 - val_loss: 397.4297\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 364.3656 - val_loss: 310.6454\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 288.6552 - val_loss: 259.5365\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 249.8205 - val_loss: 234.2764\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 230.8590 - val_loss: 223.4466\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 220.8455 - val_loss: 217.5558\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 214.8131 - val_loss: 213.4936\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.0721 - val_loss: 210.0617\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.4224 - val_loss: 207.4494\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 201.6782 - val_loss: 204.9886\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.7231 - val_loss: 203.3967\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.5950 - val_loss: 201.5564\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.1484 - val_loss: 200.0522\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.8381 - val_loss: 198.3329\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.6090 - val_loss: 197.5773\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.6926 - val_loss: 195.7965\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.0166 - val_loss: 195.1991\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.1972 - val_loss: 194.1356\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.8323 - val_loss: 193.0430\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.2675 - val_loss: 192.3613\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.2701 - val_loss: 191.8027\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.1317 - val_loss: 190.5763\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.6241 - val_loss: 189.7045\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.3091 - val_loss: 188.8848\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.3721 - val_loss: 188.4254\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.3214 - val_loss: 188.2369\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.1805 - val_loss: 187.4912\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.2715 - val_loss: 186.7859\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.4224 - val_loss: 186.3780\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.1201 - val_loss: 185.6883\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.4891 - val_loss: 185.1953\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.4977 - val_loss: 184.5378\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.1789 - val_loss: 184.3963\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.6843 - val_loss: 183.0171\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.9917 - val_loss: 182.4759\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.1903 - val_loss: 181.8959\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.5002 - val_loss: 181.0503\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.0798 - val_loss: 180.8904\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.2281 - val_loss: 180.5564\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.3491 - val_loss: 179.6731\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.6910 - val_loss: 179.2472\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.6305 - val_loss: 178.8869\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.3426 - val_loss: 178.5601\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.0182 - val_loss: 177.7252\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.0632 - val_loss: 177.5475\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.3699 - val_loss: 177.4905\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.1003 - val_loss: 176.5467\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.3918 - val_loss: 176.4812\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.8857 - val_loss: 175.5296\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.3097 - val_loss: 175.8624\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.7193 - val_loss: 174.9920\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.2150 - val_loss: 174.9987\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.5812 - val_loss: 174.8649\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.8536 - val_loss: 174.3086\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.4431 - val_loss: 173.7556\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.7595 - val_loss: 173.8537\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.6610 - val_loss: 173.3943\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.9975 - val_loss: 172.9929\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.6444 - val_loss: 173.0656\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0468 - val_loss: 172.9281\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.7804 - val_loss: 171.6571\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.1744 - val_loss: 171.7398\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.8299 - val_loss: 171.4641\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.6103 - val_loss: 171.1595\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.2395 - val_loss: 171.0014\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.8659 - val_loss: 170.5269\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.2991 - val_loss: 170.7059\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 147.1576 - val_loss: 170.4268\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.9122 - val_loss: 170.0693\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.1169 - val_loss: 169.7206\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.8862 - val_loss: 169.0197\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.5319 - val_loss: 169.1910\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.3661 - val_loss: 168.8289\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.9188 - val_loss: 168.9282\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.6832 - val_loss: 167.7064\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.2791 - val_loss: 168.0710\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.1683 - val_loss: 167.7623\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.7337 - val_loss: 167.3025\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.2504 - val_loss: 167.0984\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.3000 - val_loss: 167.6742\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.0889 - val_loss: 166.7153\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.4110 - val_loss: 166.6519\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.1719 - val_loss: 166.1104\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.7232 - val_loss: 166.0037\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.5572 - val_loss: 166.0329\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.2635 - val_loss: 165.5678\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.1687 - val_loss: 165.8568\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.7452 - val_loss: 164.9844\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.6839 - val_loss: 164.8980\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1503.1257 - val_loss: 1629.7516\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1458.5345 - val_loss: 1573.9307\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1401.1234 - val_loss: 1498.8754\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1324.5951 - val_loss: 1404.1760\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1229.5233 - val_loss: 1288.2094\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1113.5940 - val_loss: 1148.6960\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 976.8615 - val_loss: 988.6255\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 826.5647 - val_loss: 814.3529\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 670.5117 - val_loss: 647.2451\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 527.0977 - val_loss: 497.0493\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 409.8679 - val_loss: 382.4910\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 324.8349 - val_loss: 305.8745\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 274.7014 - val_loss: 258.9461\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 245.9759 - val_loss: 234.5406\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 232.4366 - val_loss: 219.0234\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 223.6844 - val_loss: 211.3005\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 217.7937 - val_loss: 204.8609\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.4789 - val_loss: 200.6593\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.6255 - val_loss: 197.8705\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 206.2233 - val_loss: 195.3481\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.0178 - val_loss: 192.3433\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.9785 - val_loss: 190.1147\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.8325 - val_loss: 188.8883\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.5226 - val_loss: 186.8847\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.4332 - val_loss: 186.1531\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.2274 - val_loss: 184.5158\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.3927 - val_loss: 183.7432\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.4749 - val_loss: 182.1142\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.6794 - val_loss: 181.3851\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.9580 - val_loss: 180.4036\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.4136 - val_loss: 179.7305\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.5955 - val_loss: 179.0391\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.1564 - val_loss: 178.2956\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.8114 - val_loss: 177.1046\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.2987 - val_loss: 176.7298\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.7330 - val_loss: 176.1509\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.2246 - val_loss: 174.8073\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.8882 - val_loss: 174.9815\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 171.6778 - val_loss: 173.8504\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.0114 - val_loss: 173.2764\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.6197 - val_loss: 172.5145\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.2822 - val_loss: 171.5157\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.0102 - val_loss: 170.6106\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.6628 - val_loss: 171.1925\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.6721 - val_loss: 170.6387\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 162.4698 - val_loss: 170.4458\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.3520 - val_loss: 169.1869\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 160.6450 - val_loss: 169.4769\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.1020 - val_loss: 168.3556\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.0242 - val_loss: 168.2654\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 156.9842 - val_loss: 167.4641\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.1316 - val_loss: 167.2436\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 155.3004 - val_loss: 165.9635\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.2209 - val_loss: 166.1234\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 153.1647 - val_loss: 165.7418\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 152.2190 - val_loss: 164.8836\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.3872 - val_loss: 164.8806\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.5413 - val_loss: 164.5137\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 150.1485 - val_loss: 163.4698\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.8935 - val_loss: 163.8375\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.0010 - val_loss: 163.7304\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 147.2244 - val_loss: 162.9192\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.1076 - val_loss: 162.3321\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.2686 - val_loss: 162.2016\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 145.2663 - val_loss: 162.6984\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.5857 - val_loss: 162.0380\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.9994 - val_loss: 161.3481\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.1984 - val_loss: 161.6272\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.9773 - val_loss: 161.1096\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.4269 - val_loss: 160.7257\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 141.4921 - val_loss: 159.8655\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.0570 - val_loss: 159.9743\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.8095 - val_loss: 160.3248\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.9756 - val_loss: 160.1797\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.6821 - val_loss: 159.9072\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.9699 - val_loss: 158.5065\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.6426 - val_loss: 158.6316\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.9376 - val_loss: 158.9341\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 137.3253 - val_loss: 158.4021\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.1508 - val_loss: 157.2164\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.9734 - val_loss: 158.0871\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.4095 - val_loss: 158.8963\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.6382 - val_loss: 157.3815\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.1487 - val_loss: 158.2725\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.0583 - val_loss: 157.5551\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.3483 - val_loss: 156.7602\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.7650 - val_loss: 156.8399\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.6514 - val_loss: 156.7645\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.3514 - val_loss: 156.3681\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.8595 - val_loss: 156.1734\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.5643 - val_loss: 156.3635\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.2661 - val_loss: 156.2731\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.8617 - val_loss: 154.8734\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.2801 - val_loss: 155.1672\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.0599 - val_loss: 155.5474\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.6395 - val_loss: 154.7409\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.2642 - val_loss: 154.6447\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 130.1876 - val_loss: 154.9133\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.0262 - val_loss: 154.0393\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.7892 - val_loss: 154.1343\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1525.4780 - val_loss: 1569.1829\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1478.1555 - val_loss: 1517.8971\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1424.7946 - val_loss: 1454.0464\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1357.0264 - val_loss: 1373.7465\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1270.8186 - val_loss: 1269.6013\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1162.1495 - val_loss: 1142.5497\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1031.6857 - val_loss: 995.0477\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 885.6011 - val_loss: 831.3235\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 729.0400 - val_loss: 665.1896\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 576.6078 - val_loss: 515.1095\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 444.9370 - val_loss: 391.1025\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 343.8147 - val_loss: 305.5566\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 279.5521 - val_loss: 257.7321\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 242.7084 - val_loss: 234.3436\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 225.0212 - val_loss: 222.4976\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 215.5576 - val_loss: 217.2148\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.6776 - val_loss: 214.4577\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.8307 - val_loss: 211.8905\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.5293 - val_loss: 209.3282\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.9765 - val_loss: 208.0741\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.5453 - val_loss: 205.4978\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.1131 - val_loss: 203.2242\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.9922 - val_loss: 202.0519\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.8426 - val_loss: 200.2008\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.0790 - val_loss: 198.9837\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.2612 - val_loss: 197.0077\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.6438 - val_loss: 195.3739\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.0721 - val_loss: 194.1853\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.6981 - val_loss: 192.9620\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.3233 - val_loss: 191.7766\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.0032 - val_loss: 190.1046\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.6243 - val_loss: 189.9167\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.5141 - val_loss: 188.8673\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.4126 - val_loss: 188.2393\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.7365 - val_loss: 186.7045\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.5631 - val_loss: 186.3900\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.5990 - val_loss: 184.9263\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.5827 - val_loss: 184.2399\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.7896 - val_loss: 183.5909\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.8128 - val_loss: 183.2578\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.4039 - val_loss: 181.9948\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.4722 - val_loss: 181.5386\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.6839 - val_loss: 180.7676\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.8217 - val_loss: 179.4772\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.3826 - val_loss: 178.4979\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.5188 - val_loss: 178.0104\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.8561 - val_loss: 177.7025\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.4598 - val_loss: 176.6767\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.5178 - val_loss: 176.4984\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.0983 - val_loss: 175.5706\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.4419 - val_loss: 175.2423\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.8158 - val_loss: 175.5430\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.4339 - val_loss: 174.5402\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.6907 - val_loss: 174.1021\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.2279 - val_loss: 173.3714\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.0147 - val_loss: 172.7639\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.7516 - val_loss: 172.3229\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.7201 - val_loss: 172.0796\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.3303 - val_loss: 171.4059\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.9358 - val_loss: 170.9834\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.4366 - val_loss: 170.3548\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.2342 - val_loss: 169.6389\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.1131 - val_loss: 170.6165\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.3484 - val_loss: 168.8345\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.3248 - val_loss: 168.9440\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.6092 - val_loss: 168.1896\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.2001 - val_loss: 167.9211\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.5916 - val_loss: 168.4571\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.4797 - val_loss: 167.5230\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.8293 - val_loss: 167.3551\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.4151 - val_loss: 167.0324\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.0369 - val_loss: 166.4830\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.5363 - val_loss: 166.0626\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.2849 - val_loss: 165.9753\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.8086 - val_loss: 165.6237\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.6742 - val_loss: 165.0606\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.5262 - val_loss: 164.0745\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.8658 - val_loss: 164.8117\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 151.4171 - val_loss: 164.2027\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.1577 - val_loss: 163.8002\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.7165 - val_loss: 163.7489\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.6632 - val_loss: 163.8601\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.7457 - val_loss: 162.9631\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.4452 - val_loss: 162.2252\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.3432 - val_loss: 162.1925\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.9772 - val_loss: 162.4884\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.4508 - val_loss: 161.2059\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.0391 - val_loss: 160.8446\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.7260 - val_loss: 161.1119\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.9157 - val_loss: 160.6433\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.0120 - val_loss: 160.9981\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 146.6055 - val_loss: 159.9712\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.5148 - val_loss: 159.9917\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.1433 - val_loss: 159.8012\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.7941 - val_loss: 159.2435\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.3578 - val_loss: 158.7810\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.5240 - val_loss: 158.8927\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.8958 - val_loss: 158.4747\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.3020 - val_loss: 158.1654\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.0718 - val_loss: 158.4589\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1544.7445 - val_loss: 1460.9753\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1491.7570 - val_loss: 1403.7231\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1424.1383 - val_loss: 1327.9801\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1333.5519 - val_loss: 1225.7474\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1214.6320 - val_loss: 1093.2510\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1064.2312 - val_loss: 932.3239\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 889.8994 - val_loss: 752.8937\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 701.3575 - val_loss: 577.2885\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 525.7164 - val_loss: 421.0972\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 380.1942 - val_loss: 313.8773\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 284.0005 - val_loss: 256.0218\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 235.8810 - val_loss: 232.3698\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 215.1344 - val_loss: 225.5234\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 208.2450 - val_loss: 222.9472\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.2747 - val_loss: 220.1514\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 201.1727 - val_loss: 217.2455\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.5850 - val_loss: 213.4928\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.4239 - val_loss: 212.0973\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.0092 - val_loss: 208.6557\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.2247 - val_loss: 206.7710\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 190.1841 - val_loss: 203.9840\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.7331 - val_loss: 203.3790\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.0870 - val_loss: 200.8072\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.4769 - val_loss: 198.9432\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.1958 - val_loss: 197.5698\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.9959 - val_loss: 195.8385\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.6171 - val_loss: 195.3793\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.7068 - val_loss: 194.6614\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.2480 - val_loss: 191.9789\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.2834 - val_loss: 190.9862\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.2251 - val_loss: 190.1852\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.0151 - val_loss: 189.0683\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.9720 - val_loss: 188.1740\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.2446 - val_loss: 187.6976\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.1239 - val_loss: 186.4188\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.2841 - val_loss: 185.7020\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.8551 - val_loss: 185.1423\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.6895 - val_loss: 184.6734\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.1166 - val_loss: 182.8644\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.2988 - val_loss: 182.1784\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.6626 - val_loss: 182.1209\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.9023 - val_loss: 180.4772\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.8221 - val_loss: 180.2369\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.9646 - val_loss: 179.6699\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.7958 - val_loss: 179.0454\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.2768 - val_loss: 178.2118\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.4359 - val_loss: 176.5262\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.8315 - val_loss: 176.6415\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.2748 - val_loss: 176.6932\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.5446 - val_loss: 174.9095\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.1254 - val_loss: 173.4876\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.2774 - val_loss: 174.7011\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.9789 - val_loss: 173.1544\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.3719 - val_loss: 173.5450\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.5553 - val_loss: 172.1394\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.9159 - val_loss: 172.0736\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.7212 - val_loss: 170.6903\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.5315 - val_loss: 171.2482\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.4641 - val_loss: 169.3208\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.1660 - val_loss: 169.2883\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8599 - val_loss: 168.2366\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.0996 - val_loss: 168.8483\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.7986 - val_loss: 167.3404\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.2622 - val_loss: 167.2566\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.4935 - val_loss: 167.1309\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.0955 - val_loss: 164.9816\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.6830 - val_loss: 165.8919\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.5547 - val_loss: 164.6677\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.6792 - val_loss: 165.0978\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.1760 - val_loss: 165.0200\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.5719 - val_loss: 163.0914\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.1471 - val_loss: 162.8664\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.8337 - val_loss: 163.7969\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.0450 - val_loss: 161.9126\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.5312 - val_loss: 160.9809\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.7700 - val_loss: 161.2525\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.3093 - val_loss: 160.0085\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.8602 - val_loss: 159.9699\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.3501 - val_loss: 159.4516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.2211 - val_loss: 160.2587\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.2425 - val_loss: 158.2473\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.9302 - val_loss: 157.7941\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.7048 - val_loss: 158.1214\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.2650 - val_loss: 157.6455\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.6895 - val_loss: 157.5650\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.3391 - val_loss: 156.1771\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.1064 - val_loss: 157.1051\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.6527 - val_loss: 156.2925\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.1102 - val_loss: 155.4623\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.0575 - val_loss: 156.2467\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.2117 - val_loss: 154.8019\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.2518 - val_loss: 154.2677\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.1613 - val_loss: 154.7142\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.2334 - val_loss: 155.2492\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.0325 - val_loss: 154.0642\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.9158 - val_loss: 153.3855\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.2812 - val_loss: 153.5223\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.9101 - val_loss: 154.1368\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.8541 - val_loss: 153.7160\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.4882 - val_loss: 152.1743\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1546.4327 - val_loss: 1507.6240\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1497.3630 - val_loss: 1452.3906\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1440.0378 - val_loss: 1387.2069\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1370.3079 - val_loss: 1306.6422\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1280.5908 - val_loss: 1201.2063\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1167.3434 - val_loss: 1072.6715\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1032.6951 - val_loss: 928.9009\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 881.6038 - val_loss: 773.7130\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 722.7178 - val_loss: 617.6321\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 566.2981 - val_loss: 478.8046\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 429.4095 - val_loss: 369.5532\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 326.2593 - val_loss: 293.5795\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 255.6795 - val_loss: 251.7933\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 216.0632 - val_loss: 234.6953\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.2444 - val_loss: 228.8815\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.6157 - val_loss: 227.4225\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.1494 - val_loss: 226.4722\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.3601 - val_loss: 226.2296\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.6012 - val_loss: 223.9165\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.0844 - val_loss: 222.6737\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.0878 - val_loss: 221.6451\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.6110 - val_loss: 220.7047\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.4845 - val_loss: 219.1902\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.3962 - val_loss: 218.0223\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.5989 - val_loss: 216.6512\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.6322 - val_loss: 215.9304\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.9346 - val_loss: 214.4072\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.6032 - val_loss: 213.6259\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.9189 - val_loss: 212.4680\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.2489 - val_loss: 212.2020\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.3328 - val_loss: 211.4663\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.5997 - val_loss: 209.8160\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.9454 - val_loss: 209.3005\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.3007 - val_loss: 208.1394\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.6629 - val_loss: 207.2802\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.1019 - val_loss: 206.3387\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.2816 - val_loss: 206.3007\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.7699 - val_loss: 205.6825\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.6134 - val_loss: 204.7864\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.5691 - val_loss: 204.5740\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 164.0712 - val_loss: 203.1304\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.3091 - val_loss: 202.4694\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.9076 - val_loss: 201.6929\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.4203 - val_loss: 201.4323\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.7586 - val_loss: 200.4383\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.1597 - val_loss: 200.2278\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.6299 - val_loss: 199.1840\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.9566 - val_loss: 198.9057\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.6216 - val_loss: 197.4167\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.9257 - val_loss: 197.5126\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.6436 - val_loss: 197.0891\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.9372 - val_loss: 195.1903\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.0993 - val_loss: 194.7263\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.7310 - val_loss: 193.6448\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.0677 - val_loss: 192.9941\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.2362 - val_loss: 192.3320\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.7729 - val_loss: 191.8235\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.2129 - val_loss: 191.2417\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.7163 - val_loss: 190.0544\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.0431 - val_loss: 189.6202\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.4443 - val_loss: 188.8176\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.0764 - val_loss: 188.9471\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.4144 - val_loss: 187.3587\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.6006 - val_loss: 186.4623\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.1672 - val_loss: 186.3974\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.5039 - val_loss: 185.0799\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.0792 - val_loss: 184.9210\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.6062 - val_loss: 183.9573\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.4330 - val_loss: 183.8770\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.5637 - val_loss: 182.7818\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.8625 - val_loss: 181.7951\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.1709 - val_loss: 181.4584\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.0294 - val_loss: 180.8102\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.3570 - val_loss: 179.5244\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.8178 - val_loss: 179.5979\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.3568 - val_loss: 178.9910\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.6069 - val_loss: 177.5906\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.0041 - val_loss: 177.5336\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 142.6181 - val_loss: 175.9712\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.0457 - val_loss: 176.9195\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.3028 - val_loss: 175.2557\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.9384 - val_loss: 175.2866\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.5602 - val_loss: 174.5249\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.9326 - val_loss: 173.6398\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.7278 - val_loss: 173.1045\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.3271 - val_loss: 173.1707\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.7204 - val_loss: 172.2685\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.3952 - val_loss: 171.8407\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.8948 - val_loss: 172.0021\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 137.5473 - val_loss: 171.7488\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.0808 - val_loss: 170.9344\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 136.7652 - val_loss: 169.2476\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.2777 - val_loss: 170.0446\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.5904 - val_loss: 169.3544\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.8287 - val_loss: 168.4832\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.6279 - val_loss: 169.7592\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.1737 - val_loss: 168.3062\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.9878 - val_loss: 168.7040\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.4675 - val_loss: 166.9060\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.2911 - val_loss: 167.6566\n",
      "10/10 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1483.9302 - val_loss: 1573.6842\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1426.2946 - val_loss: 1508.2863\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1357.6638 - val_loss: 1425.6946\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1268.2871 - val_loss: 1318.8523\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1151.7526 - val_loss: 1182.2804\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1009.4882 - val_loss: 1020.0083\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 848.7098 - val_loss: 844.2344\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 683.4555 - val_loss: 669.2297\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 528.9225 - val_loss: 514.6243\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 402.5393 - val_loss: 395.4217\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 310.6995 - val_loss: 318.2203\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 258.7198 - val_loss: 271.4971\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 230.7422 - val_loss: 248.8774\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 218.1120 - val_loss: 237.3178\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.5678 - val_loss: 230.1707\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.5370 - val_loss: 225.2202\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.6686 - val_loss: 221.2156\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.6746 - val_loss: 216.9549\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.5550 - val_loss: 214.2045\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.4564 - val_loss: 212.1985\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.1916 - val_loss: 209.5011\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.1453 - val_loss: 206.2450\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.2811 - val_loss: 204.8896\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.4636 - val_loss: 203.5241\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.1777 - val_loss: 201.9214\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.7247 - val_loss: 200.6645\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.3899 - val_loss: 199.0079\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.6467 - val_loss: 197.2939\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.9898 - val_loss: 196.9005\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.9505 - val_loss: 195.5661\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.0121 - val_loss: 194.2656\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.0880 - val_loss: 193.5562\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.2837 - val_loss: 192.2556\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.9023 - val_loss: 191.5934\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.5754 - val_loss: 190.8505\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 172.6619 - val_loss: 190.1152\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.9748 - val_loss: 189.3291\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.9531 - val_loss: 188.5837\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.5779 - val_loss: 187.7944\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.8161 - val_loss: 186.9838\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.9844 - val_loss: 186.2189\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.2902 - val_loss: 185.8007\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.0724 - val_loss: 184.9848\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.3758 - val_loss: 184.4321\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.3231 - val_loss: 184.3915\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.1696 - val_loss: 183.4115\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.7427 - val_loss: 182.2811\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.1042 - val_loss: 182.3217\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.5361 - val_loss: 181.5303\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.1885 - val_loss: 181.2528\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.6351 - val_loss: 180.5014\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.1206 - val_loss: 179.9067\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.5954 - val_loss: 179.9442\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.4416 - val_loss: 179.0205\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.9648 - val_loss: 178.7314\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.3402 - val_loss: 178.3619\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.8406 - val_loss: 178.1643\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.4115 - val_loss: 177.3543\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.3550 - val_loss: 177.2239\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.6193 - val_loss: 176.5305\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.2596 - val_loss: 175.8099\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 158.6325 - val_loss: 175.9117\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.3465 - val_loss: 175.1242\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.1090 - val_loss: 174.0904\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4450 - val_loss: 174.3734\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8771 - val_loss: 173.6612\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.4646 - val_loss: 172.8043\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.0480 - val_loss: 172.5700\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.5385 - val_loss: 172.0180\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.1148 - val_loss: 171.0988\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.6953 - val_loss: 171.1382\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.0478 - val_loss: 170.1888\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.2747 - val_loss: 170.1056\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.1902 - val_loss: 168.8308\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.5444 - val_loss: 168.5222\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.9569 - val_loss: 168.2690\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8609 - val_loss: 167.6105\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.4437 - val_loss: 167.2469\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 150.9911 - val_loss: 167.1797\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.8846 - val_loss: 167.0881\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.6352 - val_loss: 166.1710\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.6059 - val_loss: 166.4753\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.1343 - val_loss: 165.8166\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.1952 - val_loss: 165.0765\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.3694 - val_loss: 165.3020\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.1059 - val_loss: 164.5339\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.9728 - val_loss: 164.8392\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.3310 - val_loss: 164.1021\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.7730 - val_loss: 164.0723\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.8697 - val_loss: 163.2488\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.9908 - val_loss: 163.9559\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 145.8928 - val_loss: 162.9004\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 145.0963 - val_loss: 162.6790\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.8368 - val_loss: 162.3147\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.5309 - val_loss: 162.2391\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.9174 - val_loss: 161.4786\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.6566 - val_loss: 161.0849\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.1366 - val_loss: 160.7738\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.8897 - val_loss: 160.5600\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.4146 - val_loss: 160.8934\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1554.4218 - val_loss: 1561.8171\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1515.2640 - val_loss: 1519.7922\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1466.9506 - val_loss: 1462.0178\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1397.1129 - val_loss: 1379.9769\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1300.6187 - val_loss: 1269.8779\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1173.6835 - val_loss: 1126.7542\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1012.5852 - val_loss: 952.0051\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 827.4918 - val_loss: 762.5558\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 637.9904 - val_loss: 581.0829\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 472.9010 - val_loss: 431.7249\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 348.8805 - val_loss: 336.6597\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 278.1888 - val_loss: 281.5430\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 242.5805 - val_loss: 258.4753\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 227.3394 - val_loss: 247.4542\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 220.7063 - val_loss: 239.1163\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 214.2544 - val_loss: 234.1101\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.2525 - val_loss: 230.5764\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.8362 - val_loss: 227.0140\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.0650 - val_loss: 222.8947\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.8949 - val_loss: 220.4351\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.3002 - val_loss: 218.1947\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.3962 - val_loss: 215.2592\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.2668 - val_loss: 213.3456\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.9223 - val_loss: 211.4684\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.0999 - val_loss: 208.7207\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.2299 - val_loss: 207.1261\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.5350 - val_loss: 206.0112\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.8401 - val_loss: 203.9641\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.4400 - val_loss: 203.1592\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.6565 - val_loss: 201.4773\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.2655 - val_loss: 199.9346\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.2989 - val_loss: 198.9345\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.1184 - val_loss: 197.6571\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 172.6122 - val_loss: 196.3178\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.4687 - val_loss: 195.2305\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.2462 - val_loss: 194.1658\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.4578 - val_loss: 193.5629\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.2865 - val_loss: 192.1882\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.1610 - val_loss: 190.7751\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.2461 - val_loss: 189.9232\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.4248 - val_loss: 189.4069\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.5573 - val_loss: 188.2972\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.4572 - val_loss: 187.6027\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.7135 - val_loss: 186.3342\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.0076 - val_loss: 185.8057\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.0138 - val_loss: 184.5971\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.5798 - val_loss: 184.1774\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.6480 - val_loss: 183.2315\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.8929 - val_loss: 182.3703\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.4054 - val_loss: 181.7067\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.9270 - val_loss: 181.1665\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8775 - val_loss: 180.6650\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.1773 - val_loss: 179.6503\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.9826 - val_loss: 179.5558\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.3328 - val_loss: 178.6834\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.7640 - val_loss: 177.9126\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.2284 - val_loss: 177.6769\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.9266 - val_loss: 176.7423\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.0606 - val_loss: 176.4873\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.7371 - val_loss: 175.9824\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.9977 - val_loss: 175.4885\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8267 - val_loss: 175.2745\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.4934 - val_loss: 174.2658\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.1786 - val_loss: 173.8742\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.9866 - val_loss: 173.2109\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.5222 - val_loss: 172.6165\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.2267 - val_loss: 172.1231\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.4713 - val_loss: 171.6161\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.3260 - val_loss: 171.1359\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.0382 - val_loss: 170.3756\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.4390 - val_loss: 170.2595\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.6425 - val_loss: 169.5406\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.1326 - val_loss: 169.4068\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.7735 - val_loss: 168.6291\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.3229 - val_loss: 168.3290\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.6361 - val_loss: 168.0123\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.2305 - val_loss: 167.7004\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.9524 - val_loss: 166.8306\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 143.4740 - val_loss: 167.2947\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.9733 - val_loss: 166.5230\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.5426 - val_loss: 166.1836\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.5154 - val_loss: 166.0851\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.6717 - val_loss: 165.5002\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.4544 - val_loss: 165.2514\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.9282 - val_loss: 164.9381\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.9022 - val_loss: 164.6973\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.1225 - val_loss: 164.4966\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.8869 - val_loss: 164.1754\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.4784 - val_loss: 163.8908\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.4564 - val_loss: 163.8212\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.3100 - val_loss: 163.1393\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.5004 - val_loss: 163.7235\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.0832 - val_loss: 163.2724\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.8232 - val_loss: 162.6362\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.7769 - val_loss: 162.4884\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.5359 - val_loss: 162.7357\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.2863 - val_loss: 162.2894\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.7072 - val_loss: 162.4162\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.4160 - val_loss: 161.6558\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.0273 - val_loss: 161.4452\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1527.1185 - val_loss: 1569.5736\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1476.2507 - val_loss: 1513.9346\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1417.5818 - val_loss: 1445.3254\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1344.5919 - val_loss: 1360.1555\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1256.4629 - val_loss: 1259.1843\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1150.3541 - val_loss: 1140.8381\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1028.5665 - val_loss: 1003.6838\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 891.1224 - val_loss: 855.1501\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 747.1522 - val_loss: 707.3472\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 609.3966 - val_loss: 569.3259\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 487.1042 - val_loss: 453.5393\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 390.0481 - val_loss: 366.6993\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 320.5957 - val_loss: 304.7126\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 273.5269 - val_loss: 263.4730\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 244.1661 - val_loss: 238.1933\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 227.7223 - val_loss: 221.8107\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 217.3524 - val_loss: 212.9303\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.4725 - val_loss: 207.2893\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.6065 - val_loss: 203.3775\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.3974 - val_loss: 199.4853\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.5109 - val_loss: 197.3549\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.6733 - val_loss: 195.6476\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.5057 - val_loss: 193.4890\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.3928 - val_loss: 191.4713\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.0014 - val_loss: 190.3502\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.9182 - val_loss: 188.3113\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.4855 - val_loss: 186.4931\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.1832 - val_loss: 184.9808\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.8119 - val_loss: 182.9466\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.4193 - val_loss: 182.1037\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.7040 - val_loss: 180.9174\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.1111 - val_loss: 178.9595\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.1258 - val_loss: 177.9465\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.0415 - val_loss: 176.5926\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.0682 - val_loss: 175.3547\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.1166 - val_loss: 174.7717\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.0927 - val_loss: 173.6733\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.3029 - val_loss: 172.3066\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.5468 - val_loss: 171.2720\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.6575 - val_loss: 170.8022\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.0107 - val_loss: 170.2081\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.1965 - val_loss: 169.1381\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.4664 - val_loss: 168.2152\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.7904 - val_loss: 167.6396\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.1552 - val_loss: 166.4873\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.8590 - val_loss: 165.9418\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.8435 - val_loss: 165.0253\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.8123 - val_loss: 165.1930\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.0859 - val_loss: 163.4943\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.1080 - val_loss: 163.5498\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.7157 - val_loss: 163.2712\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.1466 - val_loss: 162.0411\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.5319 - val_loss: 161.3228\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.2441 - val_loss: 160.0602\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.9679 - val_loss: 160.0570\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.1059 - val_loss: 160.5326\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.9782 - val_loss: 159.4259\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.2802 - val_loss: 158.0129\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.6282 - val_loss: 157.3559\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.1615 - val_loss: 157.2750\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.8040 - val_loss: 156.8344\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.2048 - val_loss: 156.2604\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.8566 - val_loss: 156.2749\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.2163 - val_loss: 154.9117\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.7334 - val_loss: 155.2292\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.7324 - val_loss: 154.2926\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.2308 - val_loss: 153.5208\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.7020 - val_loss: 152.1842\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.1109 - val_loss: 152.2654\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.6981 - val_loss: 151.8351\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.5187 - val_loss: 151.6272\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.2631 - val_loss: 150.5961\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.6603 - val_loss: 150.5204\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.2342 - val_loss: 150.4005\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.0309 - val_loss: 149.3315\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.5213 - val_loss: 148.9341\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.2022 - val_loss: 148.7179\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.8904 - val_loss: 148.5895\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 157.5242 - val_loss: 148.6264\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.3335 - val_loss: 147.2612\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.9811 - val_loss: 146.8728\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.4376 - val_loss: 146.6246\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.5941 - val_loss: 146.8950\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.0953 - val_loss: 146.1405\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.4358 - val_loss: 145.3310\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.1457 - val_loss: 145.3202\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.2480 - val_loss: 145.0222\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.1566 - val_loss: 144.4753\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.1959 - val_loss: 144.3477\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.9512 - val_loss: 143.4942\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.7055 - val_loss: 143.0128\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.1359 - val_loss: 142.7741\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.0610 - val_loss: 142.0751\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.7911 - val_loss: 141.9435\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.5146 - val_loss: 141.3901\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.2587 - val_loss: 141.1380\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.0330 - val_loss: 140.7260\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.9849 - val_loss: 140.0606\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.1683 - val_loss: 140.0094\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.1259 - val_loss: 139.9979\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#The code\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "\n",
    "mse_values = []\n",
    "for i in range(50):\n",
    "    #The train test split:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3) \n",
    "    #Producing the model:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape=(X.shape[1],), activation='relu'))  # Input layer with 32 neurons\n",
    "    model.add(Dense(10, activation='relu'))  # Hidden layer with 16 neurons\n",
    "    model.add(Dense(1, activation='linear'))  \n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.001))\n",
    "    model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86ec7b00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average MSE over 50 runs: 153.11510656636077\n",
      "\n",
      "Average MSE standard deviations over 50 runs: 10.2510115599912\n"
     ]
    }
   ],
   "source": [
    "average_mse = np.mean(mse_values)\n",
    "std_dev_mse=np.std(mse_values)\n",
    "print(f\"\\nAverage MSE over 50 runs: {average_mse}\")\n",
    "print(f\"\\nAverage MSE standard deviations over 50 runs: {std_dev_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638fafa6",
   "metadata": {},
   "source": [
    "## In comparison to the \"B model\", both the MSE and its standard deviation decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11024ea3",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "D. Increase the number of hidden layers (5 marks)\n",
    "\n",
    "Repeat part B but use a neural network with the following instead:\n",
    "\n",
    "- Three hidden layers, each of 10 nodes and ReLU activation function.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a52e7144",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 1510.4069 - val_loss: 1517.7566\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1454.3030 - val_loss: 1438.5192\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1347.0684 - val_loss: 1282.8558\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1142.4419 - val_loss: 1003.2161\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 809.0532 - val_loss: 609.7430\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 444.8062 - val_loss: 319.0630\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 280.8380 - val_loss: 265.9560\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 255.0373 - val_loss: 240.9715\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 238.9790 - val_loss: 224.9826\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 227.9386 - val_loss: 215.8603\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 219.7982 - val_loss: 209.6474\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 213.3970 - val_loss: 204.2108\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 209.2358 - val_loss: 199.4957\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.2935 - val_loss: 195.6726\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.5744 - val_loss: 192.6580\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.6044 - val_loss: 191.2602\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.5519 - val_loss: 188.7406\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.3232 - val_loss: 186.3589\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.9519 - val_loss: 183.8741\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 186.0708 - val_loss: 181.6165\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.0986 - val_loss: 180.5768\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 181.1210 - val_loss: 180.1899\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 179.7170 - val_loss: 177.8567\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.7687 - val_loss: 176.6816\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.2779 - val_loss: 175.5110\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.3862 - val_loss: 174.9077\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.7314 - val_loss: 173.0702\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.3876 - val_loss: 172.4092\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 169.9707 - val_loss: 170.9541\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.5883 - val_loss: 170.7113\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.2357 - val_loss: 169.5475\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.9618 - val_loss: 168.9709\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.1596 - val_loss: 168.3610\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.6002 - val_loss: 167.6149\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.7866 - val_loss: 166.4879\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.5681 - val_loss: 166.3547\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.3579 - val_loss: 165.5939\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.6536 - val_loss: 164.3202\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.4088 - val_loss: 164.7686\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.9946 - val_loss: 163.3739\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.4768 - val_loss: 163.2989\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.2119 - val_loss: 162.0700\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.2927 - val_loss: 161.5751\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.5842 - val_loss: 160.7982\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.7567 - val_loss: 160.8507\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.2171 - val_loss: 160.3983\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 153.2042 - val_loss: 159.1673\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.5128 - val_loss: 159.1490\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.4479 - val_loss: 158.8793\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.8475 - val_loss: 158.3749\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.3328 - val_loss: 157.7189\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.7065 - val_loss: 156.9740\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.6597 - val_loss: 156.6580\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.3049 - val_loss: 155.8694\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.0422 - val_loss: 155.9916\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.1928 - val_loss: 154.7948\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 147.3189 - val_loss: 154.9994\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.9698 - val_loss: 154.8356\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.3807 - val_loss: 153.7499\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.0634 - val_loss: 153.4330\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.7794 - val_loss: 153.5028\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.0041 - val_loss: 153.1056\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.0108 - val_loss: 152.5948\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.7739 - val_loss: 152.8273\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.5078 - val_loss: 151.5146\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.5455 - val_loss: 150.8062\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.5250 - val_loss: 151.4116\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.4469 - val_loss: 150.0254\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.1232 - val_loss: 149.8282\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.5972 - val_loss: 149.1559\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.6349 - val_loss: 149.8618\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.0879 - val_loss: 148.7907\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.9303 - val_loss: 148.7574\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.9663 - val_loss: 148.9527\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.1870 - val_loss: 147.1164\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.4744 - val_loss: 146.9327\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.5404 - val_loss: 147.5254\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.9834 - val_loss: 147.0945\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.3778 - val_loss: 145.4695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.7826 - val_loss: 145.7042\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.5112 - val_loss: 145.3696\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.4370 - val_loss: 145.5759\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.7354 - val_loss: 144.8134\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.1202 - val_loss: 144.2394\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.8865 - val_loss: 145.0087\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.3885 - val_loss: 144.2249\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.0285 - val_loss: 144.6026\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.7227 - val_loss: 144.3062\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.6118 - val_loss: 143.2304\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.6548 - val_loss: 143.2373\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.8039 - val_loss: 143.9890\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.9300 - val_loss: 143.2270\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.8667 - val_loss: 142.6056\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.2567 - val_loss: 142.0776\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.3712 - val_loss: 142.2342\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.2124 - val_loss: 142.4568\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.0448 - val_loss: 142.1058\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.0374 - val_loss: 141.1577\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.8486 - val_loss: 141.3123\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.3191 - val_loss: 141.2142\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 9ms/step - loss: 1545.7257 - val_loss: 1535.9248\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1508.4501 - val_loss: 1480.1838\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1421.5486 - val_loss: 1356.8322\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1247.2871 - val_loss: 1126.2279\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 958.5392 - val_loss: 781.2089\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 600.8246 - val_loss: 444.5088\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 361.8697 - val_loss: 292.2195\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 279.7903 - val_loss: 224.2361\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 238.5166 - val_loss: 196.6115\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 219.0130 - val_loss: 185.6041\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 211.5506 - val_loss: 179.5208\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 206.8731 - val_loss: 177.0988\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.9871 - val_loss: 173.9874\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.8837 - val_loss: 170.6220\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.8942 - val_loss: 167.9546\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.2115 - val_loss: 166.6801\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.8802 - val_loss: 164.3199\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.6417 - val_loss: 163.8939\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.5679 - val_loss: 161.5598\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.8421 - val_loss: 159.6863\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.4528 - val_loss: 158.6248\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.9905 - val_loss: 158.0374\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.4272 - val_loss: 155.2073\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.7613 - val_loss: 154.2130\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.3683 - val_loss: 152.9596\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.4700 - val_loss: 152.0331\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.4704 - val_loss: 150.9266\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.6996 - val_loss: 149.6210\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.9122 - val_loss: 148.6705\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.2346 - val_loss: 147.8011\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.9137 - val_loss: 146.7035\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.2577 - val_loss: 145.5392\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.8103 - val_loss: 145.1029\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.1937 - val_loss: 144.0183\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.0379 - val_loss: 143.9966\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.7604 - val_loss: 142.1819\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.5028 - val_loss: 141.3750\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.7132 - val_loss: 141.0132\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 150.8599 - val_loss: 140.0462\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.8792 - val_loss: 140.1120\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.9991 - val_loss: 139.0630\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.0419 - val_loss: 138.8634\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.6826 - val_loss: 138.0143\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 145.6049 - val_loss: 137.1104\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 145.2251 - val_loss: 138.0174\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.7324 - val_loss: 136.3946\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.3066 - val_loss: 136.4084\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.8082 - val_loss: 137.2533\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.7106 - val_loss: 135.7780\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.1901 - val_loss: 136.8312\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.3228 - val_loss: 135.2484\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.4152 - val_loss: 135.5162\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.8118 - val_loss: 135.1814\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 139.4745 - val_loss: 135.7309\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.1209 - val_loss: 135.2191\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.5743 - val_loss: 135.4107\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.4069 - val_loss: 135.5275\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 136.6485 - val_loss: 137.1376\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.5196 - val_loss: 134.6119\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.1677 - val_loss: 134.8541\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 133.9646 - val_loss: 134.6249\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.0458 - val_loss: 134.8262\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.3557 - val_loss: 134.8295\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.4147 - val_loss: 134.5804\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.2899 - val_loss: 134.5931\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.1358 - val_loss: 135.3660\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.7493 - val_loss: 134.6080\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.1853 - val_loss: 135.1429\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.5715 - val_loss: 135.6871\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.6598 - val_loss: 134.4769\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.5757 - val_loss: 135.1022\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.2604 - val_loss: 134.8308\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.0778 - val_loss: 135.3086\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.6349 - val_loss: 134.9255\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.9579 - val_loss: 135.2864\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.8339 - val_loss: 135.3708\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.5568 - val_loss: 135.2732\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.0635 - val_loss: 136.0879\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.6636 - val_loss: 135.3585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.0910 - val_loss: 135.2084\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.2120 - val_loss: 135.7079\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.7060 - val_loss: 135.7957\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 126.6369 - val_loss: 135.7790\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.9236 - val_loss: 136.0084\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.7589 - val_loss: 136.3171\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.7477 - val_loss: 136.8985\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.5418 - val_loss: 135.9535\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.2916 - val_loss: 137.3174\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.7657 - val_loss: 136.1172\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.8457 - val_loss: 137.1547\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.9323 - val_loss: 136.1021\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.7613 - val_loss: 138.8811\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.9443 - val_loss: 137.9633\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 124.9523 - val_loss: 136.5631\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.6008 - val_loss: 138.1399\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.8325 - val_loss: 137.0653\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.6970 - val_loss: 136.7915\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.9312 - val_loss: 138.9254\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.9371 - val_loss: 137.1149\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.3248 - val_loss: 138.2960\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 9ms/step - loss: 1553.8171 - val_loss: 1612.8948\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1538.5983 - val_loss: 1605.5793\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1532.5560 - val_loss: 1599.0094\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1522.2327 - val_loss: 1581.8829\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1489.8741 - val_loss: 1526.0052\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1398.1266 - val_loss: 1382.5964\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1193.2633 - val_loss: 1089.6289\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 826.5206 - val_loss: 639.2821\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 410.8871 - val_loss: 293.7900\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 253.0842 - val_loss: 224.4751\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 221.4799 - val_loss: 215.8577\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 209.3243 - val_loss: 210.0756\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.1150 - val_loss: 206.8902\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.9706 - val_loss: 204.0648\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.0532 - val_loss: 201.0929\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.2294 - val_loss: 199.1544\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.3950 - val_loss: 196.1001\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.0882 - val_loss: 193.7808\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.9850 - val_loss: 192.1035\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.9397 - val_loss: 190.4113\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.4674 - val_loss: 188.4419\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.7759 - val_loss: 187.3153\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.4719 - val_loss: 184.8408\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.8262 - val_loss: 184.1089\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 163.9415 - val_loss: 181.3755\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.7578 - val_loss: 182.1400\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.7070 - val_loss: 178.6921\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.7652 - val_loss: 178.0301\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.8069 - val_loss: 176.9284\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.1619 - val_loss: 175.5701\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.2908 - val_loss: 173.0786\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.9183 - val_loss: 173.9853\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.3466 - val_loss: 171.2265\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.2964 - val_loss: 169.8407\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.9550 - val_loss: 169.2986\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.6962 - val_loss: 167.1692\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.4064 - val_loss: 166.5054\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.6053 - val_loss: 165.3532\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.3078 - val_loss: 165.7631\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.1697 - val_loss: 164.2404\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.1891 - val_loss: 162.4971\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.0862 - val_loss: 162.2742\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.3422 - val_loss: 161.6034\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.2492 - val_loss: 161.9102\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.6417 - val_loss: 160.2594\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.5073 - val_loss: 159.3719\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.6220 - val_loss: 159.0045\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.7670 - val_loss: 159.2869\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.8115 - val_loss: 158.5611\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.5315 - val_loss: 158.3304\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.7395 - val_loss: 156.9439\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.8399 - val_loss: 156.8204\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.3609 - val_loss: 156.5311\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.5283 - val_loss: 156.1754\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.4458 - val_loss: 156.6513\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.7492 - val_loss: 155.9211\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.2172 - val_loss: 155.2535\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.4896 - val_loss: 155.3698\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.7024 - val_loss: 155.5918\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.2052 - val_loss: 154.8714\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.3941 - val_loss: 156.3056\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.9422 - val_loss: 153.8746\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.6120 - val_loss: 153.6200\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.5511 - val_loss: 153.4739\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.1642 - val_loss: 153.5577\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.4797 - val_loss: 153.0967\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.5396 - val_loss: 153.5854\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.1116 - val_loss: 152.6783\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.1814 - val_loss: 153.0812\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.6686 - val_loss: 152.2969\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.6016 - val_loss: 152.8907\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.2790 - val_loss: 153.5050\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.0386 - val_loss: 152.6169\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.1461 - val_loss: 152.0862\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.4686 - val_loss: 152.0582\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 116.1302 - val_loss: 151.8420\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.9438 - val_loss: 152.7437\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.6834 - val_loss: 151.8641\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 116.6862 - val_loss: 151.8026\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.6921 - val_loss: 151.4899\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.5469 - val_loss: 151.1755\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.3777 - val_loss: 151.4455\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.2572 - val_loss: 151.5991\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.8795 - val_loss: 151.7571\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.8378 - val_loss: 151.4075\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.8735 - val_loss: 151.7091\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.4129 - val_loss: 151.2222\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.1280 - val_loss: 150.3825\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.2008 - val_loss: 151.5018\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 114.4851 - val_loss: 151.3440\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.0243 - val_loss: 151.3769\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 113.8857 - val_loss: 151.0148\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.2750 - val_loss: 151.0805\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 113.6342 - val_loss: 151.5949\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 113.5598 - val_loss: 150.7705\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 113.4035 - val_loss: 151.3484\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.6559 - val_loss: 150.9674\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 113.0519 - val_loss: 150.6956\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 113.6567 - val_loss: 151.1866\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 112.3590 - val_loss: 150.9791\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 11ms/step - loss: 1553.4532 - val_loss: 1550.5895\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1519.5525 - val_loss: 1509.0112\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 1459.6595 - val_loss: 1424.4242\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1335.8350 - val_loss: 1254.2418\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1098.0328 - val_loss: 933.2021\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 694.2979 - val_loss: 480.4748\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 312.2920 - val_loss: 264.8835\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 229.3307 - val_loss: 249.3169\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 211.2997 - val_loss: 237.3150\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.2313 - val_loss: 231.3481\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.6422 - val_loss: 225.9869\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.8387 - val_loss: 220.1171\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 187.8718 - val_loss: 215.5721\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.5166 - val_loss: 213.3659\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.3418 - val_loss: 210.0914\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.4190 - val_loss: 206.2878\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.2085 - val_loss: 204.7523\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.0199 - val_loss: 202.1178\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.4205 - val_loss: 200.2198\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.1057 - val_loss: 196.9438\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.5280 - val_loss: 196.5775\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.1173 - val_loss: 194.7159\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.3561 - val_loss: 191.7758\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.2406 - val_loss: 190.7864\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.9986 - val_loss: 189.5725\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.4272 - val_loss: 187.8300\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.0833 - val_loss: 186.5331\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4559 - val_loss: 185.1922\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.0036 - val_loss: 184.7290\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.7611 - val_loss: 183.8201\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.6207 - val_loss: 181.3268\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.5823 - val_loss: 179.6460\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.9590 - val_loss: 178.9229\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.7675 - val_loss: 178.1958\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.5259 - val_loss: 177.2286\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.0981 - val_loss: 175.4202\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.7561 - val_loss: 174.4161\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 143.7719 - val_loss: 172.3961\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.8033 - val_loss: 171.1660\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.2906 - val_loss: 170.6452\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.3925 - val_loss: 168.8709\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.9833 - val_loss: 169.7981\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.4444 - val_loss: 166.4980\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.1348 - val_loss: 167.1079\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.5189 - val_loss: 164.5399\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.4785 - val_loss: 163.7007\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.8081 - val_loss: 163.1177\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.5123 - val_loss: 163.2812\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.0101 - val_loss: 162.8730\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.5213 - val_loss: 161.0609\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.1766 - val_loss: 160.0800\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.5895 - val_loss: 160.5570\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.1302 - val_loss: 160.2439\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.4225 - val_loss: 159.9261\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.4488 - val_loss: 159.5137\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.9026 - val_loss: 158.8431\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.6537 - val_loss: 157.8876\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.5165 - val_loss: 157.8631\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.8972 - val_loss: 158.5260\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 125.6006 - val_loss: 158.0352\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.4745 - val_loss: 157.7545\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.2535 - val_loss: 156.8389\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.1058 - val_loss: 156.9901\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.5168 - val_loss: 156.3283\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.3113 - val_loss: 155.8914\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.6896 - val_loss: 155.5529\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.4373 - val_loss: 155.7166\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.6938 - val_loss: 155.9666\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.5953 - val_loss: 157.4704\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.6293 - val_loss: 157.4628\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.8372 - val_loss: 155.2914\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.9110 - val_loss: 158.1809\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.8499 - val_loss: 154.8323\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.3826 - val_loss: 156.3655\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.6501 - val_loss: 155.7849\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.6706 - val_loss: 157.1011\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.2775 - val_loss: 154.6628\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.4309 - val_loss: 157.3663\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.4305 - val_loss: 153.8996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.1033 - val_loss: 154.6505\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.1706 - val_loss: 154.6796\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.6288 - val_loss: 154.9452\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.6628 - val_loss: 155.0011\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.9271 - val_loss: 154.8831\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.1463 - val_loss: 156.0536\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.2117 - val_loss: 155.1803\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.0864 - val_loss: 154.2863\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.8661 - val_loss: 156.0129\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.6620 - val_loss: 154.2816\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.8196 - val_loss: 153.9348\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 117.7445 - val_loss: 153.1990\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.9383 - val_loss: 154.5850\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.3613 - val_loss: 154.4085\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 116.9981 - val_loss: 152.9227\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.8056 - val_loss: 152.7982\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 116.9873 - val_loss: 154.6150\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.0348 - val_loss: 154.7840\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.9767 - val_loss: 154.0492\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.8600 - val_loss: 152.3463\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.0122 - val_loss: 154.3530\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1518.7194 - val_loss: 1625.1375\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1479.7294 - val_loss: 1562.1696\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1388.2262 - val_loss: 1415.9413\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1188.2079 - val_loss: 1114.5956\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 837.0316 - val_loss: 669.2012\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 455.0959 - val_loss: 334.9264\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 294.3634 - val_loss: 261.1845\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 256.2132 - val_loss: 239.1856\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 235.8846 - val_loss: 228.5795\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 224.0971 - val_loss: 217.7467\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 214.0176 - val_loss: 212.0726\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.6056 - val_loss: 206.7356\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.7553 - val_loss: 203.9998\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.9421 - val_loss: 198.6053\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.6635 - val_loss: 195.3800\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 191.4210 - val_loss: 193.7677\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.5920 - val_loss: 190.3068\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.3819 - val_loss: 189.5490\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.6145 - val_loss: 186.3120\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.2887 - val_loss: 186.4453\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.6455 - val_loss: 183.8351\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.9725 - val_loss: 181.9603\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.1889 - val_loss: 180.6461\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.1382 - val_loss: 178.9739\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.0994 - val_loss: 177.6989\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.5097 - val_loss: 175.7578\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.0246 - val_loss: 175.1790\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.3702 - val_loss: 172.8628\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.9735 - val_loss: 171.9958\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.5287 - val_loss: 171.7474\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.0408 - val_loss: 169.5332\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.3134 - val_loss: 168.6758\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.8786 - val_loss: 167.2858\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.0560 - val_loss: 166.6738\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.2232 - val_loss: 166.0112\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.3605 - val_loss: 164.1099\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.4030 - val_loss: 164.5846\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.2381 - val_loss: 162.6134\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.8901 - val_loss: 160.6642\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.3712 - val_loss: 161.1646\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.9243 - val_loss: 160.5216\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.9463 - val_loss: 158.3743\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.7729 - val_loss: 159.5519\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.8726 - val_loss: 158.4307\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.7737 - val_loss: 156.6589\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.7581 - val_loss: 156.5385\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.1419 - val_loss: 155.3205\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.2976 - val_loss: 155.3620\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.8120 - val_loss: 152.7875\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.9365 - val_loss: 154.5017\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.4871 - val_loss: 153.8481\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.0987 - val_loss: 150.3044\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.6066 - val_loss: 151.2254\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.5140 - val_loss: 151.6193\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.4643 - val_loss: 149.2191\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.6910 - val_loss: 150.4566\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.5344 - val_loss: 149.3842\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.1213 - val_loss: 149.3932\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.3932 - val_loss: 148.8534\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.3435 - val_loss: 147.3705\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.7881 - val_loss: 145.7527\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.8937 - val_loss: 146.4981\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.2270 - val_loss: 146.8718\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.8539 - val_loss: 146.8448\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.0853 - val_loss: 148.7382\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.0359 - val_loss: 146.6919\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.1448 - val_loss: 144.9467\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.0970 - val_loss: 145.2749\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.9333 - val_loss: 143.8572\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.4014 - val_loss: 146.3435\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.4849 - val_loss: 145.6671\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.3842 - val_loss: 143.4162\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.7443 - val_loss: 142.6174\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.3186 - val_loss: 141.9665\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.5949 - val_loss: 143.1899\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 131.8589 - val_loss: 142.6013\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.1133 - val_loss: 141.8022\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.2147 - val_loss: 142.6886\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.7608 - val_loss: 141.4079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.9680 - val_loss: 140.6461\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.8130 - val_loss: 141.1230\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.9707 - val_loss: 140.3969\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.4991 - val_loss: 139.7077\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 129.9959 - val_loss: 142.4833\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.1254 - val_loss: 139.2231\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.0504 - val_loss: 139.2732\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.0112 - val_loss: 140.0996\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.1592 - val_loss: 140.2323\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.8338 - val_loss: 138.7922\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.4238 - val_loss: 138.9788\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.3347 - val_loss: 139.4951\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.7945 - val_loss: 137.7608\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.6669 - val_loss: 141.9718\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.4884 - val_loss: 137.2007\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.2600 - val_loss: 138.8478\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 125.5693 - val_loss: 138.3026\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.3976 - val_loss: 141.3316\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.4417 - val_loss: 137.0786\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.8326 - val_loss: 141.0941\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.1135 - val_loss: 137.3871\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1549.2281 - val_loss: 1558.1198\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1524.3186 - val_loss: 1526.6064\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1480.8646 - val_loss: 1470.5374\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1403.6638 - val_loss: 1368.5269\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1265.1145 - val_loss: 1187.5157\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1023.0107 - val_loss: 877.2326\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 661.0730 - val_loss: 480.6349\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 339.0923 - val_loss: 254.0169\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 245.5625 - val_loss: 214.6618\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 216.1637 - val_loss: 202.4379\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.5109 - val_loss: 199.6728\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.4954 - val_loss: 193.5927\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.2517 - val_loss: 190.5619\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.4955 - val_loss: 187.6575\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.0854 - val_loss: 183.3842\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.3928 - val_loss: 181.3691\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.6392 - val_loss: 178.3633\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.5853 - val_loss: 177.3478\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.1695 - val_loss: 175.8450\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.0806 - val_loss: 173.4043\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.9245 - val_loss: 171.7895\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.0847 - val_loss: 171.5237\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.3710 - val_loss: 169.6981\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.3795 - val_loss: 169.3465\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.9404 - val_loss: 165.6397\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.4025 - val_loss: 166.9165\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.3260 - val_loss: 164.9828\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 155.8823 - val_loss: 163.2216\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.7078 - val_loss: 163.3244\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.5098 - val_loss: 162.9713\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.4268 - val_loss: 162.1858\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.1515 - val_loss: 160.0407\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.1508 - val_loss: 159.4631\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.3858 - val_loss: 159.1407\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.1662 - val_loss: 158.9573\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.7544 - val_loss: 156.4416\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.1332 - val_loss: 157.3136\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.1770 - val_loss: 156.7863\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.1261 - val_loss: 155.4735\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.2800 - val_loss: 154.7012\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.8428 - val_loss: 154.6558\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.0953 - val_loss: 153.3150\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.6711 - val_loss: 153.3527\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.1359 - val_loss: 153.1122\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.8853 - val_loss: 153.1600\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.8913 - val_loss: 151.2521\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.0027 - val_loss: 151.8208\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.1626 - val_loss: 151.4468\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.7039 - val_loss: 150.8428\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.1753 - val_loss: 149.5334\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.4821 - val_loss: 152.1312\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.8994 - val_loss: 148.5536\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.3940 - val_loss: 150.0811\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.0016 - val_loss: 148.2463\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.4548 - val_loss: 148.2129\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.5103 - val_loss: 148.4861\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.4961 - val_loss: 147.0813\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.9281 - val_loss: 148.2412\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.6628 - val_loss: 148.6735\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.4246 - val_loss: 145.7816\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.8894 - val_loss: 145.8757\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.0162 - val_loss: 146.9902\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.6165 - val_loss: 146.4947\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.3709 - val_loss: 146.5704\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.9462 - val_loss: 145.4771\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.7467 - val_loss: 145.6300\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.3239 - val_loss: 145.0393\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.0071 - val_loss: 145.4708\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.0122 - val_loss: 144.3791\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.1201 - val_loss: 145.1735\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.5287 - val_loss: 144.9171\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.9908 - val_loss: 143.7162\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.4600 - val_loss: 144.8800\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.5456 - val_loss: 144.4758\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.9124 - val_loss: 144.0465\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.8120 - val_loss: 143.9498\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.7973 - val_loss: 144.3615\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.4215 - val_loss: 142.4698\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.6347 - val_loss: 144.3633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.6025 - val_loss: 143.3762\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.8970 - val_loss: 142.4271\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.3282 - val_loss: 145.1798\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.3987 - val_loss: 142.9926\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.8491 - val_loss: 142.9216\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.0004 - val_loss: 143.2173\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.8058 - val_loss: 142.8212\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.7684 - val_loss: 143.5356\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.2092 - val_loss: 143.4201\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.0640 - val_loss: 142.8872\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.2232 - val_loss: 142.5286\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.6748 - val_loss: 142.4956\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.4024 - val_loss: 144.3589\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.8120 - val_loss: 142.9069\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.9664 - val_loss: 144.7605\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.6109 - val_loss: 142.6826\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 116.2899 - val_loss: 143.5986\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.1030 - val_loss: 142.3521\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 116.4555 - val_loss: 142.8727\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.2165 - val_loss: 143.4642\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.2637 - val_loss: 141.9668\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1605.8126 - val_loss: 1465.5059\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1587.4109 - val_loss: 1447.9043\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1559.0940 - val_loss: 1401.0305\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1478.2166 - val_loss: 1280.3411\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1297.8842 - val_loss: 1044.0419\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 970.7855 - val_loss: 677.0804\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 558.0466 - val_loss: 347.5375\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 298.4171 - val_loss: 249.2347\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 236.8646 - val_loss: 216.7884\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 213.7092 - val_loss: 206.3088\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.2199 - val_loss: 202.2025\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.7797 - val_loss: 199.1218\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.9268 - val_loss: 195.4488\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.0540 - val_loss: 191.5229\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.6291 - val_loss: 190.1484\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.2126 - val_loss: 186.6054\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.2760 - val_loss: 184.1611\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.3075 - val_loss: 182.2125\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.5399 - val_loss: 179.3226\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.7013 - val_loss: 178.0135\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.0537 - val_loss: 176.5424\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.7578 - val_loss: 173.4805\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.3965 - val_loss: 173.5123\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.8026 - val_loss: 171.4438\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.8059 - val_loss: 170.3517\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.4991 - val_loss: 169.5504\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.4903 - val_loss: 168.0819\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 160.2186 - val_loss: 167.5593\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.6000 - val_loss: 166.9318\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.2729 - val_loss: 164.4767\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.2378 - val_loss: 164.3323\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.6566 - val_loss: 161.1424\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 153.5161 - val_loss: 162.2263\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.7003 - val_loss: 161.4195\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 150.7563 - val_loss: 161.0882\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.0994 - val_loss: 160.8632\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.9382 - val_loss: 159.8607\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 147.0078 - val_loss: 159.6109\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 145.8819 - val_loss: 157.5971\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.7279 - val_loss: 158.4341\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.7439 - val_loss: 156.1166\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.8516 - val_loss: 156.2736\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.0353 - val_loss: 156.6174\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 140.6964 - val_loss: 153.3850\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 139.6335 - val_loss: 154.7864\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.8514 - val_loss: 154.5014\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.6722 - val_loss: 155.9007\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.3911 - val_loss: 151.7667\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.1772 - val_loss: 154.5477\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.4078 - val_loss: 151.7624\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 134.8282 - val_loss: 153.0406\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 134.4937 - val_loss: 151.5229\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 133.8456 - val_loss: 154.1492\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.4146 - val_loss: 149.9941\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.0481 - val_loss: 152.8502\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.0935 - val_loss: 149.3021\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 132.0073 - val_loss: 153.3541\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.2027 - val_loss: 148.8713\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.4113 - val_loss: 150.9317\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.2067 - val_loss: 150.9205\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.3218 - val_loss: 148.7539\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.6212 - val_loss: 152.2413\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.0291 - val_loss: 148.6156\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.4543 - val_loss: 149.6406\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.7284 - val_loss: 150.4765\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.7059 - val_loss: 148.7790\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.5283 - val_loss: 148.8324\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.8440 - val_loss: 152.6112\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.6142 - val_loss: 149.2131\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.4545 - val_loss: 150.4949\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.7691 - val_loss: 149.4734\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.6862 - val_loss: 150.6331\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.1331 - val_loss: 149.0003\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.3575 - val_loss: 149.7912\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.1536 - val_loss: 148.0944\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.0104 - val_loss: 147.8668\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.2473 - val_loss: 151.3342\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.2252 - val_loss: 147.4640\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.8706 - val_loss: 148.4958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.9661 - val_loss: 148.0679\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.1501 - val_loss: 149.8729\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.1249 - val_loss: 152.2877\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.3325 - val_loss: 147.2721\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.9654 - val_loss: 148.0876\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.8133 - val_loss: 151.9192\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.8441 - val_loss: 149.1518\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.9543 - val_loss: 147.9528\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.2005 - val_loss: 149.8968\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.1583 - val_loss: 148.6177\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.2746 - val_loss: 148.4544\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.6893 - val_loss: 152.2078\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.4900 - val_loss: 149.0533\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.9318 - val_loss: 149.4119\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.8810 - val_loss: 147.6724\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.6947 - val_loss: 150.6214\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.4492 - val_loss: 149.6054\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.2835 - val_loss: 151.5897\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.5844 - val_loss: 148.1144\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.2660 - val_loss: 152.6057\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.4792 - val_loss: 145.9856\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1557.8254 - val_loss: 1536.5288\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1533.0598 - val_loss: 1503.5179\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1478.5923 - val_loss: 1416.1337\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1326.7332 - val_loss: 1179.2153\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 979.5777 - val_loss: 726.1404\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 486.4832 - val_loss: 307.7788\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 240.2567 - val_loss: 260.4780\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 214.1521 - val_loss: 234.7415\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.8507 - val_loss: 227.1029\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.7084 - val_loss: 222.8590\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.4424 - val_loss: 218.2671\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.9494 - val_loss: 214.8078\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.8493 - val_loss: 210.8561\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.0535 - val_loss: 207.5143\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.4656 - val_loss: 203.9515\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.2771 - val_loss: 201.3490\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.6753 - val_loss: 199.3395\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.0442 - val_loss: 195.9661\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.4600 - val_loss: 193.0942\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.3603 - val_loss: 190.9789\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.4225 - val_loss: 187.9907\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.3965 - val_loss: 187.4218\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.3698 - val_loss: 184.9061\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.6704 - val_loss: 182.6646\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.6181 - val_loss: 182.7019\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.3655 - val_loss: 178.1509\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.2517 - val_loss: 177.8539\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.1035 - val_loss: 176.0295\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.7902 - val_loss: 173.0411\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.6640 - val_loss: 171.3612\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.2646 - val_loss: 170.9468\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.6735 - val_loss: 168.4909\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.8786 - val_loss: 166.8878\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.3956 - val_loss: 165.7692\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.2590 - val_loss: 164.0426\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.9983 - val_loss: 162.6225\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.0609 - val_loss: 161.5891\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.7439 - val_loss: 160.5349\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.3450 - val_loss: 159.3142\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.2309 - val_loss: 158.7750\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.1112 - val_loss: 158.5729\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.5369 - val_loss: 156.1309\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.7319 - val_loss: 155.2581\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.1415 - val_loss: 156.2917\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.3922 - val_loss: 155.0785\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.2701 - val_loss: 154.4103\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.7403 - val_loss: 152.1550\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.9695 - val_loss: 153.7269\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.1922 - val_loss: 152.5986\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.6593 - val_loss: 151.6045\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.7110 - val_loss: 152.2698\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.5462 - val_loss: 151.1427\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.4707 - val_loss: 151.7451\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.6110 - val_loss: 150.8175\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.8386 - val_loss: 150.2133\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.7642 - val_loss: 149.1722\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.2155 - val_loss: 149.1174\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.8828 - val_loss: 149.8781\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.5525 - val_loss: 148.4699\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.6732 - val_loss: 146.7487\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.8410 - val_loss: 149.8677\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.6543 - val_loss: 147.3812\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.7478 - val_loss: 146.2095\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.3796 - val_loss: 147.3260\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.4828 - val_loss: 146.4770\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.2923 - val_loss: 146.2543\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.3885 - val_loss: 145.7440\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.4973 - val_loss: 146.7698\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.7842 - val_loss: 147.2362\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.1678 - val_loss: 145.1970\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.1033 - val_loss: 148.2685\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.1708 - val_loss: 144.6367\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 126.9783 - val_loss: 146.8091\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.0636 - val_loss: 144.0232\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.5620 - val_loss: 146.7208\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.8005 - val_loss: 145.4774\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.6088 - val_loss: 144.9693\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.7885 - val_loss: 144.8855\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.1261 - val_loss: 145.7191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.4539 - val_loss: 144.4063\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.6271 - val_loss: 144.1061\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.5004 - val_loss: 145.5526\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.6169 - val_loss: 146.0916\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.4558 - val_loss: 144.2599\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.6869 - val_loss: 143.3953\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.2005 - val_loss: 145.0235\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.1399 - val_loss: 143.8813\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.8225 - val_loss: 143.3805\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.3347 - val_loss: 144.5350\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.4018 - val_loss: 144.1711\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.9298 - val_loss: 144.8094\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.5178 - val_loss: 146.4167\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.5339 - val_loss: 143.9699\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.7542 - val_loss: 146.1596\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.6124 - val_loss: 144.4852\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.6355 - val_loss: 144.2183\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.0397 - val_loss: 144.6412\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.8535 - val_loss: 144.7266\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.5306 - val_loss: 144.4988\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.9019 - val_loss: 144.7259\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 9ms/step - loss: 1590.4418 - val_loss: 1431.2803\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1548.7899 - val_loss: 1374.2617\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1467.3969 - val_loss: 1265.8588\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1314.1934 - val_loss: 1068.5203\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1041.2874 - val_loss: 747.9933\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 634.7552 - val_loss: 374.8645\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 310.9088 - val_loss: 235.0331\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 233.4020 - val_loss: 200.0959\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 213.2221 - val_loss: 191.8670\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 206.5134 - val_loss: 186.2206\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.5341 - val_loss: 182.1715\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.6481 - val_loss: 178.7365\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.6953 - val_loss: 176.9734\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.9505 - val_loss: 174.1005\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.7302 - val_loss: 171.7735\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.0095 - val_loss: 170.5190\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.1366 - val_loss: 169.7755\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.1232 - val_loss: 167.6743\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.0913 - val_loss: 166.0773\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.6104 - val_loss: 165.1864\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.6208 - val_loss: 164.2203\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.9056 - val_loss: 163.2370\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.0860 - val_loss: 161.8385\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.8152 - val_loss: 161.2463\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.5872 - val_loss: 160.5582\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.3445 - val_loss: 159.6320\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.2353 - val_loss: 158.2880\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.5723 - val_loss: 158.2282\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.8477 - val_loss: 157.4766\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.2094 - val_loss: 156.3402\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.7497 - val_loss: 155.8873\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 164.9077 - val_loss: 155.4026\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.0856 - val_loss: 155.0838\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.2209 - val_loss: 154.5184\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.1461 - val_loss: 154.0367\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.4106 - val_loss: 153.8777\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.9004 - val_loss: 152.0436\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.0156 - val_loss: 151.7024\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.0366 - val_loss: 151.6530\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.4618 - val_loss: 150.9173\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.0095 - val_loss: 150.5765\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.3703 - val_loss: 149.7480\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.5821 - val_loss: 149.2987\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.8655 - val_loss: 148.8057\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.3976 - val_loss: 148.8297\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.8966 - val_loss: 148.2944\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.8607 - val_loss: 148.1886\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.3712 - val_loss: 147.5393\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.4761 - val_loss: 147.4088\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.2600 - val_loss: 146.8208\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.3734 - val_loss: 146.8237\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.6965 - val_loss: 146.3960\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.2232 - val_loss: 146.3003\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.9030 - val_loss: 145.8009\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.6079 - val_loss: 145.8354\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.4153 - val_loss: 145.3824\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.7352 - val_loss: 145.0013\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 149.6597 - val_loss: 144.5062\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.7878 - val_loss: 145.1890\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.8270 - val_loss: 143.5137\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.7463 - val_loss: 144.0023\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.1181 - val_loss: 143.3599\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.2445 - val_loss: 143.1143\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.0405 - val_loss: 143.6761\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.2759 - val_loss: 143.0688\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.6077 - val_loss: 142.1188\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.9617 - val_loss: 142.4939\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.4802 - val_loss: 142.6013\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.1802 - val_loss: 141.4084\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.6741 - val_loss: 142.3056\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.3251 - val_loss: 141.4616\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.2249 - val_loss: 141.5042\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.2610 - val_loss: 140.9667\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.0732 - val_loss: 141.2122\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.6195 - val_loss: 140.7506\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.2536 - val_loss: 140.4800\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.4861 - val_loss: 140.9598\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.1838 - val_loss: 141.1370\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 140.1218 - val_loss: 140.4193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.5976 - val_loss: 140.4631\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.8350 - val_loss: 140.1458\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.1552 - val_loss: 140.1693\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.3956 - val_loss: 140.3091\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.4452 - val_loss: 140.0214\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.5535 - val_loss: 140.2646\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.4224 - val_loss: 139.0480\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.1817 - val_loss: 139.1320\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.4210 - val_loss: 139.6501\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.6311 - val_loss: 137.8315\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 135.2724 - val_loss: 138.8663\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.3157 - val_loss: 139.2200\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.2905 - val_loss: 138.6380\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.1049 - val_loss: 139.0912\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.0724 - val_loss: 138.6039\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.0025 - val_loss: 139.5527\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.6876 - val_loss: 137.9086\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.7318 - val_loss: 138.1042\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.6025 - val_loss: 139.0818\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.7048 - val_loss: 137.5573\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.8814 - val_loss: 137.0259\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 9ms/step - loss: 1543.6329 - val_loss: 1423.6021\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1460.5872 - val_loss: 1299.2739\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1265.0906 - val_loss: 1021.2089\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 887.1586 - val_loss: 579.1823\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 426.7062 - val_loss: 255.9777\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 242.2554 - val_loss: 223.5742\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 219.1944 - val_loss: 202.9181\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.9142 - val_loss: 198.2908\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.1141 - val_loss: 194.1953\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.8177 - val_loss: 191.4823\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.9157 - val_loss: 189.2695\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.1226 - val_loss: 187.3375\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.6003 - val_loss: 186.6361\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.4655 - val_loss: 184.7811\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.9911 - val_loss: 183.3471\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.3336 - val_loss: 182.1568\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.3152 - val_loss: 180.6627\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.7865 - val_loss: 180.3524\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.1960 - val_loss: 178.2955\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.4323 - val_loss: 177.6148\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.9240 - val_loss: 176.0942\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.9386 - val_loss: 176.2802\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.8587 - val_loss: 175.3501\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.1729 - val_loss: 173.3944\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.2753 - val_loss: 172.8661\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.7931 - val_loss: 171.4888\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.4829 - val_loss: 171.7614\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.6827 - val_loss: 169.7489\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.8817 - val_loss: 170.2837\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.5020 - val_loss: 167.7839\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.2004 - val_loss: 167.1400\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.8551 - val_loss: 166.1507\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.6277 - val_loss: 164.8035\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.3668 - val_loss: 164.4142\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.8059 - val_loss: 162.8689\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.7283 - val_loss: 162.2011\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.8557 - val_loss: 161.6041\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.6940 - val_loss: 159.7072\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.5058 - val_loss: 159.6801\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.2902 - val_loss: 158.0601\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.3890 - val_loss: 158.4449\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.6763 - val_loss: 157.1333\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.7568 - val_loss: 155.3521\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.3070 - val_loss: 155.4307\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.5776 - val_loss: 153.6814\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 149.7879 - val_loss: 153.0944\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.7968 - val_loss: 151.7569\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.0970 - val_loss: 151.3819\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 144.4251 - val_loss: 151.1331\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.1450 - val_loss: 150.1944\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.6415 - val_loss: 149.0353\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.3889 - val_loss: 149.2254\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.5291 - val_loss: 148.2442\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 140.1777 - val_loss: 147.0918\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.2391 - val_loss: 147.0742\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.3941 - val_loss: 145.8698\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.9606 - val_loss: 145.9982\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 136.7988 - val_loss: 146.0004\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 135.6122 - val_loss: 144.1268\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 136.0574 - val_loss: 144.2569\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 133.9817 - val_loss: 144.3850\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.5742 - val_loss: 143.5270\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.2756 - val_loss: 143.0771\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 132.6549 - val_loss: 142.7875\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 132.6118 - val_loss: 141.9077\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.9024 - val_loss: 141.4452\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.2557 - val_loss: 140.9829\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 130.0613 - val_loss: 141.1396\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.0505 - val_loss: 140.0632\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 129.8172 - val_loss: 142.2486\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 128.3545 - val_loss: 140.3829\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.8588 - val_loss: 141.8470\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.8801 - val_loss: 139.7354\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.5064 - val_loss: 139.4625\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.3054 - val_loss: 139.0358\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 126.4464 - val_loss: 139.2833\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.3185 - val_loss: 138.8347\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 125.7187 - val_loss: 139.9623\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 125.7824 - val_loss: 139.0612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.3157 - val_loss: 138.2162\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.4404 - val_loss: 138.7817\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.6762 - val_loss: 137.9004\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 124.7082 - val_loss: 137.6537\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.3991 - val_loss: 138.4176\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 125.2611 - val_loss: 137.4336\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 124.4979 - val_loss: 141.1234\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 124.2003 - val_loss: 137.5316\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 124.4624 - val_loss: 137.8282\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 122.7558 - val_loss: 137.6381\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.7154 - val_loss: 139.3441\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.7624 - val_loss: 137.5736\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.3625 - val_loss: 137.6690\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 121.6473 - val_loss: 137.3011\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.0170 - val_loss: 139.9361\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.5422 - val_loss: 138.5118\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.5530 - val_loss: 137.9772\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.4516 - val_loss: 137.5949\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 121.2063 - val_loss: 136.7667\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 121.8224 - val_loss: 138.3702\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.5350 - val_loss: 137.3860\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1568.5355 - val_loss: 1505.8625\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1530.1084 - val_loss: 1452.0640\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1449.6703 - val_loss: 1339.6990\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1288.1858 - val_loss: 1123.7382\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 994.6909 - val_loss: 761.6280\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 600.8105 - val_loss: 395.7241\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 356.3694 - val_loss: 255.4795\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 255.1182 - val_loss: 217.8730\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 226.8684 - val_loss: 208.8002\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.3998 - val_loss: 198.1387\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 206.2346 - val_loss: 194.0861\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.7105 - val_loss: 191.2540\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.5103 - val_loss: 189.1086\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.2428 - val_loss: 182.7268\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 188.7160 - val_loss: 182.2264\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.7791 - val_loss: 178.9560\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.0745 - val_loss: 176.9539\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.5881 - val_loss: 174.9821\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.3827 - val_loss: 171.5119\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.5590 - val_loss: 171.4960\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.3744 - val_loss: 170.2404\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.5347 - val_loss: 169.6526\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.6665 - val_loss: 166.3478\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.2456 - val_loss: 166.0592\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.0551 - val_loss: 164.4061\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.6535 - val_loss: 163.7236\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.6404 - val_loss: 162.4827\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.5192 - val_loss: 163.5562\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.2692 - val_loss: 162.3758\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.0149 - val_loss: 160.7147\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 157.4912 - val_loss: 160.3954\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.8758 - val_loss: 161.7566\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.1282 - val_loss: 159.6746\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.3631 - val_loss: 160.6449\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.9388 - val_loss: 158.5703\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.2526 - val_loss: 160.2504\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.1602 - val_loss: 159.1292\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.7597 - val_loss: 159.0901\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.1195 - val_loss: 157.6279\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.5162 - val_loss: 160.6636\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.5340 - val_loss: 158.7781\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.4414 - val_loss: 158.4866\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.5745 - val_loss: 159.0773\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.5447 - val_loss: 157.1705\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.0248 - val_loss: 157.6237\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.0422 - val_loss: 157.9424\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.5278 - val_loss: 157.3973\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 138.6317 - val_loss: 159.1056\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.8632 - val_loss: 158.6204\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.0678 - val_loss: 162.1014\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.8921 - val_loss: 157.9141\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.7574 - val_loss: 159.7802\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.9336 - val_loss: 161.1620\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.4491 - val_loss: 158.2379\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.1630 - val_loss: 159.0912\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.7301 - val_loss: 159.5859\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.9110 - val_loss: 158.8617\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.2524 - val_loss: 163.0693\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.2875 - val_loss: 159.6703\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.7571 - val_loss: 160.2650\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.6825 - val_loss: 160.5690\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.6887 - val_loss: 159.9521\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 129.4208 - val_loss: 156.9992\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.5475 - val_loss: 160.1437\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.1587 - val_loss: 158.6975\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.9418 - val_loss: 163.5392\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 128.6989 - val_loss: 157.6111\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.7250 - val_loss: 160.0402\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.6164 - val_loss: 162.6130\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.3791 - val_loss: 160.8009\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.3126 - val_loss: 162.6620\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.3483 - val_loss: 158.3597\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.5785 - val_loss: 165.3550\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.5658 - val_loss: 161.3967\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.0392 - val_loss: 162.1517\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 124.3425 - val_loss: 161.5905\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.0134 - val_loss: 164.1152\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.2411 - val_loss: 158.5004\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.6627 - val_loss: 163.5986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.7623 - val_loss: 160.0209\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.6614 - val_loss: 163.7447\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.3991 - val_loss: 164.2988\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.1640 - val_loss: 160.9334\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.9093 - val_loss: 162.0856\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 121.7053 - val_loss: 159.7626\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.5243 - val_loss: 170.0386\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.8613 - val_loss: 159.9271\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.8707 - val_loss: 159.7807\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 120.8000 - val_loss: 163.5388\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.2892 - val_loss: 158.9463\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.5797 - val_loss: 164.2979\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.1789 - val_loss: 163.3663\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.3683 - val_loss: 163.8074\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.4391 - val_loss: 161.4106\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.5345 - val_loss: 160.8951\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 119.6970 - val_loss: 158.8116\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.5223 - val_loss: 162.4046\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.8838 - val_loss: 164.9801\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.6344 - val_loss: 159.2664\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.4798 - val_loss: 161.7074\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1568.6077 - val_loss: 1525.5048\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1550.4377 - val_loss: 1498.8181\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1510.9867 - val_loss: 1437.1077\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1411.7302 - val_loss: 1279.6429\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1166.3240 - val_loss: 913.8066\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 706.7763 - val_loss: 391.8070\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 306.5093 - val_loss: 219.1978\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 234.5876 - val_loss: 202.3769\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 219.5562 - val_loss: 194.7855\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.1357 - val_loss: 190.0657\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 208.1846 - val_loss: 185.9961\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.1647 - val_loss: 181.9283\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.2341 - val_loss: 178.5882\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.8700 - val_loss: 175.8339\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.1420 - val_loss: 173.2348\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 189.6278 - val_loss: 170.9447\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.2168 - val_loss: 168.5783\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.6636 - val_loss: 166.8792\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.9999 - val_loss: 164.6203\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.4881 - val_loss: 162.8043\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.8142 - val_loss: 161.0324\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.3412 - val_loss: 159.4690\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.9738 - val_loss: 158.5128\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.6125 - val_loss: 157.3523\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.9427 - val_loss: 155.3257\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.3045 - val_loss: 153.8442\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.6473 - val_loss: 152.8431\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.2647 - val_loss: 151.8316\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.7405 - val_loss: 150.6434\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.3823 - val_loss: 149.7020\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.3940 - val_loss: 148.9136\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.9433 - val_loss: 147.6176\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.0967 - val_loss: 146.8312\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.0289 - val_loss: 146.1548\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.9191 - val_loss: 145.2464\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.9165 - val_loss: 143.9947\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.0268 - val_loss: 143.7766\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.9089 - val_loss: 142.0557\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.3208 - val_loss: 142.1756\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.9889 - val_loss: 141.3100\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.7955 - val_loss: 139.9672\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.6764 - val_loss: 139.8297\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.5682 - val_loss: 138.9929\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.4781 - val_loss: 138.1531\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.1187 - val_loss: 138.5694\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.5609 - val_loss: 137.1873\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.8527 - val_loss: 136.9802\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.0398 - val_loss: 135.9410\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.0060 - val_loss: 135.4294\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.1915 - val_loss: 136.0094\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.2411 - val_loss: 134.9560\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.4081 - val_loss: 133.8826\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.9508 - val_loss: 135.0368\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.1676 - val_loss: 133.5443\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.3113 - val_loss: 133.6675\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.1843 - val_loss: 133.8528\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.8786 - val_loss: 132.3091\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.1979 - val_loss: 132.8972\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 131.8228 - val_loss: 132.6465\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.9393 - val_loss: 131.8292\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.6647 - val_loss: 131.9325\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.1062 - val_loss: 132.7115\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.4565 - val_loss: 131.1752\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.5108 - val_loss: 131.8853\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.7965 - val_loss: 131.3563\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.8386 - val_loss: 131.5396\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.5783 - val_loss: 131.2646\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.5180 - val_loss: 130.4858\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.6397 - val_loss: 131.7217\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.0397 - val_loss: 130.7462\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.2267 - val_loss: 131.9565\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 126.6367 - val_loss: 130.4655\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 126.0542 - val_loss: 131.2335\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.1659 - val_loss: 132.0056\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.2361 - val_loss: 130.2811\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.5231 - val_loss: 131.3341\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.2834 - val_loss: 130.3998\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.9812 - val_loss: 131.0253\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.7480 - val_loss: 130.0230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.3555 - val_loss: 131.9184\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.3650 - val_loss: 130.3859\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.7878 - val_loss: 130.9491\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.5434 - val_loss: 131.0483\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.2065 - val_loss: 130.6848\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.8293 - val_loss: 131.5803\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.4965 - val_loss: 130.6663\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.0738 - val_loss: 130.5428\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.7131 - val_loss: 130.9403\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.9306 - val_loss: 130.3334\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.9609 - val_loss: 130.2473\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.1646 - val_loss: 134.6636\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.6043 - val_loss: 129.4117\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.8496 - val_loss: 130.2214\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.8697 - val_loss: 129.8166\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.4668 - val_loss: 130.4930\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.5464 - val_loss: 130.4550\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.3693 - val_loss: 130.3726\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.4555 - val_loss: 130.2124\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.1774 - val_loss: 130.0558\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.2078 - val_loss: 130.2673\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1566.8081 - val_loss: 1516.1340\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1546.7583 - val_loss: 1490.7344\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1509.1625 - val_loss: 1437.1412\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1425.9413 - val_loss: 1319.6702\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1250.2231 - val_loss: 1086.5208\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 931.7851 - val_loss: 685.0314\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 487.1345 - val_loss: 307.5968\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 247.5518 - val_loss: 232.8895\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 220.5339 - val_loss: 223.2302\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.5921 - val_loss: 219.9140\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.8291 - val_loss: 214.6077\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.9048 - val_loss: 211.3636\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.4150 - val_loss: 208.7058\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.1128 - val_loss: 205.9108\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.4147 - val_loss: 204.1044\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.1606 - val_loss: 202.2513\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.3605 - val_loss: 200.3919\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.7338 - val_loss: 198.9118\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.4202 - val_loss: 197.6440\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.4273 - val_loss: 196.2181\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.6803 - val_loss: 194.9895\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.4200 - val_loss: 193.8149\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.6853 - val_loss: 192.1031\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.7110 - val_loss: 191.8081\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 168.3187 - val_loss: 191.1736\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.6484 - val_loss: 188.8407\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.4178 - val_loss: 188.8535\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.3697 - val_loss: 188.2096\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.7622 - val_loss: 185.9366\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.8917 - val_loss: 186.5821\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.1455 - val_loss: 184.8665\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.4183 - val_loss: 183.8907\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.4184 - val_loss: 182.8993\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.3779 - val_loss: 181.9710\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.5752 - val_loss: 181.7781\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.2620 - val_loss: 179.1636\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.6241 - val_loss: 178.5998\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.1451 - val_loss: 178.3367\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.3938 - val_loss: 177.3748\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.9155 - val_loss: 177.6985\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.0611 - val_loss: 175.6964\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.3931 - val_loss: 174.3364\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.5199 - val_loss: 173.1965\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.7183 - val_loss: 172.9304\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.1193 - val_loss: 170.9590\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.3790 - val_loss: 170.2036\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.7434 - val_loss: 169.1452\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.2450 - val_loss: 168.3707\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.8099 - val_loss: 167.8240\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.9723 - val_loss: 166.4428\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.2224 - val_loss: 166.3030\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.3218 - val_loss: 165.8246\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.0916 - val_loss: 163.9145\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.8643 - val_loss: 165.0680\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.5201 - val_loss: 163.9200\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.9438 - val_loss: 162.2047\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.2485 - val_loss: 162.4879\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.0522 - val_loss: 161.7274\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.3687 - val_loss: 161.4776\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.4691 - val_loss: 158.9174\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.2220 - val_loss: 159.6746\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.6008 - val_loss: 157.5754\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.0241 - val_loss: 158.2719\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.7442 - val_loss: 157.7383\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.7358 - val_loss: 157.3889\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.5160 - val_loss: 155.1127\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.3131 - val_loss: 156.2263\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.2698 - val_loss: 154.7545\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 130.8603 - val_loss: 153.0773\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.3385 - val_loss: 154.2767\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.5572 - val_loss: 153.1374\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.4799 - val_loss: 152.4198\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.2578 - val_loss: 152.4783\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.5839 - val_loss: 151.0880\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.1016 - val_loss: 151.8456\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.4819 - val_loss: 151.2002\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.7555 - val_loss: 151.6512\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.4580 - val_loss: 149.4850\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.6283 - val_loss: 150.1429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.4891 - val_loss: 151.4943\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 126.6269 - val_loss: 148.9505\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.8294 - val_loss: 149.3920\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.6555 - val_loss: 149.6701\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.2783 - val_loss: 148.1297\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.8338 - val_loss: 148.1510\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.5946 - val_loss: 148.3135\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.7131 - val_loss: 147.6184\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.1098 - val_loss: 148.7096\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.5266 - val_loss: 149.4782\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.4251 - val_loss: 146.9957\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.7545 - val_loss: 146.9616\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.2700 - val_loss: 147.6993\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.3838 - val_loss: 146.3660\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.1114 - val_loss: 146.0552\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.5548 - val_loss: 146.3133\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.7015 - val_loss: 147.1633\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.4994 - val_loss: 146.6692\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.3366 - val_loss: 145.7932\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.4909 - val_loss: 145.4831\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.0097 - val_loss: 147.2532\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1544.4608 - val_loss: 1596.6814\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1526.4839 - val_loss: 1570.3923\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1490.6300 - val_loss: 1521.9607\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1425.7113 - val_loss: 1434.2584\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1299.7578 - val_loss: 1247.8069\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1049.4213 - val_loss: 913.6089\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 680.5511 - val_loss: 510.0446\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 351.2888 - val_loss: 277.3715\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 243.2557 - val_loss: 233.7903\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 215.6928 - val_loss: 221.5359\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 201.6363 - val_loss: 212.5946\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.0126 - val_loss: 207.3105\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.1171 - val_loss: 203.6306\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.4337 - val_loss: 200.6840\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.4433 - val_loss: 198.5933\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.4760 - val_loss: 195.4205\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.6920 - val_loss: 194.7056\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.1870 - val_loss: 191.9604\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.8046 - val_loss: 190.0252\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.7428 - val_loss: 188.2243\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.8890 - val_loss: 186.4777\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.4908 - val_loss: 185.9130\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.4495 - val_loss: 183.7945\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.2955 - val_loss: 181.9973\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.3712 - val_loss: 182.0310\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.6757 - val_loss: 180.6889\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.1452 - val_loss: 178.9145\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.1465 - val_loss: 178.3261\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.7297 - val_loss: 176.8710\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.4509 - val_loss: 176.2121\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.5914 - val_loss: 175.0665\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.4440 - val_loss: 173.6478\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.3237 - val_loss: 174.0865\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.9902 - val_loss: 172.4360\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.3090 - val_loss: 171.4110\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.9008 - val_loss: 170.5182\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.6565 - val_loss: 169.3974\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.2854 - val_loss: 168.7933\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.8366 - val_loss: 167.8727\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.6003 - val_loss: 167.1942\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.8324 - val_loss: 166.3121\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.2454 - val_loss: 165.8994\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.6064 - val_loss: 164.4378\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.5205 - val_loss: 164.5832\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.3878 - val_loss: 164.4894\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.2856 - val_loss: 162.8413\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.0099 - val_loss: 162.5444\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.2642 - val_loss: 161.6740\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.7436 - val_loss: 160.5611\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.4057 - val_loss: 160.5329\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.1673 - val_loss: 159.5025\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.6803 - val_loss: 158.6869\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 139.9223 - val_loss: 157.9826\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.5914 - val_loss: 157.6994\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 138.9821 - val_loss: 156.8857\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.3816 - val_loss: 156.8846\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 137.3688 - val_loss: 155.6454\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.7675 - val_loss: 155.2387\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.3235 - val_loss: 154.2086\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.3894 - val_loss: 153.6523\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.4724 - val_loss: 153.5403\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.4790 - val_loss: 153.7285\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.1325 - val_loss: 152.2959\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 131.6994 - val_loss: 152.4671\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 130.9804 - val_loss: 151.2774\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 131.0365 - val_loss: 151.4728\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 129.9703 - val_loss: 150.5952\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.0204 - val_loss: 150.7933\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.6044 - val_loss: 149.7177\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.8321 - val_loss: 149.9806\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.8168 - val_loss: 148.3623\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.1658 - val_loss: 149.1379\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.4010 - val_loss: 148.8289\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.3934 - val_loss: 148.3180\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.6959 - val_loss: 148.1795\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 125.7491 - val_loss: 147.0701\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 125.7361 - val_loss: 146.9519\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 125.1436 - val_loss: 147.0736\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.8524 - val_loss: 147.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.4153 - val_loss: 147.2844\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 123.8026 - val_loss: 146.3015\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.0294 - val_loss: 146.9929\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.7615 - val_loss: 146.2040\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 122.4859 - val_loss: 145.9110\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.8806 - val_loss: 145.4017\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.1533 - val_loss: 145.8601\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.6101 - val_loss: 145.9473\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.0045 - val_loss: 144.7905\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.1651 - val_loss: 144.8282\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.6460 - val_loss: 144.1634\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.9985 - val_loss: 144.2990\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.4652 - val_loss: 144.9038\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.5832 - val_loss: 144.1518\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.1640 - val_loss: 144.1088\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.1081 - val_loss: 144.0068\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.8458 - val_loss: 143.8651\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.0678 - val_loss: 143.8615\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.2132 - val_loss: 144.2189\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.1911 - val_loss: 143.7421\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.0894 - val_loss: 144.0002\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1557.6165 - val_loss: 1506.7858\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1533.8000 - val_loss: 1476.0902\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1490.2430 - val_loss: 1418.6594\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1407.2054 - val_loss: 1306.5698\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1246.4918 - val_loss: 1090.4562\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 966.3564 - val_loss: 760.4088\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 592.4772 - val_loss: 374.9233\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 296.5280 - val_loss: 223.3925\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 236.5671 - val_loss: 206.3110\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 222.2092 - val_loss: 198.2087\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.9171 - val_loss: 191.6638\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.4325 - val_loss: 187.7371\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.0897 - val_loss: 184.5691\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.7119 - val_loss: 182.4563\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.7083 - val_loss: 180.8259\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.0682 - val_loss: 179.1889\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.1897 - val_loss: 176.9750\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 190.6209 - val_loss: 176.2122\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.8515 - val_loss: 174.9571\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.4914 - val_loss: 173.3664\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.0085 - val_loss: 172.0495\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.1891 - val_loss: 172.2171\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.3429 - val_loss: 170.0874\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.1095 - val_loss: 168.8491\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.2573 - val_loss: 168.2431\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.0780 - val_loss: 167.4386\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.9023 - val_loss: 166.6055\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.2349 - val_loss: 165.7839\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.0234 - val_loss: 165.5728\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.0730 - val_loss: 164.4853\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.8775 - val_loss: 163.3933\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.7962 - val_loss: 163.0665\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.3643 - val_loss: 162.9044\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.3748 - val_loss: 161.8703\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.7362 - val_loss: 161.5051\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.7832 - val_loss: 160.9247\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.7111 - val_loss: 160.3784\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.9125 - val_loss: 160.2707\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.1423 - val_loss: 159.7264\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.5291 - val_loss: 158.9354\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.5078 - val_loss: 158.4947\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.9154 - val_loss: 158.0873\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.5449 - val_loss: 157.9290\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.4019 - val_loss: 157.1358\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.7143 - val_loss: 156.7863\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.0568 - val_loss: 156.3803\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.2586 - val_loss: 156.1027\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.5228 - val_loss: 155.6498\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.9810 - val_loss: 155.2093\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.4081 - val_loss: 155.0944\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.6964 - val_loss: 154.6469\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.5748 - val_loss: 154.5742\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.7336 - val_loss: 154.7139\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.1825 - val_loss: 153.9882\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.4503 - val_loss: 153.4845\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.9334 - val_loss: 153.0616\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.4850 - val_loss: 152.6181\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.5684 - val_loss: 152.8540\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.5254 - val_loss: 152.1403\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.5168 - val_loss: 152.2910\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.0756 - val_loss: 151.2881\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.6035 - val_loss: 151.3998\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.6920 - val_loss: 151.2332\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.7747 - val_loss: 150.7892\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.3140 - val_loss: 150.2666\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.2834 - val_loss: 150.3681\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.8992 - val_loss: 149.7802\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.7147 - val_loss: 149.6088\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.6416 - val_loss: 149.5190\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.1922 - val_loss: 148.8785\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.2334 - val_loss: 149.6070\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.6024 - val_loss: 148.4864\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.9307 - val_loss: 148.1904\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.5688 - val_loss: 149.9083\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.9427 - val_loss: 147.4361\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.4998 - val_loss: 147.8587\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.5652 - val_loss: 147.5851\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.1436 - val_loss: 147.0115\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.0278 - val_loss: 147.0573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.6526 - val_loss: 148.0529\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.2005 - val_loss: 146.8879\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.4345 - val_loss: 146.4331\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.3440 - val_loss: 149.7245\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.7176 - val_loss: 146.3768\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.7202 - val_loss: 146.8950\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.9614 - val_loss: 147.4260\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.6782 - val_loss: 147.5021\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.2865 - val_loss: 146.7641\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.0151 - val_loss: 148.3255\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.8235 - val_loss: 147.2696\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.5664 - val_loss: 146.0301\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.9707 - val_loss: 148.1000\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.0034 - val_loss: 145.8844\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.1319 - val_loss: 145.8322\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.5185 - val_loss: 146.0080\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.3294 - val_loss: 145.3513\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.9098 - val_loss: 149.6172\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.6915 - val_loss: 145.8713\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.7098 - val_loss: 148.4874\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.7014 - val_loss: 145.2773\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1590.8188 - val_loss: 1433.5634\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1552.0759 - val_loss: 1383.9622\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1480.1654 - val_loss: 1278.6022\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1320.9747 - val_loss: 1051.3979\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 995.7803 - val_loss: 659.7383\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 550.7499 - val_loss: 297.4930\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 277.6671 - val_loss: 240.9287\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 236.8412 - val_loss: 225.5511\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 217.8705 - val_loss: 218.2637\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.4893 - val_loss: 214.7465\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.2445 - val_loss: 213.4171\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.3199 - val_loss: 210.4177\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.9546 - val_loss: 208.4763\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.3812 - val_loss: 206.6291\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.7304 - val_loss: 204.0855\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.0987 - val_loss: 202.3175\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.8961 - val_loss: 201.0000\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.7354 - val_loss: 201.1030\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.8246 - val_loss: 198.7702\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.0125 - val_loss: 198.1158\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.7502 - val_loss: 195.6545\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.9285 - val_loss: 196.0219\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.3266 - val_loss: 194.2752\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.5018 - val_loss: 194.4199\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.3782 - val_loss: 192.0446\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.7636 - val_loss: 191.2709\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.1378 - val_loss: 192.8492\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.0024 - val_loss: 189.6436\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.0370 - val_loss: 190.4077\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.2838 - val_loss: 189.0370\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.2486 - val_loss: 188.2338\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.5313 - val_loss: 187.8601\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.4951 - val_loss: 186.8442\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.0707 - val_loss: 186.7577\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.4548 - val_loss: 185.0213\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.7415 - val_loss: 185.7089\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.7277 - val_loss: 184.3991\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.6139 - val_loss: 184.1324\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.3314 - val_loss: 183.2921\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.8375 - val_loss: 183.3492\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.7689 - val_loss: 182.3610\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.2908 - val_loss: 181.2496\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.6282 - val_loss: 181.5067\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.6304 - val_loss: 179.9852\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.5339 - val_loss: 180.3755\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.9712 - val_loss: 179.0156\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.3595 - val_loss: 179.6209\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.4990 - val_loss: 177.6225\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.3236 - val_loss: 176.9553\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.3881 - val_loss: 176.1613\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.5035 - val_loss: 175.1885\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.2942 - val_loss: 174.5379\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.2520 - val_loss: 174.3957\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.7691 - val_loss: 173.9057\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.1228 - val_loss: 173.0071\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.3987 - val_loss: 171.8673\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.6308 - val_loss: 171.4084\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.8819 - val_loss: 170.3018\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.0188 - val_loss: 169.7733\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.0428 - val_loss: 168.8499\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.3461 - val_loss: 168.7414\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.3636 - val_loss: 168.5513\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.4051 - val_loss: 167.0903\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.8144 - val_loss: 166.4780\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.3582 - val_loss: 166.1928\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.1594 - val_loss: 163.8633\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.3818 - val_loss: 164.5274\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.8012 - val_loss: 163.7646\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.6223 - val_loss: 163.0384\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.0577 - val_loss: 162.8984\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.3285 - val_loss: 161.3956\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.1475 - val_loss: 160.8284\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.6729 - val_loss: 160.4155\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.1024 - val_loss: 160.0977\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.6359 - val_loss: 159.0654\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.9635 - val_loss: 159.0598\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.8730 - val_loss: 158.7479\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.1992 - val_loss: 158.3692\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.8792 - val_loss: 156.8632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.6843 - val_loss: 158.1546\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.6355 - val_loss: 155.8799\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.1769 - val_loss: 155.7211\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.8719 - val_loss: 154.4081\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.9677 - val_loss: 154.2494\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.4005 - val_loss: 155.0174\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.9928 - val_loss: 153.2173\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.4291 - val_loss: 154.7330\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.3625 - val_loss: 155.4749\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.8496 - val_loss: 152.0057\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.7946 - val_loss: 154.1888\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.6535 - val_loss: 151.3970\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.4339 - val_loss: 150.8642\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.6264 - val_loss: 151.4705\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.6345 - val_loss: 150.5072\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.0622 - val_loss: 150.8694\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.6857 - val_loss: 149.6546\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.8362 - val_loss: 150.2519\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.5042 - val_loss: 150.3994\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.0482 - val_loss: 150.2479\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.2170 - val_loss: 148.7581\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 10ms/step - loss: 1517.9816 - val_loss: 1543.1877\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1461.1511 - val_loss: 1462.9985\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1346.8223 - val_loss: 1301.1045\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1128.3497 - val_loss: 1009.0108\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 787.1808 - val_loss: 633.3939\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 458.1016 - val_loss: 367.3357\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 301.5960 - val_loss: 288.8016\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 250.2835 - val_loss: 254.8334\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 225.1134 - val_loss: 238.3130\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.0978 - val_loss: 230.2161\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.2684 - val_loss: 224.1630\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.0273 - val_loss: 223.1532\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.8529 - val_loss: 219.2328\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.7525 - val_loss: 216.5328\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.5355 - val_loss: 214.0592\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.7920 - val_loss: 212.7571\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.8734 - val_loss: 210.6248\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.5248 - val_loss: 208.3656\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.0962 - val_loss: 207.8474\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.7886 - val_loss: 205.6082\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.8679 - val_loss: 204.7503\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.6801 - val_loss: 201.4332\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.7061 - val_loss: 200.1855\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.1792 - val_loss: 200.6886\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.2970 - val_loss: 197.7398\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.6430 - val_loss: 196.1830\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.0015 - val_loss: 197.2561\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.0429 - val_loss: 193.3541\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 154.0879 - val_loss: 192.8822\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.6989 - val_loss: 193.0714\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.3977 - val_loss: 190.1934\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.2008 - val_loss: 188.9302\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.7670 - val_loss: 190.0188\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.5804 - val_loss: 186.4751\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.6792 - val_loss: 186.5783\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.4077 - val_loss: 183.8302\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.3589 - val_loss: 184.0617\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.5733 - val_loss: 182.3659\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.7217 - val_loss: 181.2822\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.0700 - val_loss: 181.4669\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.1390 - val_loss: 179.1689\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.9522 - val_loss: 179.4258\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.6972 - val_loss: 178.7878\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.7968 - val_loss: 176.8180\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 138.0600 - val_loss: 174.9880\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.3292 - val_loss: 176.0757\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 137.1139 - val_loss: 173.6438\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.9895 - val_loss: 173.5674\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.3395 - val_loss: 173.5821\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.7144 - val_loss: 169.9199\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.3547 - val_loss: 171.5045\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.1030 - val_loss: 170.2519\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.5107 - val_loss: 167.9142\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.2539 - val_loss: 168.4357\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.6080 - val_loss: 167.7980\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 130.7049 - val_loss: 167.1472\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.7298 - val_loss: 165.4498\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.1851 - val_loss: 165.5553\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.9916 - val_loss: 164.6106\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.1725 - val_loss: 165.4363\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.6242 - val_loss: 162.6384\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.3743 - val_loss: 167.0238\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.5015 - val_loss: 163.4385\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.2287 - val_loss: 160.9014\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.1434 - val_loss: 163.5025\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.8763 - val_loss: 161.0900\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.4227 - val_loss: 161.0918\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.9544 - val_loss: 159.2182\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.4478 - val_loss: 162.2973\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.6646 - val_loss: 158.4653\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.2355 - val_loss: 157.1373\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.3684 - val_loss: 157.8296\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.5006 - val_loss: 159.7357\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.0539 - val_loss: 156.2665\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.2282 - val_loss: 156.1305\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.9817 - val_loss: 155.4720\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.0684 - val_loss: 156.7136\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.2516 - val_loss: 157.9120\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.2154 - val_loss: 157.1427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.5661 - val_loss: 154.7675\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.9387 - val_loss: 156.5486\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.8138 - val_loss: 156.4157\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.1234 - val_loss: 155.4521\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.7787 - val_loss: 155.5218\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.3129 - val_loss: 155.8544\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.7727 - val_loss: 156.4320\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.0611 - val_loss: 155.3085\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.6904 - val_loss: 153.7854\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 119.9317 - val_loss: 153.3422\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.9820 - val_loss: 153.7617\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.6898 - val_loss: 153.2993\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 119.4985 - val_loss: 154.0289\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 118.1882 - val_loss: 155.8715\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 118.3429 - val_loss: 152.3476\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 118.0681 - val_loss: 153.4008\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 118.2071 - val_loss: 152.9846\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.5825 - val_loss: 152.5665\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 117.9952 - val_loss: 152.0596\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 119.3481 - val_loss: 153.6344\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.4216 - val_loss: 152.8652\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 10ms/step - loss: 1531.5061 - val_loss: 1530.0835\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1478.0900 - val_loss: 1456.6696\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1379.4750 - val_loss: 1318.9675\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1192.3866 - val_loss: 1059.5717\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 869.6431 - val_loss: 652.5761\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 468.2675 - val_loss: 295.4665\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 261.1634 - val_loss: 212.3705\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 224.1136 - val_loss: 202.0460\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 210.9607 - val_loss: 196.0221\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.3761 - val_loss: 192.1784\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.8296 - val_loss: 189.3577\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.7136 - val_loss: 187.5374\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.7646 - val_loss: 185.2676\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.2800 - val_loss: 183.6451\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.2728 - val_loss: 182.1354\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.7088 - val_loss: 180.7557\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.5444 - val_loss: 179.0872\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.3028 - val_loss: 177.8138\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.9053 - val_loss: 176.9860\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.1438 - val_loss: 175.4593\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.6035 - val_loss: 174.9474\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.0988 - val_loss: 173.2160\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.9596 - val_loss: 172.6588\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.7382 - val_loss: 171.2144\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.7031 - val_loss: 170.1398\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.8866 - val_loss: 169.1272\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.6000 - val_loss: 167.9585\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.6006 - val_loss: 167.0515\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.1913 - val_loss: 165.9392\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.4471 - val_loss: 165.3469\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.8302 - val_loss: 164.3596\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.0156 - val_loss: 162.7519\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.5613 - val_loss: 162.0674\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.0200 - val_loss: 161.0373\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.1029 - val_loss: 160.2554\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.4241 - val_loss: 159.4798\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.2547 - val_loss: 158.3058\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.1071 - val_loss: 157.7627\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.8383 - val_loss: 156.7603\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.9734 - val_loss: 156.6674\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.8793 - val_loss: 155.8236\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.3492 - val_loss: 154.3387\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.4991 - val_loss: 154.9659\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 138.5387 - val_loss: 153.7899\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.4321 - val_loss: 152.2031\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.9864 - val_loss: 152.4308\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.3866 - val_loss: 151.7413\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.7238 - val_loss: 150.9185\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.0432 - val_loss: 150.5776\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.1470 - val_loss: 150.9621\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.1135 - val_loss: 150.2807\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.8878 - val_loss: 149.8208\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.2436 - val_loss: 149.5369\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.7781 - val_loss: 149.1265\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.6120 - val_loss: 148.8310\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.8557 - val_loss: 148.1793\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.9221 - val_loss: 147.4216\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.0446 - val_loss: 147.5067\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.1223 - val_loss: 147.6470\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.4391 - val_loss: 146.7883\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.2592 - val_loss: 147.2644\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.5006 - val_loss: 147.6602\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.3156 - val_loss: 146.2372\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.2457 - val_loss: 146.2109\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.6686 - val_loss: 146.1809\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.7022 - val_loss: 146.1669\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.3000 - val_loss: 145.4535\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.3474 - val_loss: 145.4223\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.5146 - val_loss: 145.4083\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.6334 - val_loss: 145.1308\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.3254 - val_loss: 144.6531\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.5712 - val_loss: 144.7777\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.2037 - val_loss: 143.6854\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.2550 - val_loss: 143.8030\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 123.1666 - val_loss: 143.4277\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.8207 - val_loss: 143.4491\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.0961 - val_loss: 143.3558\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.9550 - val_loss: 143.6622\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.2674 - val_loss: 142.4250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.6806 - val_loss: 143.7639\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.4329 - val_loss: 142.9546\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.9418 - val_loss: 141.9192\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.4282 - val_loss: 142.6580\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.4178 - val_loss: 142.2403\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.3503 - val_loss: 142.5229\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.9279 - val_loss: 142.1277\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.3171 - val_loss: 142.2137\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.8616 - val_loss: 141.4378\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.7488 - val_loss: 141.5393\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.1587 - val_loss: 141.7013\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 119.9202 - val_loss: 141.4097\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.7908 - val_loss: 141.7202\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.6585 - val_loss: 141.7034\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.2233 - val_loss: 141.1191\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.6385 - val_loss: 141.2102\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.6732 - val_loss: 141.0723\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.8465 - val_loss: 141.0416\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.2927 - val_loss: 140.3986\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.4529 - val_loss: 140.8002\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.9021 - val_loss: 140.3885\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 9ms/step - loss: 1555.4359 - val_loss: 1538.5427\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1522.2277 - val_loss: 1485.7029\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1437.9078 - val_loss: 1355.6868\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1252.0959 - val_loss: 1098.5363\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 918.1506 - val_loss: 694.6400\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 491.1922 - val_loss: 308.5957\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 251.3909 - val_loss: 216.4295\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 229.0507 - val_loss: 209.5629\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 217.8822 - val_loss: 206.3456\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 211.3181 - val_loss: 202.9679\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.6734 - val_loss: 199.6098\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 200.0192 - val_loss: 198.1208\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.2981 - val_loss: 195.8647\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.7038 - val_loss: 194.7595\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.6195 - val_loss: 193.3505\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.6061 - val_loss: 191.8741\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.2259 - val_loss: 190.0148\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.5388 - val_loss: 188.7305\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.3140 - val_loss: 187.3612\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.5179 - val_loss: 186.8180\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.8021 - val_loss: 185.0048\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.7413 - val_loss: 183.7569\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.5198 - val_loss: 183.9997\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.9719 - val_loss: 182.2224\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.1626 - val_loss: 181.3039\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.0083 - val_loss: 179.9674\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.4060 - val_loss: 178.8977\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.3307 - val_loss: 177.9680\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.5611 - val_loss: 177.8289\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.9647 - val_loss: 176.9791\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.4090 - val_loss: 175.1980\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.9182 - val_loss: 174.9644\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.7831 - val_loss: 173.9543\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.6096 - val_loss: 173.3064\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.8653 - val_loss: 172.1733\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.1163 - val_loss: 172.2245\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.7806 - val_loss: 171.0650\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.1940 - val_loss: 171.3538\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.8049 - val_loss: 169.9807\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.3712 - val_loss: 170.0191\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.8367 - val_loss: 169.1336\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.9749 - val_loss: 168.9865\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.4874 - val_loss: 167.5042\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.3947 - val_loss: 166.8650\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.6419 - val_loss: 166.8707\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.9192 - val_loss: 166.0177\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.8748 - val_loss: 166.3691\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.9540 - val_loss: 164.7666\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 140.7281 - val_loss: 164.3970\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.1888 - val_loss: 164.4512\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.6186 - val_loss: 163.5247\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.7940 - val_loss: 161.8660\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.1039 - val_loss: 163.4164\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.3618 - val_loss: 161.6515\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.0515 - val_loss: 162.4640\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.3139 - val_loss: 161.8399\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.8923 - val_loss: 160.9902\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.8433 - val_loss: 160.4339\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.8850 - val_loss: 159.5280\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.0542 - val_loss: 159.9061\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.3398 - val_loss: 159.4208\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.1713 - val_loss: 158.8666\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.9686 - val_loss: 158.4085\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.1502 - val_loss: 158.6023\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.7741 - val_loss: 157.7425\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.8832 - val_loss: 157.3089\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.2174 - val_loss: 156.5266\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.8555 - val_loss: 157.9489\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 128.6145 - val_loss: 155.9805\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.0241 - val_loss: 155.4311\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.6230 - val_loss: 155.0629\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.0665 - val_loss: 155.0286\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.2471 - val_loss: 154.7298\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.9993 - val_loss: 155.4070\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.4025 - val_loss: 155.0723\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.1310 - val_loss: 154.3406\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.2996 - val_loss: 152.8697\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.3761 - val_loss: 154.9673\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 125.1335 - val_loss: 154.1074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.5570 - val_loss: 154.1035\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.3796 - val_loss: 153.2008\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.0424 - val_loss: 152.9979\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.8189 - val_loss: 153.0563\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.3167 - val_loss: 152.0305\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.6716 - val_loss: 151.6016\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.8616 - val_loss: 151.3659\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.4342 - val_loss: 152.8375\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.2320 - val_loss: 152.2968\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.8838 - val_loss: 150.8369\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.8089 - val_loss: 151.1793\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.3771 - val_loss: 150.3027\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.9574 - val_loss: 153.1006\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.9717 - val_loss: 148.6594\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.4437 - val_loss: 151.1096\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.5489 - val_loss: 149.4180\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 120.2562 - val_loss: 150.7452\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.7696 - val_loss: 149.5636\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.0594 - val_loss: 149.6582\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.5211 - val_loss: 149.3635\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.4477 - val_loss: 150.7773\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1503.1167 - val_loss: 1593.1558\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1456.7937 - val_loss: 1529.2610\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1364.6542 - val_loss: 1394.7141\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1175.8469 - val_loss: 1127.8906\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 839.6801 - val_loss: 700.0554\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 428.1769 - val_loss: 326.3511\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 251.4919 - val_loss: 243.5856\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 234.7131 - val_loss: 238.4916\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 221.4979 - val_loss: 225.5598\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 215.7389 - val_loss: 220.3829\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 210.4760 - val_loss: 215.2710\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.7645 - val_loss: 211.6044\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.0619 - val_loss: 206.6596\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.4452 - val_loss: 204.1685\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.4992 - val_loss: 201.6178\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.4019 - val_loss: 203.3724\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.0428 - val_loss: 197.1760\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.4884 - val_loss: 196.5495\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.0725 - val_loss: 191.8101\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.3889 - val_loss: 190.5109\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.0415 - val_loss: 188.2598\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.6647 - val_loss: 187.4113\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.5253 - val_loss: 186.2209\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.4519 - val_loss: 185.3928\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.1911 - val_loss: 183.4942\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.4924 - val_loss: 180.7466\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 177.0387 - val_loss: 181.5880\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.0071 - val_loss: 177.3597\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.8115 - val_loss: 178.8089\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.1023 - val_loss: 176.6986\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.4078 - val_loss: 176.8228\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.6838 - val_loss: 174.9793\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.8579 - val_loss: 172.5084\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.7982 - val_loss: 172.5796\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.0081 - val_loss: 170.9749\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.3897 - val_loss: 170.3583\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 166.6441 - val_loss: 169.3831\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.9808 - val_loss: 170.5385\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.7465 - val_loss: 169.8863\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.3089 - val_loss: 167.7457\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.9781 - val_loss: 164.3009\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.8292 - val_loss: 167.5531\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.9409 - val_loss: 163.2281\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.0775 - val_loss: 164.7180\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.2981 - val_loss: 162.8598\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.5697 - val_loss: 163.6397\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.8461 - val_loss: 165.1971\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.4109 - val_loss: 158.6288\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.0024 - val_loss: 161.6053\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.8365 - val_loss: 157.0099\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.5529 - val_loss: 160.9333\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.8766 - val_loss: 160.8383\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4439 - val_loss: 160.2313\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.1813 - val_loss: 158.5333\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.3392 - val_loss: 158.0198\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.9962 - val_loss: 155.3996\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 155.7959 - val_loss: 155.8380\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.7433 - val_loss: 157.2852\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.7923 - val_loss: 154.5367\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.7804 - val_loss: 156.3045\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.2382 - val_loss: 155.6104\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.6001 - val_loss: 154.7328\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.4259 - val_loss: 152.7851\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.7476 - val_loss: 155.6607\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.7538 - val_loss: 155.2992\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.7100 - val_loss: 152.8935\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.4213 - val_loss: 152.8096\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0665 - val_loss: 152.2070\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.9075 - val_loss: 154.5587\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.4153 - val_loss: 150.8141\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.8658 - val_loss: 151.4061\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.8577 - val_loss: 149.8146\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.7368 - val_loss: 151.1313\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.8057 - val_loss: 151.3687\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.5995 - val_loss: 148.0995\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.5120 - val_loss: 148.9596\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.6733 - val_loss: 150.0893\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.6790 - val_loss: 151.3490\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.9725 - val_loss: 147.0866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.3107 - val_loss: 148.0753\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.7312 - val_loss: 148.2922\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.0609 - val_loss: 149.0510\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.1642 - val_loss: 147.9089\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.6477 - val_loss: 150.0984\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.8824 - val_loss: 145.9949\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.2695 - val_loss: 149.1199\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.7411 - val_loss: 146.2085\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.6403 - val_loss: 144.9561\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 142.0473 - val_loss: 150.1225\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.7406 - val_loss: 145.8756\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.7411 - val_loss: 147.1747\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.4609 - val_loss: 143.2796\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.5411 - val_loss: 143.8486\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.1603 - val_loss: 144.6339\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.7840 - val_loss: 144.5847\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.9034 - val_loss: 144.6667\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.9874 - val_loss: 145.2869\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 139.8245 - val_loss: 145.5286\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.1780 - val_loss: 144.6512\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.0555 - val_loss: 144.2759\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1579.6670 - val_loss: 1489.5386\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1558.2262 - val_loss: 1456.8896\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1502.5402 - val_loss: 1370.6749\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1366.6865 - val_loss: 1175.3430\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1083.8500 - val_loss: 817.9472\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 642.6234 - val_loss: 391.7352\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 288.1752 - val_loss: 245.6788\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 217.0944 - val_loss: 218.2483\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 200.5392 - val_loss: 200.2811\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 196.1532 - val_loss: 195.1465\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.5212 - val_loss: 193.0523\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.1284 - val_loss: 189.8566\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 184.0418 - val_loss: 187.5020\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 181.6616 - val_loss: 185.1174\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 179.8403 - val_loss: 183.3806\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.4200 - val_loss: 180.8917\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 176.5325 - val_loss: 180.4384\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 175.1824 - val_loss: 179.2163\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.1880 - val_loss: 177.7065\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.7703 - val_loss: 176.3013\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.9750 - val_loss: 175.3029\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.7317 - val_loss: 173.9381\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 169.3361 - val_loss: 173.4861\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.7083 - val_loss: 172.5930\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 168.3082 - val_loss: 170.5967\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.4596 - val_loss: 171.3293\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.7169 - val_loss: 168.6166\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.4778 - val_loss: 169.8058\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 164.3939 - val_loss: 168.1691\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.8700 - val_loss: 166.7787\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.1873 - val_loss: 165.1412\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.9225 - val_loss: 164.1084\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 160.0023 - val_loss: 162.4498\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.5249 - val_loss: 161.5748\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.2933 - val_loss: 160.0460\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 156.7032 - val_loss: 159.0704\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 155.0468 - val_loss: 157.4844\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.6383 - val_loss: 157.4635\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.3581 - val_loss: 155.6208\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.6675 - val_loss: 154.4568\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.3293 - val_loss: 154.7037\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.9494 - val_loss: 154.0810\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.3703 - val_loss: 153.1883\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.8181 - val_loss: 150.1075\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.4579 - val_loss: 150.6918\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.1788 - val_loss: 149.1701\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.3432 - val_loss: 147.9264\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.8109 - val_loss: 148.3576\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 144.6194 - val_loss: 146.8905\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.6353 - val_loss: 145.2354\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.2579 - val_loss: 146.8460\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.1972 - val_loss: 143.7894\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.0701 - val_loss: 143.6690\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.3859 - val_loss: 143.8319\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.9216 - val_loss: 142.8212\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.2034 - val_loss: 142.5209\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.4426 - val_loss: 141.1589\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.2033 - val_loss: 142.6384\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.5439 - val_loss: 140.1913\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.0789 - val_loss: 139.3230\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.3997 - val_loss: 139.5414\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.8322 - val_loss: 138.4308\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.6131 - val_loss: 138.1548\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.9272 - val_loss: 138.1949\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.7073 - val_loss: 138.5727\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.4699 - val_loss: 136.5433\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.8745 - val_loss: 137.6648\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.4115 - val_loss: 136.5836\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.9418 - val_loss: 137.2273\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.8552 - val_loss: 136.3130\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.5239 - val_loss: 135.5217\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.4804 - val_loss: 137.4598\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.6997 - val_loss: 134.5581\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.8039 - val_loss: 134.1816\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.5587 - val_loss: 134.3230\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.0464 - val_loss: 134.8554\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.4696 - val_loss: 133.4711\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.0452 - val_loss: 134.4529\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.8642 - val_loss: 134.6032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.8369 - val_loss: 133.4847\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.5743 - val_loss: 134.0797\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.7447 - val_loss: 133.5260\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.3908 - val_loss: 133.5669\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.1452 - val_loss: 134.2282\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.7253 - val_loss: 132.7643\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.4724 - val_loss: 132.8917\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.5949 - val_loss: 133.0575\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.3586 - val_loss: 133.8821\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.7514 - val_loss: 132.3232\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.0894 - val_loss: 132.3806\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.1824 - val_loss: 133.1271\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.1212 - val_loss: 132.6738\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.2223 - val_loss: 132.0521\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.2507 - val_loss: 132.1373\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.4355 - val_loss: 133.5495\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.5048 - val_loss: 131.9562\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.4895 - val_loss: 133.4744\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.8305 - val_loss: 130.8501\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.8506 - val_loss: 132.7151\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.2626 - val_loss: 131.3549\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1478.2727 - val_loss: 1612.9146\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1411.4653 - val_loss: 1509.9117\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1271.5679 - val_loss: 1299.3617\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1004.2942 - val_loss: 935.8205\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 616.8337 - val_loss: 501.2128\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 292.3308 - val_loss: 290.6387\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 225.6777 - val_loss: 263.1463\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 216.5860 - val_loss: 248.9230\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.0878 - val_loss: 242.5280\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.4958 - val_loss: 235.5987\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.2765 - val_loss: 230.3551\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.6644 - val_loss: 225.5070\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.4952 - val_loss: 222.5150\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.5368 - val_loss: 219.7825\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.4620 - val_loss: 216.1386\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.2476 - val_loss: 215.1550\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.5716 - val_loss: 212.1504\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.5473 - val_loss: 209.1905\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.9831 - val_loss: 208.2834\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.0199 - val_loss: 205.4546\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.5095 - val_loss: 203.4453\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.5689 - val_loss: 201.6903\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.8868 - val_loss: 199.9881\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.0886 - val_loss: 198.2111\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.7501 - val_loss: 198.2273\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.3144 - val_loss: 195.0751\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.8814 - val_loss: 194.3412\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.2941 - val_loss: 193.7403\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.9722 - val_loss: 191.7036\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.2331 - val_loss: 190.5683\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.3738 - val_loss: 189.5658\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.3318 - val_loss: 187.9371\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.6562 - val_loss: 186.0745\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.0478 - val_loss: 185.8741\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0053 - val_loss: 185.0241\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.5319 - val_loss: 185.1099\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.1891 - val_loss: 182.9450\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.4787 - val_loss: 181.2764\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.6469 - val_loss: 180.7666\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.1527 - val_loss: 178.3966\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.3616 - val_loss: 180.0418\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.1900 - val_loss: 178.0045\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.2244 - val_loss: 176.8181\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.2562 - val_loss: 176.3578\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.2965 - val_loss: 173.7488\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.2561 - val_loss: 174.4149\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.2479 - val_loss: 172.4657\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.7078 - val_loss: 173.2505\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.2720 - val_loss: 170.0265\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.6081 - val_loss: 171.1391\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.1238 - val_loss: 169.4114\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.0590 - val_loss: 169.4893\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.1971 - val_loss: 168.3896\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.0181 - val_loss: 167.6216\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.8617 - val_loss: 167.6123\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.7780 - val_loss: 166.1044\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.6059 - val_loss: 165.9167\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.8481 - val_loss: 164.3737\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.0992 - val_loss: 164.2237\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.7004 - val_loss: 164.1601\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.2568 - val_loss: 163.7192\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.1552 - val_loss: 163.6285\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.6746 - val_loss: 163.4789\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.3270 - val_loss: 161.7465\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.4767 - val_loss: 162.3864\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.5445 - val_loss: 161.3704\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.6897 - val_loss: 164.0489\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.5719 - val_loss: 160.2758\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.5289 - val_loss: 161.4466\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.6516 - val_loss: 162.5521\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.9331 - val_loss: 160.1191\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.9497 - val_loss: 161.7310\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.4873 - val_loss: 159.8708\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.4560 - val_loss: 159.9864\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.5078 - val_loss: 160.7066\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.5071 - val_loss: 159.0146\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.5500 - val_loss: 160.8199\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.2761 - val_loss: 160.4010\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.0975 - val_loss: 159.3816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.7675 - val_loss: 160.7821\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.2439 - val_loss: 158.7528\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 116.7732 - val_loss: 158.8051\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.2700 - val_loss: 161.2946\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.2798 - val_loss: 159.4768\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.5816 - val_loss: 158.7886\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.5604 - val_loss: 161.0341\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.8780 - val_loss: 159.2272\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.4724 - val_loss: 157.3734\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.9171 - val_loss: 161.9114\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.4868 - val_loss: 159.9648\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 116.6764 - val_loss: 159.0924\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.3024 - val_loss: 159.5706\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.0366 - val_loss: 158.7888\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 114.8284 - val_loss: 158.8096\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.5920 - val_loss: 160.1199\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 114.4258 - val_loss: 161.7876\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 113.9787 - val_loss: 160.7913\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 113.8555 - val_loss: 160.9469\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.1566 - val_loss: 160.7506\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 114.3955 - val_loss: 162.1248\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1594.5697 - val_loss: 1488.1858\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1576.6737 - val_loss: 1466.3334\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1544.9448 - val_loss: 1419.9381\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1478.7875 - val_loss: 1328.0023\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1351.5585 - val_loss: 1158.6718\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1123.1615 - val_loss: 868.8425\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 776.8835 - val_loss: 486.2887\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 398.9672 - val_loss: 222.5272\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 240.4659 - val_loss: 189.2617\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 219.5484 - val_loss: 177.1655\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 209.7844 - val_loss: 174.3367\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.0507 - val_loss: 171.9342\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.8712 - val_loss: 170.8091\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.0805 - val_loss: 167.6320\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.3451 - val_loss: 166.1215\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.3062 - val_loss: 164.7828\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.4647 - val_loss: 162.7630\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.8023 - val_loss: 161.2639\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.7105 - val_loss: 160.5318\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.2099 - val_loss: 159.1529\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.5024 - val_loss: 157.7362\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.1189 - val_loss: 156.3521\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 176.5303 - val_loss: 155.5836\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.2541 - val_loss: 153.9903\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.8765 - val_loss: 153.1903\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.7359 - val_loss: 151.7977\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.5141 - val_loss: 150.9219\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.5013 - val_loss: 149.8931\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.9997 - val_loss: 148.9497\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.6806 - val_loss: 147.7168\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.8423 - val_loss: 146.7662\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.1650 - val_loss: 145.6944\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.8870 - val_loss: 145.0384\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.9628 - val_loss: 144.3624\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.9215 - val_loss: 143.4864\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.9599 - val_loss: 143.5072\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.9366 - val_loss: 142.1568\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.4260 - val_loss: 141.4297\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.6828 - val_loss: 141.6969\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.8158 - val_loss: 140.2152\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.7026 - val_loss: 140.2843\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.1710 - val_loss: 139.5189\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.0130 - val_loss: 139.0294\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.8311 - val_loss: 138.9409\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.2521 - val_loss: 138.1070\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.8591 - val_loss: 137.9936\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.1538 - val_loss: 137.2905\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.7532 - val_loss: 136.9917\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.1562 - val_loss: 137.3436\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.4921 - val_loss: 136.2570\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.8326 - val_loss: 136.3175\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.2892 - val_loss: 136.0739\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.2355 - val_loss: 135.6776\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.8085 - val_loss: 135.7375\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.8933 - val_loss: 135.8847\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.4299 - val_loss: 135.3593\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.8525 - val_loss: 135.2948\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.3815 - val_loss: 135.0881\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.2143 - val_loss: 135.6799\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.6513 - val_loss: 134.8433\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.3221 - val_loss: 135.2581\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.3579 - val_loss: 135.1213\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.9409 - val_loss: 134.7532\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.7333 - val_loss: 134.8098\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.3926 - val_loss: 134.7074\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.2688 - val_loss: 134.5128\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.8362 - val_loss: 134.5885\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.4912 - val_loss: 135.1288\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.2102 - val_loss: 134.6712\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.2482 - val_loss: 135.0090\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.7539 - val_loss: 136.1776\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.4052 - val_loss: 134.9271\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.8875 - val_loss: 135.0917\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.9185 - val_loss: 135.6422\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.5395 - val_loss: 134.8799\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.0602 - val_loss: 135.4514\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.9841 - val_loss: 135.0873\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.6797 - val_loss: 134.5613\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.2179 - val_loss: 135.1411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.5060 - val_loss: 134.3688\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.6173 - val_loss: 134.5008\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.6951 - val_loss: 134.6929\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.5246 - val_loss: 134.2743\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.9987 - val_loss: 135.2434\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 124.7762 - val_loss: 134.4179\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.4920 - val_loss: 134.0001\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.6631 - val_loss: 134.3617\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.2276 - val_loss: 133.7475\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.6994 - val_loss: 134.3308\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.2965 - val_loss: 133.5350\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.9113 - val_loss: 134.6550\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.6054 - val_loss: 133.9160\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.2891 - val_loss: 133.8574\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.2882 - val_loss: 135.1979\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.3696 - val_loss: 134.4120\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.8684 - val_loss: 135.4367\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.3296 - val_loss: 134.1515\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.5974 - val_loss: 133.7383\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.2181 - val_loss: 134.2234\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.8731 - val_loss: 135.2084\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 9ms/step - loss: 1570.3109 - val_loss: 1508.5643\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1550.3911 - val_loss: 1477.4406\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1499.9572 - val_loss: 1398.7074\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1377.7163 - val_loss: 1217.2059\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1114.9181 - val_loss: 849.8102\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 648.7224 - val_loss: 362.6611\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 300.4043 - val_loss: 236.2766\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 251.0777 - val_loss: 213.7723\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 231.0938 - val_loss: 202.2596\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 221.9952 - val_loss: 195.4506\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.8001 - val_loss: 189.2528\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.6720 - val_loss: 184.9404\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.7508 - val_loss: 182.3160\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.3132 - val_loss: 178.5065\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.8485 - val_loss: 175.8614\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.8266 - val_loss: 173.0961\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.9709 - val_loss: 171.7922\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.2246 - val_loss: 169.9492\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.2742 - val_loss: 167.9025\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.0488 - val_loss: 165.8685\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.0889 - val_loss: 164.6623\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.4623 - val_loss: 163.8105\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 174.5190 - val_loss: 161.8789\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.0100 - val_loss: 160.9621\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.3411 - val_loss: 159.5793\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.5483 - val_loss: 158.3729\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.0873 - val_loss: 157.5281\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.4515 - val_loss: 156.5571\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.6952 - val_loss: 155.8192\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.7106 - val_loss: 154.6943\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.8887 - val_loss: 153.6995\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.2122 - val_loss: 153.2047\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.5282 - val_loss: 152.6191\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.0432 - val_loss: 151.6126\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.9592 - val_loss: 151.3776\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.8874 - val_loss: 150.8907\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.3003 - val_loss: 150.2695\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.4418 - val_loss: 150.3932\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.1133 - val_loss: 149.5591\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.1903 - val_loss: 149.0808\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.0461 - val_loss: 149.9704\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.0681 - val_loss: 148.0920\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.5131 - val_loss: 147.8628\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.7832 - val_loss: 147.8710\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.4575 - val_loss: 147.0446\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.6336 - val_loss: 146.7291\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.4946 - val_loss: 146.7033\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.1807 - val_loss: 147.0914\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.1997 - val_loss: 146.1890\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.4117 - val_loss: 146.3302\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.5669 - val_loss: 146.1356\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.7827 - val_loss: 146.1073\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 150.4614 - val_loss: 145.3324\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.6450 - val_loss: 145.2866\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.3281 - val_loss: 144.4729\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.2260 - val_loss: 144.4274\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 148.4943 - val_loss: 144.6523\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.1446 - val_loss: 144.0590\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.2869 - val_loss: 143.6595\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.2358 - val_loss: 143.6083\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.3790 - val_loss: 143.4879\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.2631 - val_loss: 143.3862\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 146.1967 - val_loss: 142.7601\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.9331 - val_loss: 143.1454\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.0409 - val_loss: 142.9137\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.7184 - val_loss: 143.0374\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.7118 - val_loss: 142.6010\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 144.6170 - val_loss: 141.7778\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.6848 - val_loss: 143.2257\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.1253 - val_loss: 141.6811\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 142.5018 - val_loss: 141.6981\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.9772 - val_loss: 141.2999\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.1166 - val_loss: 140.6992\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.3069 - val_loss: 143.3874\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.7109 - val_loss: 142.2771\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.2307 - val_loss: 140.7235\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.7833 - val_loss: 141.2384\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 141.5837 - val_loss: 140.5838\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 139.7145 - val_loss: 139.7509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 139.8501 - val_loss: 139.8446\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.9392 - val_loss: 139.4766\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.4871 - val_loss: 139.2606\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.4103 - val_loss: 139.4588\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.5086 - val_loss: 139.1745\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.1655 - val_loss: 138.1777\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.5356 - val_loss: 138.9658\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.3631 - val_loss: 138.2947\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.9579 - val_loss: 138.1790\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 136.7361 - val_loss: 137.1647\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.4007 - val_loss: 137.5935\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.0203 - val_loss: 137.6155\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.4982 - val_loss: 137.0817\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.1642 - val_loss: 137.3819\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.4256 - val_loss: 136.5898\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.3772 - val_loss: 136.9306\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.6783 - val_loss: 136.5585\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.1321 - val_loss: 136.5362\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.7082 - val_loss: 136.3893\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.4103 - val_loss: 136.0849\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.7751 - val_loss: 135.4442\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 9ms/step - loss: 1614.3341 - val_loss: 1355.9460\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1571.0347 - val_loss: 1295.5680\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1470.3494 - val_loss: 1155.1981\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1243.6323 - val_loss: 857.1891\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 810.9048 - val_loss: 434.6719\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 392.9608 - val_loss: 266.7154\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 263.3853 - val_loss: 244.1704\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 232.4411 - val_loss: 224.3857\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 217.7007 - val_loss: 221.6495\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 208.6308 - val_loss: 212.1060\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 202.6418 - val_loss: 208.3784\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.9864 - val_loss: 206.2792\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.4547 - val_loss: 202.2461\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.9332 - val_loss: 202.6577\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.9084 - val_loss: 196.9178\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.9543 - val_loss: 200.2132\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.8391 - val_loss: 193.1964\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.0015 - val_loss: 193.4725\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.1015 - val_loss: 193.4675\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.7856 - val_loss: 190.5382\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.8365 - val_loss: 192.8015\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.1061 - val_loss: 186.4536\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.8175 - val_loss: 186.3462\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.7122 - val_loss: 185.6593\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.5034 - val_loss: 186.9325\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.7771 - val_loss: 185.6591\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 162.9567 - val_loss: 183.0844\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.1312 - val_loss: 182.5893\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.4846 - val_loss: 178.9393\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.3875 - val_loss: 179.0614\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.6587 - val_loss: 178.1597\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.5463 - val_loss: 175.9218\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.0244 - val_loss: 173.5457\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.7996 - val_loss: 173.5271\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.6467 - val_loss: 175.1777\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.6251 - val_loss: 172.1579\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.5332 - val_loss: 171.3852\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.5225 - val_loss: 168.3789\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.0044 - val_loss: 170.6230\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.9889 - val_loss: 169.1686\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.6562 - val_loss: 167.3393\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.3078 - val_loss: 167.8751\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.6982 - val_loss: 166.9043\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.2768 - val_loss: 164.6574\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.9808 - val_loss: 166.5783\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.1591 - val_loss: 163.6715\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.3181 - val_loss: 164.5740\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.2867 - val_loss: 159.7435\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.5771 - val_loss: 161.5156\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 136.4044 - val_loss: 157.4845\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.5426 - val_loss: 163.8210\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.2671 - val_loss: 157.4086\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 134.5354 - val_loss: 162.0704\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.4686 - val_loss: 157.6913\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.5536 - val_loss: 154.2261\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.9996 - val_loss: 158.7473\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.9563 - val_loss: 158.0073\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 130.8613 - val_loss: 151.6461\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.8339 - val_loss: 156.8469\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.8921 - val_loss: 151.8789\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.2136 - val_loss: 153.1382\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.5706 - val_loss: 155.3619\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.5316 - val_loss: 151.4479\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.3198 - val_loss: 156.2422\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.0438 - val_loss: 147.7230\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.6041 - val_loss: 153.2844\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 125.5252 - val_loss: 152.2281\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.7992 - val_loss: 150.0213\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.5388 - val_loss: 155.7842\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.8658 - val_loss: 152.7767\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.1717 - val_loss: 149.3591\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.1019 - val_loss: 152.1113\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.0511 - val_loss: 148.0573\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.7325 - val_loss: 160.2123\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.4200 - val_loss: 150.0442\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.5806 - val_loss: 150.3146\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.5134 - val_loss: 156.8158\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.5950 - val_loss: 144.4266\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.0129 - val_loss: 153.3798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.1110 - val_loss: 149.5258\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.6641 - val_loss: 150.4452\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.6098 - val_loss: 149.5323\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.1571 - val_loss: 151.0110\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.2394 - val_loss: 153.6985\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.1975 - val_loss: 147.6107\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.1177 - val_loss: 152.3695\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.2046 - val_loss: 144.5377\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 121.1278 - val_loss: 152.2270\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.7035 - val_loss: 147.9125\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.8471 - val_loss: 147.4703\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 120.4139 - val_loss: 148.4607\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.7943 - val_loss: 145.9758\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.0083 - val_loss: 150.1429\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.9844 - val_loss: 148.3503\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.9289 - val_loss: 148.3167\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.3088 - val_loss: 148.7263\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.7193 - val_loss: 149.6994\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.6857 - val_loss: 149.1463\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.0095 - val_loss: 149.7391\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.0680 - val_loss: 149.1578\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 9ms/step - loss: 1556.9480 - val_loss: 1564.8796\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1536.3436 - val_loss: 1539.9976\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1500.0834 - val_loss: 1484.3379\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1418.8073 - val_loss: 1364.8140\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1255.3892 - val_loss: 1143.4172\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 975.5382 - val_loss: 784.3161\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 593.0529 - val_loss: 393.3155\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 292.8311 - val_loss: 233.2946\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 224.1864 - val_loss: 218.7520\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 206.3168 - val_loss: 217.1600\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.2484 - val_loss: 215.5620\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 196.0122 - val_loss: 211.6632\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 193.3797 - val_loss: 208.2887\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.9256 - val_loss: 204.6947\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.7166 - val_loss: 201.0623\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.6195 - val_loss: 197.0057\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.1089 - val_loss: 195.1883\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.2068 - val_loss: 192.2939\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.4963 - val_loss: 189.2659\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.4953 - val_loss: 186.5298\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.7170 - val_loss: 183.9199\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 172.4216 - val_loss: 181.0496\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.7068 - val_loss: 178.7454\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.7014 - val_loss: 177.3876\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 167.3140 - val_loss: 174.1793\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 165.5619 - val_loss: 172.6216\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 164.6186 - val_loss: 169.6652\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 162.0252 - val_loss: 167.8148\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.6914 - val_loss: 165.4844\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.9343 - val_loss: 163.4003\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4696 - val_loss: 162.5216\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.1601 - val_loss: 161.1338\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.5117 - val_loss: 157.3656\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.4137 - val_loss: 155.4673\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.6215 - val_loss: 153.9294\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.7167 - val_loss: 153.5759\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.7689 - val_loss: 150.6579\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.8299 - val_loss: 149.7259\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.8481 - val_loss: 148.1406\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.8798 - val_loss: 145.8745\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.9563 - val_loss: 145.8743\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.6422 - val_loss: 143.8766\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.7884 - val_loss: 142.4317\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.7696 - val_loss: 141.3603\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.9828 - val_loss: 139.9563\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.3147 - val_loss: 140.5157\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.2641 - val_loss: 138.5922\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.8440 - val_loss: 138.3531\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.9822 - val_loss: 136.9544\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.3220 - val_loss: 135.9732\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.5759 - val_loss: 135.1555\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.6558 - val_loss: 134.3150\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.5678 - val_loss: 134.1935\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.6347 - val_loss: 134.4045\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.6364 - val_loss: 132.0034\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.5371 - val_loss: 132.6513\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.6435 - val_loss: 131.5063\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.2581 - val_loss: 131.9499\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.9664 - val_loss: 130.2222\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.0655 - val_loss: 130.0622\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.4897 - val_loss: 130.4086\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.5206 - val_loss: 128.5861\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.1487 - val_loss: 129.1173\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.5577 - val_loss: 129.1781\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.9921 - val_loss: 128.6430\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.1722 - val_loss: 128.1309\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.7280 - val_loss: 128.3916\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.8826 - val_loss: 126.5209\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.6760 - val_loss: 127.6714\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.3257 - val_loss: 126.5748\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.3405 - val_loss: 127.2020\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.4151 - val_loss: 127.7563\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.3034 - val_loss: 125.7075\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.1625 - val_loss: 127.1177\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.3208 - val_loss: 125.7579\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.0619 - val_loss: 125.5611\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.4508 - val_loss: 124.7713\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.4776 - val_loss: 125.5298\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.2687 - val_loss: 125.2234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.3640 - val_loss: 125.5028\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.2099 - val_loss: 124.6518\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.1554 - val_loss: 125.0789\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.1742 - val_loss: 124.4029\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.7222 - val_loss: 125.0070\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.2547 - val_loss: 124.6034\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.4172 - val_loss: 125.6621\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.7763 - val_loss: 124.1524\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.4210 - val_loss: 125.5536\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.1836 - val_loss: 124.2113\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.4096 - val_loss: 125.3808\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.3481 - val_loss: 125.3978\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.0989 - val_loss: 124.6105\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.8370 - val_loss: 124.6051\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.0332 - val_loss: 125.0403\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.9667 - val_loss: 124.8464\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.1674 - val_loss: 125.3551\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.4944 - val_loss: 124.3987\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.2566 - val_loss: 126.6245\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.1306 - val_loss: 124.1514\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.0045 - val_loss: 124.3423\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1581.1073 - val_loss: 1513.2349\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1574.0759 - val_loss: 1503.8750\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1556.3610 - val_loss: 1475.7681\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1511.8599 - val_loss: 1412.2393\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1416.3462 - val_loss: 1276.8954\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1221.0040 - val_loss: 1024.7932\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 887.9805 - val_loss: 640.0795\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 482.0894 - val_loss: 311.9806\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 256.4406 - val_loss: 252.0253\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 225.6561 - val_loss: 242.4011\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.6345 - val_loss: 234.0294\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.3408 - val_loss: 228.7207\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.3007 - val_loss: 223.9608\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.2807 - val_loss: 222.0332\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.7516 - val_loss: 215.8397\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.6576 - val_loss: 213.6476\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.3929 - val_loss: 210.2204\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.2068 - val_loss: 209.1456\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.8093 - val_loss: 206.5853\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.9614 - val_loss: 202.1917\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.0372 - val_loss: 200.9665\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.0502 - val_loss: 199.3481\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.9821 - val_loss: 196.8402\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.3690 - val_loss: 195.3823\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.6988 - val_loss: 195.5042\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.9102 - val_loss: 193.3629\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.1249 - val_loss: 191.6532\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.1773 - val_loss: 191.0941\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.7896 - val_loss: 188.9552\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.2805 - val_loss: 188.9073\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.2184 - val_loss: 186.8130\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.9400 - val_loss: 185.6687\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.7554 - val_loss: 184.5619\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.3053 - val_loss: 184.6871\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.1085 - val_loss: 183.6068\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.1404 - val_loss: 182.6281\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.3882 - val_loss: 181.0963\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.4270 - val_loss: 180.0504\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.4307 - val_loss: 178.9390\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.8695 - val_loss: 178.2061\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.2029 - val_loss: 178.7508\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.3602 - val_loss: 176.0384\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.4112 - val_loss: 177.3715\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 144.5318 - val_loss: 175.3709\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.5079 - val_loss: 176.4889\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.5063 - val_loss: 174.5362\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.9482 - val_loss: 173.5303\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.9426 - val_loss: 174.5448\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.8123 - val_loss: 172.2329\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.7889 - val_loss: 173.8222\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.4355 - val_loss: 171.1942\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.7218 - val_loss: 170.3580\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.8198 - val_loss: 171.1163\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.8148 - val_loss: 169.4654\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 135.3889 - val_loss: 169.0386\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.2312 - val_loss: 170.6180\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.6831 - val_loss: 167.2968\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 133.7308 - val_loss: 166.9609\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.3605 - val_loss: 168.3085\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.1350 - val_loss: 168.1657\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.9857 - val_loss: 167.0560\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 131.3444 - val_loss: 165.7628\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.0171 - val_loss: 164.5956\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.8109 - val_loss: 164.9791\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.2338 - val_loss: 164.3919\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.3805 - val_loss: 164.8553\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.8579 - val_loss: 165.0972\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.0368 - val_loss: 163.7773\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.9310 - val_loss: 163.6828\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.2793 - val_loss: 162.2739\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.9198 - val_loss: 162.7829\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.7411 - val_loss: 162.7243\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.0533 - val_loss: 163.9368\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.6904 - val_loss: 161.4318\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.2940 - val_loss: 162.1298\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.8287 - val_loss: 162.2412\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.6435 - val_loss: 160.2311\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.7284 - val_loss: 160.3435\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 122.4869 - val_loss: 160.8539\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.3546 - val_loss: 160.0663\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.0995 - val_loss: 159.5595\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.5446 - val_loss: 161.0072\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.6295 - val_loss: 159.2041\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.1712 - val_loss: 159.8376\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 121.5679 - val_loss: 160.9114\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.6015 - val_loss: 159.0259\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.6639 - val_loss: 158.2217\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.2637 - val_loss: 159.4695\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.8087 - val_loss: 158.2637\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.8819 - val_loss: 157.2805\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.3181 - val_loss: 158.8039\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.8509 - val_loss: 157.1628\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.8037 - val_loss: 158.1997\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.7640 - val_loss: 158.0350\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.6373 - val_loss: 158.4906\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.2036 - val_loss: 158.8372\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.9127 - val_loss: 156.7806\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.3731 - val_loss: 156.4225\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.7756 - val_loss: 157.2619\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.4689 - val_loss: 156.3953\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1526.8572 - val_loss: 1601.7029\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1499.4674 - val_loss: 1560.7460\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1441.7422 - val_loss: 1474.2885\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1324.2008 - val_loss: 1302.2617\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1099.0063 - val_loss: 989.3428\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 743.9725 - val_loss: 574.9719\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 403.9019 - val_loss: 342.9055\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 276.4481 - val_loss: 311.8679\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 245.6356 - val_loss: 291.1725\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 224.9908 - val_loss: 278.2389\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 215.0959 - val_loss: 269.1898\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.3702 - val_loss: 259.2305\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.0367 - val_loss: 251.7195\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.3138 - val_loss: 245.1456\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.4534 - val_loss: 239.4697\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.9019 - val_loss: 232.7745\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.4807 - val_loss: 227.9876\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.1172 - val_loss: 223.4724\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.7050 - val_loss: 219.8294\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.5075 - val_loss: 213.3126\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.7918 - val_loss: 207.0241\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.9639 - val_loss: 203.7410\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.3282 - val_loss: 201.1005\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.3957 - val_loss: 197.9947\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.4510 - val_loss: 195.6690\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.8095 - val_loss: 192.4442\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.7003 - val_loss: 188.0641\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.3199 - val_loss: 186.8485\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.7914 - val_loss: 185.9894\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.4260 - val_loss: 181.6779\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.3902 - val_loss: 179.7781\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.0580 - val_loss: 178.7107\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.2139 - val_loss: 175.7296\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.8044 - val_loss: 174.9621\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.4625 - val_loss: 173.0008\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.0119 - val_loss: 170.3944\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8743 - val_loss: 168.8904\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.2579 - val_loss: 168.9082\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.0657 - val_loss: 166.9311\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.7663 - val_loss: 165.8158\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.3430 - val_loss: 164.1789\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.7456 - val_loss: 163.6514\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.3272 - val_loss: 162.1340\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.0444 - val_loss: 161.3603\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.7076 - val_loss: 158.5597\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.7422 - val_loss: 157.5029\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.7094 - val_loss: 156.8291\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.6621 - val_loss: 155.5186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.6855 - val_loss: 153.9466\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.1107 - val_loss: 152.9798\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.0334 - val_loss: 152.8980\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.3814 - val_loss: 151.6615\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.6425 - val_loss: 151.5305\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.1897 - val_loss: 149.7172\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.3302 - val_loss: 149.7246\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.5445 - val_loss: 148.2572\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.5441 - val_loss: 148.7879\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.6857 - val_loss: 149.2725\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.9342 - val_loss: 147.9789\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.3904 - val_loss: 147.0839\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.1960 - val_loss: 146.7851\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.2301 - val_loss: 146.4815\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.9190 - val_loss: 146.0799\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.0702 - val_loss: 145.9334\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.6472 - val_loss: 145.1506\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.9529 - val_loss: 144.6977\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.1827 - val_loss: 144.7766\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.9246 - val_loss: 143.7403\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.7336 - val_loss: 145.0895\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.4821 - val_loss: 143.3918\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.3256 - val_loss: 142.2420\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.6628 - val_loss: 142.9264\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.1336 - val_loss: 143.1387\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.2341 - val_loss: 144.7564\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.5956 - val_loss: 142.4883\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.0989 - val_loss: 142.3472\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.8408 - val_loss: 143.1398\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.2428 - val_loss: 143.4422\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.1601 - val_loss: 142.4661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.6734 - val_loss: 141.4806\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.5765 - val_loss: 142.1788\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.3527 - val_loss: 141.5789\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.7917 - val_loss: 141.5058\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.5076 - val_loss: 140.8830\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.2486 - val_loss: 142.3217\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.8981 - val_loss: 141.0848\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.7473 - val_loss: 142.2631\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.1566 - val_loss: 142.5269\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.3354 - val_loss: 140.9456\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.1456 - val_loss: 140.9919\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.4931 - val_loss: 141.1738\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.9935 - val_loss: 142.8772\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.4053 - val_loss: 141.9215\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.6307 - val_loss: 140.0247\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.2685 - val_loss: 140.7038\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.4038 - val_loss: 141.1201\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.2714 - val_loss: 141.7180\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.9750 - val_loss: 142.4486\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.2632 - val_loss: 139.6687\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.5714 - val_loss: 142.0159\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1537.2582 - val_loss: 1530.4352\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1492.5544 - val_loss: 1460.0563\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1386.6390 - val_loss: 1297.8910\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1151.6038 - val_loss: 954.3245\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 734.9798 - val_loss: 480.9581\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 342.3741 - val_loss: 261.9349\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 244.7758 - val_loss: 221.9422\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 220.1477 - val_loss: 205.9822\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.2323 - val_loss: 197.2313\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.9875 - val_loss: 192.4797\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.3520 - val_loss: 188.5812\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.4869 - val_loss: 185.5036\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.0087 - val_loss: 182.8183\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.6810 - val_loss: 180.3236\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.9360 - val_loss: 178.4399\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.0321 - val_loss: 176.5344\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.6929 - val_loss: 174.8392\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.0482 - val_loss: 172.4718\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.4070 - val_loss: 169.6366\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.7827 - val_loss: 168.2141\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.1916 - val_loss: 165.4325\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.1656 - val_loss: 164.0363\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.5550 - val_loss: 161.5030\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.3890 - val_loss: 160.4853\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.0214 - val_loss: 159.3939\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.9068 - val_loss: 158.0776\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.0370 - val_loss: 156.8870\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.2568 - val_loss: 156.0458\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.1616 - val_loss: 155.0330\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.7987 - val_loss: 152.7078\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.6476 - val_loss: 152.4672\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.5541 - val_loss: 151.4500\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.0354 - val_loss: 150.6786\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.6926 - val_loss: 149.5452\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.5681 - val_loss: 149.1580\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.4872 - val_loss: 148.3956\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.2643 - val_loss: 147.3437\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.1974 - val_loss: 147.1035\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.7912 - val_loss: 146.8663\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.1341 - val_loss: 145.8124\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.9317 - val_loss: 144.7800\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.3152 - val_loss: 143.8847\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.6059 - val_loss: 143.4602\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.6140 - val_loss: 143.5347\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.9525 - val_loss: 142.8265\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.0145 - val_loss: 141.6615\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.7864 - val_loss: 141.9685\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.8622 - val_loss: 141.2886\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.9097 - val_loss: 141.1824\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.3820 - val_loss: 140.5472\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.6759 - val_loss: 140.0761\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.7880 - val_loss: 140.0001\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.6091 - val_loss: 140.6436\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.8206 - val_loss: 139.5475\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.4600 - val_loss: 141.6867\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.9812 - val_loss: 138.6561\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.6537 - val_loss: 138.5266\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 128.8569 - val_loss: 139.2666\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.3279 - val_loss: 138.6123\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 126.7177 - val_loss: 138.5147\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 126.8576 - val_loss: 137.6367\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 125.3517 - val_loss: 138.5079\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.2784 - val_loss: 138.3385\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 125.2194 - val_loss: 138.3035\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.0232 - val_loss: 138.1361\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.7648 - val_loss: 138.9224\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.1339 - val_loss: 138.7523\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.9232 - val_loss: 138.1739\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 123.0373 - val_loss: 137.6912\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.9453 - val_loss: 137.8643\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 123.3342 - val_loss: 137.9238\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 122.5994 - val_loss: 138.0109\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 123.8376 - val_loss: 139.3863\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.9279 - val_loss: 138.7460\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.2247 - val_loss: 137.4951\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 121.5817 - val_loss: 137.0914\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.7582 - val_loss: 137.9550\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.2142 - val_loss: 138.1969\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 120.0851 - val_loss: 139.1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.9838 - val_loss: 138.0659\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.1781 - val_loss: 137.8853\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.2356 - val_loss: 137.6640\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 120.1759 - val_loss: 137.2475\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 121.0400 - val_loss: 137.1777\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.9545 - val_loss: 137.0902\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 119.5865 - val_loss: 136.5882\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.9247 - val_loss: 136.3254\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.0917 - val_loss: 137.1117\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.0654 - val_loss: 137.5901\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.7944 - val_loss: 137.2915\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.1816 - val_loss: 136.7015\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.4681 - val_loss: 136.4592\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.9473 - val_loss: 136.8355\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.5649 - val_loss: 137.3417\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.7514 - val_loss: 136.5252\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.4655 - val_loss: 136.0473\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.4444 - val_loss: 136.0585\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.0632 - val_loss: 138.7428\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.7231 - val_loss: 135.7384\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.6982 - val_loss: 136.4087\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1597.0292 - val_loss: 1470.6165\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1579.0094 - val_loss: 1453.5052\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1553.5532 - val_loss: 1421.9396\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1504.8013 - val_loss: 1360.1031\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1406.3651 - val_loss: 1236.6489\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1217.0741 - val_loss: 1005.2983\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 886.3447 - val_loss: 645.7652\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 487.8426 - val_loss: 333.9458\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 265.2518 - val_loss: 240.9458\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 225.8430 - val_loss: 222.2889\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 214.6946 - val_loss: 212.5360\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 206.6882 - val_loss: 205.9505\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.6135 - val_loss: 202.3080\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.2458 - val_loss: 198.1475\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.3696 - val_loss: 194.8462\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.1997 - val_loss: 192.0777\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.2442 - val_loss: 189.7454\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.0400 - val_loss: 187.2637\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.9845 - val_loss: 185.9647\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.3414 - val_loss: 183.9636\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.7648 - val_loss: 181.8137\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.5020 - val_loss: 180.3823\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.4192 - val_loss: 179.2296\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.6922 - val_loss: 176.9204\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.1429 - val_loss: 175.0890\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.3677 - val_loss: 174.2821\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.7587 - val_loss: 172.5541\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.4113 - val_loss: 170.9955\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.0514 - val_loss: 169.5061\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.5389 - val_loss: 167.8395\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.9226 - val_loss: 166.6691\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.4136 - val_loss: 165.7881\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.5705 - val_loss: 164.9791\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.9870 - val_loss: 162.4770\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.2986 - val_loss: 161.3992\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.8046 - val_loss: 160.9749\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.0799 - val_loss: 158.3167\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.1479 - val_loss: 157.4972\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.1664 - val_loss: 155.9554\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.2625 - val_loss: 154.6293\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.7489 - val_loss: 153.7027\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.9214 - val_loss: 152.8716\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.7575 - val_loss: 151.7806\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.2146 - val_loss: 151.4120\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.5669 - val_loss: 149.6211\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.5966 - val_loss: 149.5588\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.6277 - val_loss: 148.0823\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.5325 - val_loss: 147.3207\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.8589 - val_loss: 147.5143\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.2816 - val_loss: 145.8391\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.1470 - val_loss: 145.2622\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.9978 - val_loss: 144.5675\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.0863 - val_loss: 144.6134\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 134.1411 - val_loss: 145.0988\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.4723 - val_loss: 144.2195\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.8441 - val_loss: 142.4923\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.5106 - val_loss: 142.6953\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.7317 - val_loss: 142.8522\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.3793 - val_loss: 141.3607\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.4373 - val_loss: 140.9206\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.9695 - val_loss: 140.9263\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.9981 - val_loss: 140.5550\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.1720 - val_loss: 141.4410\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.3506 - val_loss: 140.0699\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.7423 - val_loss: 139.5509\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 126.7319 - val_loss: 140.6165\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.4147 - val_loss: 138.7643\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.7887 - val_loss: 139.4680\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.0803 - val_loss: 139.8416\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.4759 - val_loss: 138.2122\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.8700 - val_loss: 138.3407\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.7665 - val_loss: 139.2600\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.8760 - val_loss: 138.7460\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.5536 - val_loss: 139.2097\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.5245 - val_loss: 138.3431\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.6870 - val_loss: 138.9291\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.5289 - val_loss: 139.1142\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.9484 - val_loss: 139.0786\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.4828 - val_loss: 137.6798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.1187 - val_loss: 138.3449\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.3120 - val_loss: 139.1172\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.8837 - val_loss: 137.8703\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.1184 - val_loss: 138.2595\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.0280 - val_loss: 139.7503\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.1475 - val_loss: 138.8305\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.2391 - val_loss: 138.8034\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.5473 - val_loss: 137.5413\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.4655 - val_loss: 139.9515\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.7516 - val_loss: 139.6794\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.2617 - val_loss: 140.5141\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.5629 - val_loss: 138.2571\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.9909 - val_loss: 138.9826\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.6974 - val_loss: 139.3117\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.8533 - val_loss: 138.7594\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.8438 - val_loss: 140.2244\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.3597 - val_loss: 138.8702\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.3788 - val_loss: 138.0792\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.4183 - val_loss: 140.0145\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.5213 - val_loss: 138.4583\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.2052 - val_loss: 139.8599\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1510.3473 - val_loss: 1607.2354\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1473.4966 - val_loss: 1552.8315\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1393.2089 - val_loss: 1436.4049\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1236.0826 - val_loss: 1224.8844\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 971.2712 - val_loss: 893.5173\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 618.6392 - val_loss: 509.4347\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 339.2837 - val_loss: 307.4098\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 250.6380 - val_loss: 250.1909\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 225.2847 - val_loss: 237.0273\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 215.6141 - val_loss: 224.3026\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.7930 - val_loss: 220.7361\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.2458 - val_loss: 215.3313\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.8261 - val_loss: 211.0644\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.5984 - val_loss: 206.9861\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.0724 - val_loss: 205.4299\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.4286 - val_loss: 203.0840\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.9303 - val_loss: 201.1486\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.2341 - val_loss: 196.7107\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.1094 - val_loss: 195.2390\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.6057 - val_loss: 193.2147\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.0410 - val_loss: 192.8951\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.1330 - val_loss: 190.2951\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.8485 - val_loss: 189.7624\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.8058 - val_loss: 189.4506\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.7382 - val_loss: 187.0585\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.3801 - val_loss: 186.4298\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.6631 - val_loss: 184.6927\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.0709 - val_loss: 183.3513\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.7446 - val_loss: 183.0477\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.8201 - val_loss: 180.6248\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.5305 - val_loss: 180.5516\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.5477 - val_loss: 180.0019\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.4874 - val_loss: 178.6329\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.4361 - val_loss: 177.9481\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.1348 - val_loss: 175.7908\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.6322 - val_loss: 178.0982\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.5013 - val_loss: 174.3928\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.7736 - val_loss: 174.8595\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.3454 - val_loss: 174.6095\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.8121 - val_loss: 173.0522\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.4195 - val_loss: 172.4421\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.0777 - val_loss: 170.9514\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.4816 - val_loss: 171.7054\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 149.4062 - val_loss: 172.5171\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.6677 - val_loss: 170.3979\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.7344 - val_loss: 168.7380\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.8880 - val_loss: 169.8189\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 147.3901 - val_loss: 168.2167\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.4896 - val_loss: 168.7641\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.4728 - val_loss: 168.3628\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.4892 - val_loss: 166.6915\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.4246 - val_loss: 167.3235\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.6885 - val_loss: 167.0182\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.7494 - val_loss: 165.0789\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.3162 - val_loss: 166.8628\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.1699 - val_loss: 165.1436\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 143.3389 - val_loss: 164.7618\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.7444 - val_loss: 164.8269\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.0643 - val_loss: 164.3229\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.0697 - val_loss: 165.4753\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.3816 - val_loss: 162.8803\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.1381 - val_loss: 164.1785\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.8303 - val_loss: 163.6960\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.0351 - val_loss: 162.8410\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.4202 - val_loss: 163.0654\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.4157 - val_loss: 161.7255\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.2859 - val_loss: 162.8788\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.2144 - val_loss: 160.3051\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.6051 - val_loss: 161.7678\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.3401 - val_loss: 161.0260\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.3389 - val_loss: 158.5804\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.3861 - val_loss: 160.3203\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.1451 - val_loss: 159.0875\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.0915 - val_loss: 158.6461\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.2275 - val_loss: 158.3255\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.1858 - val_loss: 157.2686\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.0068 - val_loss: 157.7668\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.1775 - val_loss: 159.1748\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.7969 - val_loss: 156.3922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.7934 - val_loss: 156.1223\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.0911 - val_loss: 154.9134\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.0343 - val_loss: 156.5822\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.9479 - val_loss: 154.0340\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.3068 - val_loss: 157.1586\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.2870 - val_loss: 153.9133\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.0633 - val_loss: 154.0036\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.2179 - val_loss: 153.5729\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.1385 - val_loss: 154.4353\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.5156 - val_loss: 153.6322\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.6772 - val_loss: 152.6997\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.2863 - val_loss: 151.8282\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.6335 - val_loss: 152.6573\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.7229 - val_loss: 152.3987\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.8359 - val_loss: 152.7299\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.2266 - val_loss: 152.2847\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.0997 - val_loss: 152.5826\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.2573 - val_loss: 149.5577\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.3656 - val_loss: 152.6196\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.7010 - val_loss: 150.7811\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.5087 - val_loss: 151.7717\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 9ms/step - loss: 1548.3171 - val_loss: 1529.2256\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1492.6206 - val_loss: 1452.4647\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1388.6418 - val_loss: 1314.8967\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1203.0131 - val_loss: 1075.9111\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 900.3419 - val_loss: 715.3536\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 522.7035 - val_loss: 347.3656\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 272.1233 - val_loss: 216.7969\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 231.6445 - val_loss: 207.7086\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 218.2718 - val_loss: 204.1407\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 213.1061 - val_loss: 201.5913\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 208.6096 - val_loss: 197.0627\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.9526 - val_loss: 194.6576\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 201.8906 - val_loss: 193.5074\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.4172 - val_loss: 190.1593\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.2164 - val_loss: 187.9895\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.7884 - val_loss: 186.8826\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.0156 - val_loss: 185.1805\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.2880 - val_loss: 183.4686\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.1285 - val_loss: 182.3629\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.1122 - val_loss: 180.5398\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.6504 - val_loss: 179.1715\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.6674 - val_loss: 178.0157\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.5547 - val_loss: 176.3564\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.5309 - val_loss: 175.8199\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.9511 - val_loss: 174.5343\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.2009 - val_loss: 175.1978\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.6436 - val_loss: 172.8559\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.3478 - val_loss: 171.2831\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.9704 - val_loss: 171.4635\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.9935 - val_loss: 171.0186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.1488 - val_loss: 170.4855\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.0513 - val_loss: 168.6199\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.4748 - val_loss: 167.9253\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.4086 - val_loss: 168.4925\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.3642 - val_loss: 166.8513\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.7492 - val_loss: 166.0777\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.2700 - val_loss: 165.3789\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.2581 - val_loss: 164.7126\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.8665 - val_loss: 163.7276\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.2036 - val_loss: 163.3810\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 164.2659 - val_loss: 162.2696\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.1208 - val_loss: 161.2050\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.0017 - val_loss: 161.2454\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.5822 - val_loss: 159.8026\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.2617 - val_loss: 159.9328\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.9553 - val_loss: 159.1295\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.1198 - val_loss: 158.0271\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4999 - val_loss: 157.1298\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.1292 - val_loss: 156.4237\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.1762 - val_loss: 156.2764\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.5335 - val_loss: 154.6340\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.3035 - val_loss: 154.4039\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.2973 - val_loss: 153.5166\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.7332 - val_loss: 153.0256\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 152.3890 - val_loss: 152.2072\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 151.0146 - val_loss: 151.8675\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.6031 - val_loss: 151.0345\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.6462 - val_loss: 150.7796\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.6729 - val_loss: 150.0779\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.5712 - val_loss: 149.6541\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.7037 - val_loss: 149.3426\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.0386 - val_loss: 148.2794\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.5985 - val_loss: 148.2320\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.3980 - val_loss: 148.0822\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.0495 - val_loss: 147.4347\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.5146 - val_loss: 147.2643\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.1013 - val_loss: 146.5500\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.1254 - val_loss: 146.1352\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.4124 - val_loss: 145.4274\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.8343 - val_loss: 145.3594\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.6074 - val_loss: 145.7278\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.4536 - val_loss: 144.9739\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.4115 - val_loss: 144.8209\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.3666 - val_loss: 144.5832\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.9978 - val_loss: 144.0401\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.1648 - val_loss: 143.8628\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.0147 - val_loss: 143.5712\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.1545 - val_loss: 143.1942\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.8300 - val_loss: 143.1479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.7876 - val_loss: 143.3229\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.5708 - val_loss: 142.7440\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.0997 - val_loss: 142.7238\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.6294 - val_loss: 142.0141\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.4784 - val_loss: 142.1646\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.9353 - val_loss: 142.3515\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 136.3854 - val_loss: 141.8439\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.7545 - val_loss: 141.6124\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.1310 - val_loss: 142.4014\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 134.3880 - val_loss: 141.4989\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.9646 - val_loss: 140.9865\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 134.4984 - val_loss: 140.6005\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.7861 - val_loss: 141.2235\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 132.7847 - val_loss: 140.7342\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.9744 - val_loss: 140.6289\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 131.8432 - val_loss: 140.7457\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 131.2196 - val_loss: 140.9661\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.7628 - val_loss: 140.2699\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.3185 - val_loss: 139.8759\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.9447 - val_loss: 139.8341\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 131.1945 - val_loss: 139.6543\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 10ms/step - loss: 1564.2653 - val_loss: 1550.4325\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1552.1816 - val_loss: 1533.2433\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1528.2660 - val_loss: 1501.2224\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1482.0378 - val_loss: 1433.1787\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1378.6024 - val_loss: 1276.3152\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1151.4263 - val_loss: 962.9117\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 763.7723 - val_loss: 511.8188\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 364.2410 - val_loss: 228.3123\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 242.5998 - val_loss: 201.8083\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 231.3807 - val_loss: 196.5287\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 220.9080 - val_loss: 189.6435\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 213.3900 - val_loss: 185.8498\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.1120 - val_loss: 180.5595\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.2556 - val_loss: 176.2856\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.1616 - val_loss: 174.7652\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.8669 - val_loss: 171.3167\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.3994 - val_loss: 169.5770\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.6544 - val_loss: 167.2707\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.0625 - val_loss: 167.1769\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.8543 - val_loss: 162.8362\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.4852 - val_loss: 163.1801\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 177.2213 - val_loss: 159.9660\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.8887 - val_loss: 159.7951\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.2095 - val_loss: 158.2528\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.0530 - val_loss: 156.3011\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.3133 - val_loss: 156.0741\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.2780 - val_loss: 155.7476\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.5494 - val_loss: 152.9572\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.1448 - val_loss: 153.5438\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.1627 - val_loss: 150.8842\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.9792 - val_loss: 150.5104\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.7067 - val_loss: 149.0640\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.1381 - val_loss: 148.8464\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.9915 - val_loss: 147.9011\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.0042 - val_loss: 146.2341\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.3833 - val_loss: 145.9292\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.5346 - val_loss: 144.6029\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.1080 - val_loss: 143.6404\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.7971 - val_loss: 143.6724\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.6915 - val_loss: 143.3648\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.6497 - val_loss: 142.1428\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.9228 - val_loss: 142.3699\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.8518 - val_loss: 141.2056\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.3998 - val_loss: 139.9002\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.4106 - val_loss: 140.5532\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.8368 - val_loss: 139.5492\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 143.3586 - val_loss: 138.2864\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.5714 - val_loss: 138.4899\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.4243 - val_loss: 138.3606\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.7350 - val_loss: 136.0393\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.0955 - val_loss: 136.6303\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.5092 - val_loss: 137.5602\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.9412 - val_loss: 136.4815\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.5750 - val_loss: 135.6182\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.5982 - val_loss: 134.6382\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.4172 - val_loss: 134.2457\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.8060 - val_loss: 135.5985\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.3720 - val_loss: 134.0959\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.1093 - val_loss: 136.0348\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.8340 - val_loss: 134.0424\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 134.8900 - val_loss: 134.1682\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.6775 - val_loss: 135.5079\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.6211 - val_loss: 132.8415\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.1879 - val_loss: 135.8279\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.2400 - val_loss: 132.8976\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.7517 - val_loss: 132.9440\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 132.5022 - val_loss: 134.4728\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.5894 - val_loss: 132.1585\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.4967 - val_loss: 134.2156\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 131.4373 - val_loss: 132.1805\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.1972 - val_loss: 133.3763\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.5564 - val_loss: 131.5866\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.1696 - val_loss: 131.0553\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.9587 - val_loss: 134.0772\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.8372 - val_loss: 130.9430\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.6407 - val_loss: 131.3112\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 129.9210 - val_loss: 131.3628\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.9453 - val_loss: 134.2826\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 129.3696 - val_loss: 130.9533\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.5583 - val_loss: 132.2676\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.6434 - val_loss: 131.3542\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.6751 - val_loss: 130.4717\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.6973 - val_loss: 132.5069\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.3935 - val_loss: 130.8981\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.2097 - val_loss: 131.8998\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.1768 - val_loss: 133.2491\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.0844 - val_loss: 129.9149\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.4729 - val_loss: 132.0013\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.4061 - val_loss: 128.9911\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.8780 - val_loss: 130.4116\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.5626 - val_loss: 130.5175\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.5932 - val_loss: 130.3003\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.9903 - val_loss: 130.6813\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.2937 - val_loss: 129.9703\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.7868 - val_loss: 130.0898\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.5696 - val_loss: 129.8482\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.5164 - val_loss: 130.8046\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.9495 - val_loss: 128.1014\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.0802 - val_loss: 128.5106\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.8505 - val_loss: 129.8941\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1505.8787 - val_loss: 1622.8577\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1465.9795 - val_loss: 1559.3264\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1380.8210 - val_loss: 1431.4122\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1208.6218 - val_loss: 1165.0908\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 878.5388 - val_loss: 701.7032\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 460.2923 - val_loss: 299.3562\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 258.3335 - val_loss: 232.1921\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 226.6445 - val_loss: 220.5492\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.9745 - val_loss: 213.5912\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.0480 - val_loss: 208.2095\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.6289 - val_loss: 206.0982\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.5744 - val_loss: 203.4887\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.5114 - val_loss: 200.9425\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.6044 - val_loss: 199.4201\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.1463 - val_loss: 196.2721\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.5313 - val_loss: 194.6234\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.4993 - val_loss: 193.6624\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.8708 - val_loss: 193.3092\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.2912 - val_loss: 190.2687\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.5337 - val_loss: 189.1703\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.3035 - val_loss: 188.8239\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.6527 - val_loss: 186.9964\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.6260 - val_loss: 187.3130\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 172.5078 - val_loss: 184.5993\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.3819 - val_loss: 183.8235\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.9563 - val_loss: 184.3993\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.3484 - val_loss: 183.2172\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.4286 - val_loss: 182.7164\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.8598 - val_loss: 181.1435\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.7218 - val_loss: 181.1031\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.7479 - val_loss: 179.4346\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.8804 - val_loss: 178.8690\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.6178 - val_loss: 178.2032\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.6110 - val_loss: 177.6448\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.1920 - val_loss: 176.6286\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.7368 - val_loss: 176.7640\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.1912 - val_loss: 176.6623\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.6438 - val_loss: 174.3469\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.4244 - val_loss: 174.1087\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.7842 - val_loss: 173.7981\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.3147 - val_loss: 173.4750\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.7478 - val_loss: 172.1913\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.9554 - val_loss: 172.6981\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 157.7642 - val_loss: 170.9717\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.2590 - val_loss: 170.7825\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.7932 - val_loss: 170.7563\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.5318 - val_loss: 169.4246\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.5117 - val_loss: 169.5999\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.8445 - val_loss: 169.5888\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.3890 - val_loss: 168.4546\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.4188 - val_loss: 168.3867\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.7835 - val_loss: 167.8249\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.5795 - val_loss: 166.4423\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.1973 - val_loss: 167.0711\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.1325 - val_loss: 166.5742\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.1777 - val_loss: 164.6299\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 152.5887 - val_loss: 165.7865\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.5106 - val_loss: 165.3082\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.5660 - val_loss: 164.7449\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.0084 - val_loss: 164.2843\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.1425 - val_loss: 163.5367\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 151.3291 - val_loss: 163.3785\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.0994 - val_loss: 162.8214\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.4779 - val_loss: 162.3382\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.9294 - val_loss: 162.1840\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.7933 - val_loss: 161.7454\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 149.8290 - val_loss: 161.6942\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.0248 - val_loss: 160.4614\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.2103 - val_loss: 161.0045\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.5443 - val_loss: 160.4760\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.3582 - val_loss: 160.2318\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.4670 - val_loss: 159.4829\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.5688 - val_loss: 158.8997\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.8754 - val_loss: 159.4618\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.9840 - val_loss: 158.3145\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.5678 - val_loss: 158.4554\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.1539 - val_loss: 159.1052\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.3554 - val_loss: 157.8550\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.8174 - val_loss: 157.9964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.4532 - val_loss: 157.5531\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.4650 - val_loss: 157.8383\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.4348 - val_loss: 156.8536\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.9482 - val_loss: 156.4351\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.3963 - val_loss: 156.3801\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.9420 - val_loss: 156.4078\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.9950 - val_loss: 155.8812\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.7770 - val_loss: 155.5789\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.8579 - val_loss: 155.5084\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.3653 - val_loss: 155.0540\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.2622 - val_loss: 156.2881\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.6928 - val_loss: 154.2955\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.9059 - val_loss: 155.1661\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.3481 - val_loss: 154.5247\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.6965 - val_loss: 154.3890\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.4424 - val_loss: 153.9207\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.0382 - val_loss: 153.7263\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.1381 - val_loss: 153.8895\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.1568 - val_loss: 152.9198\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.6701 - val_loss: 153.3421\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.2921 - val_loss: 152.2909\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1545.6167 - val_loss: 1575.5093\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1520.5784 - val_loss: 1538.7405\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1467.3374 - val_loss: 1460.3215\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1358.4917 - val_loss: 1307.6627\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1157.7324 - val_loss: 1032.9357\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 832.9935 - val_loss: 652.9777\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 467.7852 - val_loss: 353.4718\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 267.1332 - val_loss: 287.5603\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 228.6195 - val_loss: 268.2176\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 214.8216 - val_loss: 254.4158\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 206.1895 - val_loss: 246.2382\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.9878 - val_loss: 239.6834\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.0767 - val_loss: 232.0842\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.7395 - val_loss: 224.3088\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.2598 - val_loss: 219.3738\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.9515 - val_loss: 216.0808\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.1590 - val_loss: 209.3329\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.7636 - val_loss: 205.8082\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.4649 - val_loss: 201.8585\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.6237 - val_loss: 198.5772\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.5487 - val_loss: 195.3183\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.4132 - val_loss: 191.4736\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.1553 - val_loss: 189.8990\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.5462 - val_loss: 185.8096\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 160.0737 - val_loss: 184.0739\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.9965 - val_loss: 181.3663\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.3799 - val_loss: 179.3420\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.9223 - val_loss: 176.9660\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.6348 - val_loss: 175.8284\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.7135 - val_loss: 174.2055\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.5519 - val_loss: 172.8793\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.5308 - val_loss: 170.4761\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.4075 - val_loss: 170.2498\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.5138 - val_loss: 169.1786\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.8866 - val_loss: 168.5528\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.8112 - val_loss: 167.5717\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.1624 - val_loss: 166.6015\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.7485 - val_loss: 165.3771\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.4437 - val_loss: 165.4617\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.3306 - val_loss: 163.6158\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.9479 - val_loss: 164.5137\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.5984 - val_loss: 162.3773\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.7347 - val_loss: 161.5322\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.2268 - val_loss: 161.8485\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.9465 - val_loss: 160.2168\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.8132 - val_loss: 159.9420\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.6346 - val_loss: 159.0453\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.5417 - val_loss: 159.9656\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.5263 - val_loss: 158.6373\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.8605 - val_loss: 157.3640\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.1872 - val_loss: 157.7920\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.7592 - val_loss: 156.7723\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.8643 - val_loss: 157.2120\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.1069 - val_loss: 154.9800\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.9651 - val_loss: 156.6233\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.1190 - val_loss: 154.7630\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.2481 - val_loss: 154.3619\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.9085 - val_loss: 154.4509\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.0026 - val_loss: 154.0489\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.3623 - val_loss: 154.8026\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.3012 - val_loss: 152.1376\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.3919 - val_loss: 153.0539\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.2873 - val_loss: 151.2553\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.7022 - val_loss: 152.0497\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.5495 - val_loss: 150.5111\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.1482 - val_loss: 150.6861\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.8428 - val_loss: 149.8304\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.5515 - val_loss: 151.6462\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.2325 - val_loss: 149.1663\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.3085 - val_loss: 149.0910\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.3729 - val_loss: 147.8369\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.9967 - val_loss: 150.9134\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.7344 - val_loss: 147.2151\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.2140 - val_loss: 147.7214\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.9601 - val_loss: 147.9092\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.4142 - val_loss: 147.3562\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.1635 - val_loss: 147.1371\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.8604 - val_loss: 146.5905\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.4997 - val_loss: 146.5716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.4491 - val_loss: 146.2711\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.2225 - val_loss: 146.0455\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.1474 - val_loss: 146.8483\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.5717 - val_loss: 145.7406\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.1858 - val_loss: 145.7808\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.8275 - val_loss: 144.5350\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 126.9131 - val_loss: 148.0467\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.8414 - val_loss: 145.0752\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.7448 - val_loss: 144.5692\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.3423 - val_loss: 144.4304\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.1163 - val_loss: 146.1986\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.4649 - val_loss: 144.6587\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.5837 - val_loss: 144.9759\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.8051 - val_loss: 144.7020\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.5812 - val_loss: 144.6728\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.8107 - val_loss: 143.7703\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.8521 - val_loss: 144.1113\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.2626 - val_loss: 145.7370\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.2526 - val_loss: 143.7583\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.4209 - val_loss: 143.3898\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.3690 - val_loss: 144.1973\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1581.6323 - val_loss: 1504.2448\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1545.7797 - val_loss: 1467.2762\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1491.1143 - val_loss: 1393.7000\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1377.2122 - val_loss: 1239.1611\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1157.6602 - val_loss: 963.7949\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 808.9121 - val_loss: 578.0485\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 423.7946 - val_loss: 284.5948\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 245.2161 - val_loss: 223.7369\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 224.5071 - val_loss: 213.3832\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 216.4203 - val_loss: 208.5894\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 210.6743 - val_loss: 203.2387\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 206.1975 - val_loss: 199.5945\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.9350 - val_loss: 196.5398\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.6785 - val_loss: 193.5597\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.9444 - val_loss: 191.6917\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.0306 - val_loss: 188.2708\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.0480 - val_loss: 187.0390\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.7903 - val_loss: 184.7722\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.5506 - val_loss: 183.0711\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.6309 - val_loss: 182.0457\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.4917 - val_loss: 179.7762\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.1384 - val_loss: 178.3011\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 179.2247 - val_loss: 176.4647\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.6810 - val_loss: 176.0816\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.6475 - val_loss: 173.9848\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.2870 - val_loss: 173.2204\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.7507 - val_loss: 170.9050\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.3397 - val_loss: 171.2886\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.3083 - val_loss: 168.9803\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.1173 - val_loss: 167.3921\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.2608 - val_loss: 166.9093\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.1006 - val_loss: 165.4654\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.6647 - val_loss: 164.6699\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.3263 - val_loss: 162.5721\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 164.5083 - val_loss: 161.2371\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.2326 - val_loss: 161.3018\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.6528 - val_loss: 159.4056\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.0066 - val_loss: 158.2753\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.5507 - val_loss: 157.4886\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.6925 - val_loss: 157.0234\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.2041 - val_loss: 155.1812\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.6592 - val_loss: 153.9748\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.0233 - val_loss: 153.1954\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.1061 - val_loss: 152.6097\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.0114 - val_loss: 151.6496\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.1626 - val_loss: 149.9719\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.5361 - val_loss: 150.5733\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.0837 - val_loss: 148.7060\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.8844 - val_loss: 147.9065\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.2477 - val_loss: 147.7138\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.8413 - val_loss: 146.1871\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.7395 - val_loss: 146.5143\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.2751 - val_loss: 145.2492\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.7113 - val_loss: 144.2878\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.8364 - val_loss: 143.5528\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.2225 - val_loss: 142.4800\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.3141 - val_loss: 142.3831\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.5965 - val_loss: 141.6168\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.3683 - val_loss: 140.7449\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.1762 - val_loss: 140.6842\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.4653 - val_loss: 139.4255\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.2773 - val_loss: 139.4710\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.0047 - val_loss: 139.3974\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.7788 - val_loss: 138.0728\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.8151 - val_loss: 138.4916\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.9240 - val_loss: 139.0289\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.9537 - val_loss: 136.8940\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.0617 - val_loss: 136.5977\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 137.8474 - val_loss: 137.5832\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.3977 - val_loss: 135.9849\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.2556 - val_loss: 136.0644\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.1624 - val_loss: 136.5003\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 136.0408 - val_loss: 135.8085\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.3269 - val_loss: 135.3065\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.6865 - val_loss: 136.0097\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.7131 - val_loss: 134.7917\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.2387 - val_loss: 134.6411\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.5488 - val_loss: 135.4057\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.7608 - val_loss: 134.9812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.1408 - val_loss: 134.9356\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.1214 - val_loss: 134.1436\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.2960 - val_loss: 134.7925\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.5140 - val_loss: 134.9082\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.9815 - val_loss: 134.0224\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.1544 - val_loss: 134.6040\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.3809 - val_loss: 134.0811\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.9330 - val_loss: 133.3576\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.5457 - val_loss: 133.3704\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.1817 - val_loss: 133.8542\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.5551 - val_loss: 133.2064\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.3748 - val_loss: 133.2248\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.7721 - val_loss: 133.4896\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.6945 - val_loss: 132.7935\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.4113 - val_loss: 133.3281\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.0432 - val_loss: 132.0511\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.7003 - val_loss: 133.0637\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.2984 - val_loss: 132.9628\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.0928 - val_loss: 131.1545\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.6174 - val_loss: 132.5521\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.4374 - val_loss: 131.5889\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1535.5260 - val_loss: 1539.6902\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1492.0750 - val_loss: 1479.4141\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1411.7432 - val_loss: 1368.5695\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1264.6904 - val_loss: 1172.9438\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1017.4421 - val_loss: 846.6638\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 651.3413 - val_loss: 449.0128\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 315.9734 - val_loss: 233.4853\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 225.5244 - val_loss: 220.1452\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.8551 - val_loss: 212.7721\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.1442 - val_loss: 207.4560\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.5984 - val_loss: 204.0149\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.0210 - val_loss: 202.1169\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.6328 - val_loss: 199.7577\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.8543 - val_loss: 198.0266\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.8105 - val_loss: 195.5485\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.2337 - val_loss: 193.8963\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.3289 - val_loss: 191.7655\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.4234 - val_loss: 190.8075\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.5089 - val_loss: 188.6590\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.8727 - val_loss: 187.3059\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.3800 - val_loss: 185.5910\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.1827 - val_loss: 184.2426\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.4872 - val_loss: 182.9640\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.5052 - val_loss: 181.5298\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 173.1381 - val_loss: 180.7331\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.5910 - val_loss: 179.2624\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.4873 - val_loss: 178.2540\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.5839 - val_loss: 177.4957\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.5341 - val_loss: 175.9758\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.3721 - val_loss: 175.0960\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.5509 - val_loss: 174.4859\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.8009 - val_loss: 172.1044\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.1192 - val_loss: 171.2883\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.6956 - val_loss: 171.2683\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.1389 - val_loss: 170.1567\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.0385 - val_loss: 168.2733\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.4958 - val_loss: 167.9107\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.2309 - val_loss: 166.3281\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.0522 - val_loss: 164.4109\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.3709 - val_loss: 164.0029\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.0076 - val_loss: 163.4993\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.6727 - val_loss: 162.9254\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.5265 - val_loss: 162.1474\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.5088 - val_loss: 161.5932\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.2942 - val_loss: 160.6651\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.2740 - val_loss: 159.1647\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.8103 - val_loss: 158.1085\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.6566 - val_loss: 157.7411\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 150.8151 - val_loss: 157.2972\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.2546 - val_loss: 156.2841\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.0097 - val_loss: 155.3840\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.0972 - val_loss: 154.8719\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.2982 - val_loss: 154.9818\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.7789 - val_loss: 153.4256\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.0423 - val_loss: 152.8072\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.2625 - val_loss: 153.0348\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.2144 - val_loss: 150.8867\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.4920 - val_loss: 150.7878\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.0989 - val_loss: 150.7908\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.8343 - val_loss: 149.5314\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.4275 - val_loss: 149.0281\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.2007 - val_loss: 148.6137\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.0293 - val_loss: 147.2000\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.5329 - val_loss: 147.9125\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.6850 - val_loss: 146.4382\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.7780 - val_loss: 146.3629\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.8172 - val_loss: 144.7177\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.8940 - val_loss: 144.6043\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.8138 - val_loss: 144.1941\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.9642 - val_loss: 144.0052\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.0907 - val_loss: 143.5615\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 137.9072 - val_loss: 144.0527\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.8321 - val_loss: 142.3557\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.0367 - val_loss: 142.9260\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.5940 - val_loss: 141.8027\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.8856 - val_loss: 141.7046\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.4980 - val_loss: 140.8014\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.6491 - val_loss: 142.0276\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.4681 - val_loss: 140.2926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.1356 - val_loss: 140.9364\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.1987 - val_loss: 139.6144\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 134.5558 - val_loss: 141.0810\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.3066 - val_loss: 139.0265\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.8440 - val_loss: 138.9747\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.7789 - val_loss: 138.3204\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 132.3551 - val_loss: 139.1497\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 132.3562 - val_loss: 137.7462\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 132.4374 - val_loss: 139.0857\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.8407 - val_loss: 137.7973\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 132.0535 - val_loss: 137.6286\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.9906 - val_loss: 138.1513\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.5977 - val_loss: 137.2406\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.6004 - val_loss: 137.1953\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.3865 - val_loss: 137.1350\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.6817 - val_loss: 136.8085\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.7739 - val_loss: 137.7582\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.4094 - val_loss: 136.5927\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.3680 - val_loss: 136.9324\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 129.5633 - val_loss: 136.0560\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.6971 - val_loss: 136.2724\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1476.5713 - val_loss: 1602.7946\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1408.9650 - val_loss: 1494.3740\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1255.7539 - val_loss: 1261.9951\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 959.3444 - val_loss: 858.6287\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 541.9902 - val_loss: 417.1734\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 280.4280 - val_loss: 285.3623\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 237.1293 - val_loss: 249.3882\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 215.5029 - val_loss: 234.1418\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 206.0667 - val_loss: 222.4516\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.7698 - val_loss: 216.4113\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.9244 - val_loss: 210.8730\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.3699 - val_loss: 206.7424\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.0005 - val_loss: 204.5737\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.2415 - val_loss: 200.7279\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.7195 - val_loss: 198.5543\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.2162 - val_loss: 196.1898\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.7752 - val_loss: 194.4797\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.6284 - val_loss: 191.9492\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.6605 - val_loss: 190.8083\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.2821 - val_loss: 188.7339\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.2099 - val_loss: 187.2459\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.1309 - val_loss: 185.0331\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.4813 - val_loss: 184.2928\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.1163 - val_loss: 181.9466\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.1663 - val_loss: 181.2559\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.2086 - val_loss: 178.8074\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.2013 - val_loss: 178.1534\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.5897 - val_loss: 176.8355\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.5298 - val_loss: 175.4091\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 159.4665 - val_loss: 173.8273\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.4230 - val_loss: 172.6329\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.1792 - val_loss: 171.9834\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.0515 - val_loss: 171.8586\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.3356 - val_loss: 169.0667\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.8020 - val_loss: 169.0502\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.8702 - val_loss: 166.9514\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8008 - val_loss: 165.8848\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.8898 - val_loss: 164.8642\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0175 - val_loss: 164.3357\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.9170 - val_loss: 163.1270\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.2842 - val_loss: 161.9702\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.1270 - val_loss: 160.9146\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.6865 - val_loss: 161.2972\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.4635 - val_loss: 158.9763\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.5804 - val_loss: 158.8491\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.9583 - val_loss: 157.6484\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.0909 - val_loss: 157.0286\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.7891 - val_loss: 155.5922\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.8934 - val_loss: 157.0258\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.1581 - val_loss: 155.0437\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.7351 - val_loss: 154.9277\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.2357 - val_loss: 154.1673\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.5909 - val_loss: 153.1687\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.0808 - val_loss: 154.4005\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.0029 - val_loss: 150.9704\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.6011 - val_loss: 152.5213\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.2330 - val_loss: 150.1803\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.3208 - val_loss: 150.3976\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.3775 - val_loss: 149.0774\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.2133 - val_loss: 149.3886\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.0251 - val_loss: 148.4250\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.1751 - val_loss: 150.5236\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.9965 - val_loss: 149.0657\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 134.4410 - val_loss: 146.7814\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.3730 - val_loss: 147.2966\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.8681 - val_loss: 148.4520\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.0938 - val_loss: 145.4527\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.2736 - val_loss: 147.3991\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.3926 - val_loss: 145.5519\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.2907 - val_loss: 145.8810\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.8341 - val_loss: 144.8003\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.7834 - val_loss: 144.4911\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.0776 - val_loss: 145.7394\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.5867 - val_loss: 143.7810\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 130.6749 - val_loss: 143.7261\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.0748 - val_loss: 144.7145\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.0204 - val_loss: 144.5229\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.2159 - val_loss: 143.9138\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.9847 - val_loss: 143.3244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.3286 - val_loss: 146.6223\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.1496 - val_loss: 143.6016\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.5124 - val_loss: 141.9156\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.1837 - val_loss: 143.2717\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.7775 - val_loss: 142.4937\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.9516 - val_loss: 141.7039\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.7694 - val_loss: 142.7648\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.5707 - val_loss: 142.9563\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.1985 - val_loss: 142.6972\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.7369 - val_loss: 142.2022\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.7593 - val_loss: 142.4653\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.3495 - val_loss: 142.7858\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.0147 - val_loss: 144.8886\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.1717 - val_loss: 140.5141\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.5468 - val_loss: 141.3701\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.7252 - val_loss: 141.4979\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.6643 - val_loss: 141.4927\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 125.7578 - val_loss: 141.3088\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.3466 - val_loss: 143.1790\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.0964 - val_loss: 140.9567\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.9635 - val_loss: 142.5099\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1564.6855 - val_loss: 1490.5480\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1524.9670 - val_loss: 1434.5179\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1436.3489 - val_loss: 1311.1519\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1246.8174 - val_loss: 1060.6676\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 899.6310 - val_loss: 664.4921\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 487.9379 - val_loss: 349.2407\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 296.7824 - val_loss: 272.7357\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 251.6636 - val_loss: 234.8382\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 224.0684 - val_loss: 218.8025\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.0857 - val_loss: 208.6148\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.0307 - val_loss: 204.2062\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.1267 - val_loss: 200.3583\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.9804 - val_loss: 197.5510\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.1150 - val_loss: 195.0355\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.1406 - val_loss: 193.3705\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.5580 - val_loss: 191.5345\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.9169 - val_loss: 189.8987\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.0454 - val_loss: 187.6180\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.4527 - val_loss: 185.9614\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.3400 - val_loss: 185.1669\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.7230 - val_loss: 182.9142\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.9756 - val_loss: 182.1942\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.4523 - val_loss: 180.2839\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.3566 - val_loss: 179.7377\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.7968 - val_loss: 178.6617\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.1253 - val_loss: 177.6560\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.3768 - val_loss: 176.2132\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.4273 - val_loss: 175.8885\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.1698 - val_loss: 174.2553\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.8832 - val_loss: 173.2585\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.3136 - val_loss: 172.4501\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.5885 - val_loss: 171.8821\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.5595 - val_loss: 170.3572\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.4772 - val_loss: 169.9193\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.7068 - val_loss: 169.5922\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.9366 - val_loss: 168.7686\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.9696 - val_loss: 167.3878\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.5578 - val_loss: 168.3894\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.1980 - val_loss: 165.2095\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 138.6299 - val_loss: 166.2690\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.7914 - val_loss: 164.5705\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.3607 - val_loss: 164.6212\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.4349 - val_loss: 163.0591\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.5857 - val_loss: 164.1595\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 133.4587 - val_loss: 163.1691\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.1796 - val_loss: 162.3160\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 132.2749 - val_loss: 160.4423\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 131.2235 - val_loss: 160.1881\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.4760 - val_loss: 160.3802\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.4104 - val_loss: 159.0653\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.4121 - val_loss: 159.8689\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.9742 - val_loss: 159.8316\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.9721 - val_loss: 159.6602\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.8745 - val_loss: 157.9562\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 126.1235 - val_loss: 157.7639\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.3851 - val_loss: 157.2028\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 125.1031 - val_loss: 156.5800\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.3049 - val_loss: 156.3597\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 123.5801 - val_loss: 155.9730\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 122.7968 - val_loss: 155.8182\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.6755 - val_loss: 154.3038\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 123.0055 - val_loss: 158.0060\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 122.4594 - val_loss: 153.7343\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 121.5681 - val_loss: 154.2852\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 121.2057 - val_loss: 153.2368\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 121.0716 - val_loss: 154.3054\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 120.5249 - val_loss: 153.5989\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 120.6703 - val_loss: 151.9760\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.3127 - val_loss: 153.2386\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.8374 - val_loss: 153.7439\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.5143 - val_loss: 151.2481\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.2106 - val_loss: 152.5873\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.1244 - val_loss: 150.7271\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.5834 - val_loss: 152.4468\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.1367 - val_loss: 151.2004\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.7061 - val_loss: 150.8529\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.1946 - val_loss: 151.9680\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.2596 - val_loss: 150.2656\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.5365 - val_loss: 153.7794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.2265 - val_loss: 149.7725\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.7038 - val_loss: 150.2300\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.8715 - val_loss: 149.2708\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.6656 - val_loss: 150.4301\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.9932 - val_loss: 149.8010\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.1053 - val_loss: 148.8858\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.9872 - val_loss: 149.5603\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.4817 - val_loss: 151.9574\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.7078 - val_loss: 149.5751\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.4411 - val_loss: 149.2174\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.0429 - val_loss: 150.8416\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.3494 - val_loss: 150.6583\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 116.2936 - val_loss: 148.9528\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.4583 - val_loss: 153.9919\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.9993 - val_loss: 148.7545\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.9276 - val_loss: 151.4265\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.0120 - val_loss: 149.6671\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.6200 - val_loss: 150.1020\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 116.8335 - val_loss: 150.3983\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 116.7519 - val_loss: 147.8734\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.0964 - val_loss: 150.1628\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 9ms/step - loss: 1581.7202 - val_loss: 1491.3358\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1552.8285 - val_loss: 1457.1663\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1504.4089 - val_loss: 1392.3657\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1412.4888 - val_loss: 1274.0150\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1248.6580 - val_loss: 1063.2717\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 967.6306 - val_loss: 730.5391\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 587.4359 - val_loss: 369.8410\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 305.1802 - val_loss: 234.7954\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 252.1889 - val_loss: 221.0338\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 235.0069 - val_loss: 212.2821\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 225.0910 - val_loss: 205.4442\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 217.4281 - val_loss: 199.7791\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 211.3343 - val_loss: 194.4981\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 206.0189 - val_loss: 190.1341\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.2783 - val_loss: 186.8381\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.9289 - val_loss: 183.9429\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.8438 - val_loss: 181.8475\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.5966 - val_loss: 178.2962\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.3713 - val_loss: 176.3422\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.6958 - val_loss: 173.7859\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.6295 - val_loss: 173.2517\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.1443 - val_loss: 170.6230\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.2503 - val_loss: 169.1176\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.4202 - val_loss: 167.3431\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 178.4322 - val_loss: 165.8177\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.2830 - val_loss: 164.5240\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.8081 - val_loss: 163.6633\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.2761 - val_loss: 162.5221\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.3554 - val_loss: 161.6371\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.7849 - val_loss: 160.1722\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.4315 - val_loss: 158.7240\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.1712 - val_loss: 157.7814\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 167.0990 - val_loss: 157.6506\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.2577 - val_loss: 155.2435\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.3713 - val_loss: 154.3034\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.0648 - val_loss: 154.1083\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.9923 - val_loss: 152.8528\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.5273 - val_loss: 152.2995\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 159.8576 - val_loss: 151.2841\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.8257 - val_loss: 150.7969\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.0558 - val_loss: 149.9469\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.9264 - val_loss: 149.6654\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.3077 - val_loss: 148.1730\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.5105 - val_loss: 148.8883\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.5040 - val_loss: 147.2214\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.2435 - val_loss: 146.4298\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.5269 - val_loss: 145.9891\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.0614 - val_loss: 145.3708\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.9340 - val_loss: 145.5059\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 150.1768 - val_loss: 143.9123\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.7310 - val_loss: 144.3187\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.0609 - val_loss: 143.0077\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.4104 - val_loss: 142.9274\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.3329 - val_loss: 141.8312\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.4525 - val_loss: 142.0721\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.3805 - val_loss: 141.7363\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.7626 - val_loss: 140.5772\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.3864 - val_loss: 141.8803\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.5414 - val_loss: 140.3155\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.4661 - val_loss: 139.8766\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.4941 - val_loss: 140.1053\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.0980 - val_loss: 139.5986\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.8397 - val_loss: 138.6834\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.2970 - val_loss: 141.0365\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.1873 - val_loss: 140.3510\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.5008 - val_loss: 139.4737\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.9136 - val_loss: 139.1340\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.2487 - val_loss: 139.0874\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.9117 - val_loss: 137.2436\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.2540 - val_loss: 138.3352\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 138.3891 - val_loss: 138.3133\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.0688 - val_loss: 137.4577\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.7384 - val_loss: 137.5145\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.4758 - val_loss: 137.8857\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.4152 - val_loss: 137.9184\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 136.0838 - val_loss: 137.8104\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.6340 - val_loss: 137.0359\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.7802 - val_loss: 137.6770\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.0212 - val_loss: 136.8196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.6643 - val_loss: 138.6285\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.9385 - val_loss: 137.1912\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.4229 - val_loss: 139.4186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.0829 - val_loss: 137.6424\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.6663 - val_loss: 136.9751\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.1704 - val_loss: 137.6274\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.9305 - val_loss: 137.1004\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.5280 - val_loss: 137.7078\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 131.1359 - val_loss: 137.1381\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.9588 - val_loss: 138.2141\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.8622 - val_loss: 136.9474\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.1664 - val_loss: 137.9888\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.3450 - val_loss: 137.7510\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.6605 - val_loss: 137.8743\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.9980 - val_loss: 138.3263\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.7355 - val_loss: 137.2498\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.6454 - val_loss: 137.6497\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.3635 - val_loss: 137.5979\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.3733 - val_loss: 138.5061\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.4710 - val_loss: 137.2982\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.1499 - val_loss: 137.6161\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1546.7615 - val_loss: 1519.3795\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1514.1716 - val_loss: 1472.5844\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1444.0465 - val_loss: 1369.9105\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1288.4963 - val_loss: 1147.6189\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 979.7758 - val_loss: 759.9315\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 549.9037 - val_loss: 349.9248\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 268.6917 - val_loss: 241.9798\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 218.3691 - val_loss: 220.1309\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.4601 - val_loss: 213.7090\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.9351 - val_loss: 209.7034\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.3575 - val_loss: 207.5018\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.1351 - val_loss: 205.9306\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.7489 - val_loss: 203.3601\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.6694 - val_loss: 201.4886\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.9566 - val_loss: 200.4350\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.2225 - val_loss: 198.6500\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.9576 - val_loss: 197.4010\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.7943 - val_loss: 196.2833\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.8258 - val_loss: 195.5022\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.9788 - val_loss: 193.5546\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.5909 - val_loss: 192.6731\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.5047 - val_loss: 192.2780\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.0318 - val_loss: 190.9806\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.8931 - val_loss: 189.6041\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.6789 - val_loss: 189.0604\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 165.6028 - val_loss: 187.6733\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.3600 - val_loss: 186.6532\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.6852 - val_loss: 185.6327\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.2677 - val_loss: 184.2843\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.6787 - val_loss: 184.1181\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.7997 - val_loss: 182.5513\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.8887 - val_loss: 182.2585\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.2849 - val_loss: 181.0778\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.7209 - val_loss: 180.1463\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.0839 - val_loss: 179.8076\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.7532 - val_loss: 178.9236\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.8654 - val_loss: 178.0246\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.8359 - val_loss: 178.3955\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.9626 - val_loss: 176.0635\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.3819 - val_loss: 175.5707\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.8355 - val_loss: 174.6012\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.6300 - val_loss: 173.7355\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 151.9206 - val_loss: 173.0839\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.4561 - val_loss: 172.3519\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.4278 - val_loss: 171.5496\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.2464 - val_loss: 171.4304\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.5085 - val_loss: 170.3044\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.6535 - val_loss: 169.7438\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.5395 - val_loss: 169.2678\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.6980 - val_loss: 168.4125\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.3905 - val_loss: 168.0198\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.5771 - val_loss: 167.0284\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.1767 - val_loss: 166.3554\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.7149 - val_loss: 166.0243\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.4875 - val_loss: 165.6231\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.5065 - val_loss: 164.9591\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.3921 - val_loss: 164.7815\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.6322 - val_loss: 164.4428\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.9209 - val_loss: 163.7609\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.6677 - val_loss: 163.4084\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 140.5284 - val_loss: 162.4339\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.9565 - val_loss: 162.7957\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.5299 - val_loss: 161.7027\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.8287 - val_loss: 161.7669\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.8155 - val_loss: 161.1847\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.2631 - val_loss: 161.1621\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.1528 - val_loss: 159.9153\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.8763 - val_loss: 159.4793\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.2181 - val_loss: 159.3647\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.6114 - val_loss: 159.4121\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.8549 - val_loss: 159.5311\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.1057 - val_loss: 158.5900\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.9267 - val_loss: 158.1328\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.7876 - val_loss: 157.3550\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.1842 - val_loss: 157.5034\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.7264 - val_loss: 156.4828\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.6001 - val_loss: 156.3774\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.0288 - val_loss: 156.9465\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.3952 - val_loss: 155.4962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.8678 - val_loss: 155.8286\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.4997 - val_loss: 154.6992\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.9961 - val_loss: 154.7000\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.6409 - val_loss: 154.1889\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.4061 - val_loss: 154.1283\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.7103 - val_loss: 153.7400\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.7106 - val_loss: 153.7651\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.0731 - val_loss: 153.1350\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.0306 - val_loss: 152.5151\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.1395 - val_loss: 152.4528\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.0777 - val_loss: 152.6284\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.1039 - val_loss: 151.9182\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.5410 - val_loss: 152.8695\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.4418 - val_loss: 151.6319\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 128.5591 - val_loss: 151.7418\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.5789 - val_loss: 150.8842\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.4776 - val_loss: 150.4087\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.0619 - val_loss: 150.1862\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.7532 - val_loss: 150.0202\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.2459 - val_loss: 150.0610\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.8548 - val_loss: 150.2241\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1560.0569 - val_loss: 1552.1370\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1546.4991 - val_loss: 1534.8103\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1521.2656 - val_loss: 1499.3734\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1466.5338 - val_loss: 1420.3098\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1353.1910 - val_loss: 1266.8064\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1145.3225 - val_loss: 1003.0711\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 823.3393 - val_loss: 629.8825\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 453.3243 - val_loss: 321.4938\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 251.6201 - val_loss: 241.4779\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 219.0534 - val_loss: 227.2092\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.7959 - val_loss: 221.4254\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.0215 - val_loss: 217.7764\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.7163 - val_loss: 213.7437\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.9489 - val_loss: 210.8482\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.3706 - val_loss: 208.7934\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.8721 - val_loss: 206.3739\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.3112 - val_loss: 204.6421\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.3812 - val_loss: 202.6324\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.8747 - val_loss: 201.0416\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.5313 - val_loss: 199.7634\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.1035 - val_loss: 197.7376\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.7562 - val_loss: 196.3535\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.4400 - val_loss: 195.1653\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 173.5709 - val_loss: 193.4585\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 172.3903 - val_loss: 192.7025\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.4693 - val_loss: 191.0791\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.5505 - val_loss: 189.8679\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 168.1450 - val_loss: 189.0966\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.2128 - val_loss: 188.1309\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.2051 - val_loss: 187.5077\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.8800 - val_loss: 185.9916\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 164.2165 - val_loss: 185.2516\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.9535 - val_loss: 184.1551\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 161.5794 - val_loss: 183.4561\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 160.3309 - val_loss: 182.9766\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 159.7463 - val_loss: 182.5141\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.7068 - val_loss: 181.8652\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.4982 - val_loss: 180.7052\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 157.1859 - val_loss: 180.3250\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 155.9200 - val_loss: 179.8607\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 155.3428 - val_loss: 178.7005\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 154.3436 - val_loss: 178.6782\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.0637 - val_loss: 177.8272\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.3637 - val_loss: 177.7294\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 152.6434 - val_loss: 177.0588\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.4172 - val_loss: 176.1148\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.1280 - val_loss: 176.0232\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.3141 - val_loss: 175.4399\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.9543 - val_loss: 174.4383\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 149.6867 - val_loss: 174.6227\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 149.5641 - val_loss: 174.1836\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 148.1463 - val_loss: 173.4332\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.4305 - val_loss: 173.0245\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 147.0787 - val_loss: 172.6145\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.9476 - val_loss: 172.6699\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.8933 - val_loss: 171.9188\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.5635 - val_loss: 171.6224\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 144.2030 - val_loss: 171.0438\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.4047 - val_loss: 171.4097\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.1982 - val_loss: 170.9834\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.0914 - val_loss: 170.1543\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.4714 - val_loss: 170.1440\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.0210 - val_loss: 169.6072\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.5077 - val_loss: 169.2864\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 139.9599 - val_loss: 169.4958\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.0159 - val_loss: 168.6804\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.2821 - val_loss: 168.1893\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.4454 - val_loss: 167.7582\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.1885 - val_loss: 167.7802\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.4379 - val_loss: 167.0548\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.5292 - val_loss: 166.4064\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.5989 - val_loss: 167.0812\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.0228 - val_loss: 166.4448\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.4062 - val_loss: 166.0590\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.1544 - val_loss: 165.7850\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.5564 - val_loss: 165.6168\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.9061 - val_loss: 165.0881\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.3901 - val_loss: 164.5413\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 132.0841 - val_loss: 164.4365\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.3418 - val_loss: 164.4465\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.9089 - val_loss: 163.8049\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.9760 - val_loss: 162.9199\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.9580 - val_loss: 164.3904\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.0089 - val_loss: 163.9378\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.2314 - val_loss: 162.4547\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.2028 - val_loss: 162.5367\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.5724 - val_loss: 162.2197\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.5512 - val_loss: 162.5104\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.3727 - val_loss: 161.6056\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.9647 - val_loss: 161.7399\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.9062 - val_loss: 161.4094\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.0871 - val_loss: 161.5960\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.5354 - val_loss: 161.0179\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.5667 - val_loss: 160.8648\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.6221 - val_loss: 161.3765\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.7428 - val_loss: 160.8917\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.4279 - val_loss: 160.9540\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 125.7757 - val_loss: 160.4144\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.7770 - val_loss: 160.1815\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.8346 - val_loss: 160.5748\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1562.2247 - val_loss: 1507.4359\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1531.7316 - val_loss: 1467.3240\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1469.4935 - val_loss: 1380.2363\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1335.4905 - val_loss: 1196.3724\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1048.8062 - val_loss: 813.6962\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 564.2323 - val_loss: 353.2925\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 264.8800 - val_loss: 268.4835\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 236.7829 - val_loss: 243.0162\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 225.3959 - val_loss: 230.2949\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 215.6266 - val_loss: 218.1779\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 208.1352 - val_loss: 211.3952\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 201.7746 - val_loss: 205.7638\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.7531 - val_loss: 198.8927\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.9934 - val_loss: 194.1930\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.3612 - val_loss: 190.8758\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.6589 - val_loss: 187.4405\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.9322 - val_loss: 185.1872\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.5636 - val_loss: 182.1005\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 173.1394 - val_loss: 179.6648\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.7426 - val_loss: 177.9097\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.7757 - val_loss: 174.7424\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.6846 - val_loss: 172.4542\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.3794 - val_loss: 171.1423\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.2899 - val_loss: 169.1590\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.6788 - val_loss: 166.6724\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.0955 - val_loss: 165.3801\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.9450 - val_loss: 164.0852\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.6756 - val_loss: 162.6976\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.6207 - val_loss: 159.1835\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.9030 - val_loss: 159.4775\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.7720 - val_loss: 158.3900\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.5638 - val_loss: 157.5024\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.3561 - val_loss: 156.3189\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.8839 - val_loss: 155.4442\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.2696 - val_loss: 153.0743\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.1358 - val_loss: 155.1107\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.0699 - val_loss: 152.2503\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.9400 - val_loss: 151.0381\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.2967 - val_loss: 152.1682\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.2554 - val_loss: 151.6258\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.1212 - val_loss: 150.4692\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.9597 - val_loss: 148.8620\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.8499 - val_loss: 148.7194\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.1384 - val_loss: 148.8837\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.5768 - val_loss: 149.2883\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.9435 - val_loss: 147.9183\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.9265 - val_loss: 147.3942\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.4445 - val_loss: 146.7415\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.6950 - val_loss: 146.1653\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.3907 - val_loss: 146.7130\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.5459 - val_loss: 145.1920\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.0834 - val_loss: 145.0043\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.3842 - val_loss: 145.7485\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.1243 - val_loss: 145.0536\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.0281 - val_loss: 144.6226\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.8674 - val_loss: 145.3033\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.7451 - val_loss: 143.4526\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.4572 - val_loss: 144.7209\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.1413 - val_loss: 144.7029\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.2598 - val_loss: 144.1153\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 133.0871 - val_loss: 143.4632\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.3935 - val_loss: 143.1911\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.4889 - val_loss: 142.4343\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.3981 - val_loss: 143.1314\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.1933 - val_loss: 142.7556\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.7212 - val_loss: 143.5595\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.4113 - val_loss: 141.8500\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.4178 - val_loss: 142.5968\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.1886 - val_loss: 141.8503\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.5705 - val_loss: 141.8287\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.4429 - val_loss: 142.2350\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.3307 - val_loss: 142.4524\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.7448 - val_loss: 141.1514\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.3649 - val_loss: 140.9895\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.0524 - val_loss: 141.4682\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.1107 - val_loss: 142.4909\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.4475 - val_loss: 142.1273\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.6974 - val_loss: 141.4835\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.8716 - val_loss: 141.2849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.6562 - val_loss: 142.5153\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.0421 - val_loss: 141.0551\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.1980 - val_loss: 141.8801\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.4312 - val_loss: 140.5120\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.7428 - val_loss: 140.8869\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.4671 - val_loss: 139.8941\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.6123 - val_loss: 140.8683\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.4041 - val_loss: 141.5104\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.4622 - val_loss: 139.6602\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.3706 - val_loss: 140.4035\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.6578 - val_loss: 138.5120\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.5675 - val_loss: 139.6213\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.0227 - val_loss: 139.4731\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.4764 - val_loss: 139.6842\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.5154 - val_loss: 138.2480\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.0197 - val_loss: 140.1531\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.7826 - val_loss: 139.2271\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.3797 - val_loss: 139.6398\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.3679 - val_loss: 139.8674\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.0294 - val_loss: 138.3369\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.2452 - val_loss: 140.3400\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1547.0771 - val_loss: 1598.8129\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1527.7545 - val_loss: 1580.1171\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1504.8204 - val_loss: 1549.8744\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1464.0884 - val_loss: 1492.8458\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1383.6921 - val_loss: 1377.8065\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1216.6088 - val_loss: 1135.3251\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 896.8573 - val_loss: 729.6785\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 478.2811 - val_loss: 347.2753\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 267.8849 - val_loss: 259.8839\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 236.5984 - val_loss: 231.7985\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 219.9625 - val_loss: 217.2121\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.1651 - val_loss: 208.1237\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 206.5553 - val_loss: 201.7627\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.3880 - val_loss: 197.1674\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.6376 - val_loss: 193.0204\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.2405 - val_loss: 188.8219\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.3803 - val_loss: 186.9507\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.7665 - val_loss: 183.2005\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.9230 - val_loss: 182.4680\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.6126 - val_loss: 178.7885\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.1260 - val_loss: 176.3498\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.8442 - val_loss: 174.0445\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.7129 - val_loss: 172.7119\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.3452 - val_loss: 170.8596\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.7422 - val_loss: 170.7119\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.2105 - val_loss: 167.7782\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.2865 - val_loss: 166.7994\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.2842 - val_loss: 164.6427\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.9784 - val_loss: 164.3178\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.2734 - val_loss: 161.4604\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.4907 - val_loss: 161.2174\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.6825 - val_loss: 159.6786\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.3878 - val_loss: 156.6330\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.9948 - val_loss: 156.3926\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.5791 - val_loss: 154.6431\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 161.5231 - val_loss: 153.7654\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.6975 - val_loss: 153.1513\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.4575 - val_loss: 152.0533\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.7005 - val_loss: 149.4060\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.0103 - val_loss: 148.6531\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.7736 - val_loss: 148.4330\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.5618 - val_loss: 145.7125\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.4696 - val_loss: 145.6846\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.8895 - val_loss: 143.4146\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.2045 - val_loss: 142.3048\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.6846 - val_loss: 141.6463\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.8109 - val_loss: 140.8010\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.6652 - val_loss: 139.3395\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.0080 - val_loss: 137.9243\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.5461 - val_loss: 139.4405\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.0870 - val_loss: 135.8797\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.6488 - val_loss: 136.7753\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.4239 - val_loss: 133.3062\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.4711 - val_loss: 136.1388\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.9140 - val_loss: 133.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.0679 - val_loss: 133.4752\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.8643 - val_loss: 131.2212\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.0950 - val_loss: 130.0952\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.9832 - val_loss: 132.3345\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.1278 - val_loss: 128.4381\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.6884 - val_loss: 128.9130\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.5617 - val_loss: 127.5094\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.1969 - val_loss: 127.4568\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.7342 - val_loss: 126.6593\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.3174 - val_loss: 128.0492\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.7132 - val_loss: 126.4351\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.9403 - val_loss: 126.4482\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.8345 - val_loss: 126.2768\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.4447 - val_loss: 125.2534\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.1458 - val_loss: 124.8083\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.4843 - val_loss: 125.6002\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.8901 - val_loss: 124.1634\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.3651 - val_loss: 123.4787\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.1448 - val_loss: 123.9849\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.5316 - val_loss: 124.5188\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 126.5475 - val_loss: 123.4036\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.5234 - val_loss: 123.7672\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.1814 - val_loss: 122.8704\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 126.6133 - val_loss: 123.8933\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.3821 - val_loss: 123.5862\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.2914 - val_loss: 123.2431\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.5754 - val_loss: 123.4774\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.1912 - val_loss: 122.3243\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.2352 - val_loss: 123.6227\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.3717 - val_loss: 124.0638\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.6627 - val_loss: 123.1862\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.5672 - val_loss: 124.3351\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.8702 - val_loss: 123.9332\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.1619 - val_loss: 122.9977\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.8938 - val_loss: 123.8801\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.1999 - val_loss: 123.0941\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.4590 - val_loss: 123.9684\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.1805 - val_loss: 123.4630\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.6928 - val_loss: 123.1849\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.6220 - val_loss: 125.0205\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.7767 - val_loss: 124.3706\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.8958 - val_loss: 123.9915\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.4388 - val_loss: 123.0833\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.5098 - val_loss: 124.6192\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.6469 - val_loss: 124.3540\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1560.4277 - val_loss: 1468.4030\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1506.9218 - val_loss: 1394.7753\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1390.3419 - val_loss: 1238.7134\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1161.8724 - val_loss: 937.3455\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 787.0753 - val_loss: 537.8671\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 403.5388 - val_loss: 274.3023\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 244.3291 - val_loss: 224.0402\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.2167 - val_loss: 215.3131\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.5992 - val_loss: 211.3604\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.7239 - val_loss: 208.6053\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.7416 - val_loss: 204.9805\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.3315 - val_loss: 202.1143\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.2216 - val_loss: 197.7739\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.9915 - val_loss: 197.5403\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.6996 - val_loss: 194.1908\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.9503 - val_loss: 192.2106\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.5561 - val_loss: 191.2232\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.7059 - val_loss: 188.4453\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.7681 - val_loss: 186.9044\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.2178 - val_loss: 185.2388\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.8336 - val_loss: 183.8117\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.1907 - val_loss: 181.9304\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.4521 - val_loss: 181.3688\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.1800 - val_loss: 179.8286\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.7026 - val_loss: 176.8532\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.8991 - val_loss: 176.4119\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.6585 - val_loss: 174.4725\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.9275 - val_loss: 172.9442\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 156.8739 - val_loss: 171.7509\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.0168 - val_loss: 169.2255\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.9333 - val_loss: 168.9244\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.1632 - val_loss: 166.7733\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.8601 - val_loss: 164.4689\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.3758 - val_loss: 163.8830\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.8394 - val_loss: 162.6086\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.0381 - val_loss: 160.3288\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.0123 - val_loss: 158.9048\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.4489 - val_loss: 158.0886\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.3026 - val_loss: 158.2776\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.3212 - val_loss: 157.2648\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.2026 - val_loss: 155.2577\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.3860 - val_loss: 154.4968\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.2948 - val_loss: 153.7046\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.4212 - val_loss: 153.0905\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.0973 - val_loss: 151.8944\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.1769 - val_loss: 151.0672\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.1820 - val_loss: 150.1118\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.3595 - val_loss: 149.6532\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.6936 - val_loss: 149.0146\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.6429 - val_loss: 148.6635\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.5254 - val_loss: 148.7411\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.4048 - val_loss: 147.0448\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.9864 - val_loss: 147.3384\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.1561 - val_loss: 145.8580\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.9475 - val_loss: 146.3743\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.3104 - val_loss: 145.5169\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.9720 - val_loss: 145.2243\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.2242 - val_loss: 144.8448\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.3675 - val_loss: 144.1969\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.1567 - val_loss: 143.1537\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.2678 - val_loss: 143.6193\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.4877 - val_loss: 143.1304\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.5706 - val_loss: 143.3802\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.0433 - val_loss: 143.6622\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.9135 - val_loss: 142.5568\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.8924 - val_loss: 145.1544\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.8762 - val_loss: 141.2365\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.6902 - val_loss: 142.3536\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.3342 - val_loss: 143.5239\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.3750 - val_loss: 140.9198\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.2753 - val_loss: 141.8706\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.7794 - val_loss: 141.7316\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.0653 - val_loss: 140.8702\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.0568 - val_loss: 141.1774\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.9627 - val_loss: 142.0361\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 123.3347 - val_loss: 140.4624\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.1338 - val_loss: 140.2106\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 123.2029 - val_loss: 139.8542\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.2268 - val_loss: 140.5111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.2284 - val_loss: 138.8399\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 122.5174 - val_loss: 141.7717\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 122.7435 - val_loss: 139.8299\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 122.6957 - val_loss: 139.8107\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 121.4434 - val_loss: 139.7501\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.9144 - val_loss: 139.2572\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 121.5200 - val_loss: 139.9671\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 120.8686 - val_loss: 139.2842\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.3004 - val_loss: 139.2452\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 120.8145 - val_loss: 140.9659\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.6894 - val_loss: 139.9375\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.0232 - val_loss: 138.9781\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.4209 - val_loss: 141.2145\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.8505 - val_loss: 139.4504\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 120.8160 - val_loss: 139.5210\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.3327 - val_loss: 139.1357\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.0510 - val_loss: 144.2984\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.6121 - val_loss: 139.1138\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 121.4455 - val_loss: 139.1590\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.2825 - val_loss: 141.5598\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.8652 - val_loss: 140.1918\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1588.9376 - val_loss: 1466.3523\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1561.3099 - val_loss: 1420.3048\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1499.9258 - val_loss: 1333.8149\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1386.4242 - val_loss: 1174.7645\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1177.3223 - val_loss: 898.0605\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 841.0886 - val_loss: 516.5615\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 450.6022 - val_loss: 271.1863\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 269.1703 - val_loss: 282.5663\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 231.9974 - val_loss: 261.6961\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 219.4811 - val_loss: 257.6022\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.4650 - val_loss: 253.0140\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.3331 - val_loss: 247.5524\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.0516 - val_loss: 241.1628\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.0189 - val_loss: 232.8972\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.3009 - val_loss: 229.8269\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.2305 - val_loss: 224.7783\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.3210 - val_loss: 221.4238\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.5464 - val_loss: 213.3444\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.9664 - val_loss: 214.4157\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.4172 - val_loss: 207.9991\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.2877 - val_loss: 201.2498\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.4784 - val_loss: 201.2835\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.9688 - val_loss: 198.8039\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.1689 - val_loss: 195.9902\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.4537 - val_loss: 192.6451\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.5139 - val_loss: 192.3607\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.0496 - val_loss: 187.6466\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.7762 - val_loss: 186.4119\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.8513 - val_loss: 183.2943\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.0063 - val_loss: 181.2349\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.2895 - val_loss: 180.1567\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.4948 - val_loss: 178.7830\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.0748 - val_loss: 179.6694\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.8658 - val_loss: 176.5260\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.3449 - val_loss: 174.2099\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.1735 - val_loss: 173.5691\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.2269 - val_loss: 171.0527\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.5338 - val_loss: 170.0863\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.2338 - val_loss: 170.5251\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.7657 - val_loss: 168.2026\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.7905 - val_loss: 166.2577\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.0521 - val_loss: 164.8865\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0329 - val_loss: 165.9593\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.3534 - val_loss: 163.1700\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.1181 - val_loss: 163.9335\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.7392 - val_loss: 160.7875\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.2383 - val_loss: 160.2346\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.3910 - val_loss: 160.7538\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.0589 - val_loss: 160.0443\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.3434 - val_loss: 158.8954\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.9907 - val_loss: 158.1998\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.7471 - val_loss: 155.9794\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.4709 - val_loss: 157.9462\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.6378 - val_loss: 155.9734\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.7791 - val_loss: 154.2597\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.3888 - val_loss: 153.5538\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.2243 - val_loss: 152.8734\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.5296 - val_loss: 153.9695\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.0319 - val_loss: 152.9346\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.5187 - val_loss: 151.5899\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.6730 - val_loss: 151.6584\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.9696 - val_loss: 152.0310\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.6608 - val_loss: 151.4253\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.3601 - val_loss: 151.1316\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.7101 - val_loss: 149.2381\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.2424 - val_loss: 149.1533\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.0176 - val_loss: 147.8127\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.4044 - val_loss: 147.7391\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.7063 - val_loss: 149.9521\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.7645 - val_loss: 147.4627\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.3802 - val_loss: 147.5302\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.1889 - val_loss: 146.7275\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.4208 - val_loss: 146.7975\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.6565 - val_loss: 144.8148\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.5494 - val_loss: 146.1605\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.8576 - val_loss: 145.4698\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.5168 - val_loss: 145.9823\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.2427 - val_loss: 144.7953\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.0782 - val_loss: 146.0082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.5489 - val_loss: 143.8113\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.0599 - val_loss: 145.0774\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.4460 - val_loss: 143.6891\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.4721 - val_loss: 142.3805\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.3462 - val_loss: 144.0132\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.5619 - val_loss: 144.3605\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.5139 - val_loss: 141.6056\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.9161 - val_loss: 141.9458\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.5047 - val_loss: 142.3004\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.7297 - val_loss: 141.6892\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.1416 - val_loss: 141.3728\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.1901 - val_loss: 140.8561\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.1193 - val_loss: 141.5038\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.6495 - val_loss: 142.8935\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.2823 - val_loss: 142.3460\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.2723 - val_loss: 141.2429\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.1756 - val_loss: 141.3413\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.8218 - val_loss: 140.2479\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.3176 - val_loss: 141.0329\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.1994 - val_loss: 140.8776\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.5579 - val_loss: 139.2448\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 10ms/step - loss: 1518.5288 - val_loss: 1602.4774\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1486.1179 - val_loss: 1552.2899\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1413.6464 - val_loss: 1438.9590\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1255.3733 - val_loss: 1196.0765\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 955.4210 - val_loss: 808.9136\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 591.2961 - val_loss: 443.7450\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 369.5432 - val_loss: 275.9703\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 269.9883 - val_loss: 215.9327\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 227.6616 - val_loss: 199.9667\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 213.6691 - val_loss: 190.6823\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.7590 - val_loss: 188.1782\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.9259 - val_loss: 183.5010\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.8622 - val_loss: 182.6241\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.2463 - val_loss: 180.0338\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 190.5676 - val_loss: 176.6165\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.7326 - val_loss: 176.2758\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.9769 - val_loss: 172.7325\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.6050 - val_loss: 170.6502\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.9178 - val_loss: 170.7436\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.5952 - val_loss: 168.3114\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.9427 - val_loss: 166.3969\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.0820 - val_loss: 167.7321\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 169.6318 - val_loss: 164.6114\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.0815 - val_loss: 162.5066\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.9595 - val_loss: 161.9906\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.5872 - val_loss: 160.6916\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.5748 - val_loss: 159.4558\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.7065 - val_loss: 158.5313\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.2724 - val_loss: 158.2228\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.4257 - val_loss: 155.9231\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.8351 - val_loss: 155.8394\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.4598 - val_loss: 155.4272\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.7640 - val_loss: 152.8240\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.4014 - val_loss: 152.6217\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.2368 - val_loss: 151.8368\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.7144 - val_loss: 151.2747\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.3621 - val_loss: 149.1977\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.6193 - val_loss: 148.5404\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 140.3693 - val_loss: 149.3726\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.1965 - val_loss: 147.2340\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.8052 - val_loss: 147.6463\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.7990 - val_loss: 146.9296\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.4708 - val_loss: 145.5768\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.9332 - val_loss: 146.6809\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.8175 - val_loss: 144.3860\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.1568 - val_loss: 144.6611\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.3826 - val_loss: 142.9748\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.6773 - val_loss: 145.1052\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.5055 - val_loss: 144.0512\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.0177 - val_loss: 146.3275\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.7189 - val_loss: 142.0954\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.0750 - val_loss: 143.2683\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.8833 - val_loss: 142.8896\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.0834 - val_loss: 142.8478\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.3716 - val_loss: 142.2154\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.8143 - val_loss: 142.4209\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.8072 - val_loss: 142.6722\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.8732 - val_loss: 144.9503\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.3783 - val_loss: 141.1035\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.9088 - val_loss: 142.8249\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.6402 - val_loss: 142.6419\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.6818 - val_loss: 141.7769\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.2974 - val_loss: 142.4334\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 123.5815 - val_loss: 142.3948\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.8077 - val_loss: 144.3471\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.6738 - val_loss: 141.5401\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.3612 - val_loss: 143.0445\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.5758 - val_loss: 144.1690\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.0652 - val_loss: 142.5397\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 119.8861 - val_loss: 141.5594\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.2311 - val_loss: 141.3266\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.1164 - val_loss: 142.0770\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.5472 - val_loss: 146.6924\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.6636 - val_loss: 141.3201\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.2250 - val_loss: 141.9209\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.8093 - val_loss: 143.5293\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.1324 - val_loss: 141.9629\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.2259 - val_loss: 142.2933\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.7498 - val_loss: 141.7452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.4091 - val_loss: 143.4440\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.6250 - val_loss: 142.8192\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.2624 - val_loss: 142.8185\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.1141 - val_loss: 144.3431\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.0776 - val_loss: 143.7725\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.7194 - val_loss: 142.0408\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.4177 - val_loss: 142.4494\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.5006 - val_loss: 144.4863\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.8726 - val_loss: 141.7047\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.5108 - val_loss: 142.9471\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.7923 - val_loss: 143.4492\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.5199 - val_loss: 143.9840\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.2865 - val_loss: 143.8289\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.1850 - val_loss: 143.5339\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.4927 - val_loss: 146.2931\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.2952 - val_loss: 141.9674\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.7683 - val_loss: 142.6841\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.5105 - val_loss: 144.2989\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.1317 - val_loss: 141.8362\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.4668 - val_loss: 145.2802\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 113.9146 - val_loss: 142.9343\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 9ms/step - loss: 1492.9799 - val_loss: 1677.9392\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1459.1072 - val_loss: 1627.6104\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1394.9076 - val_loss: 1528.7322\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1271.3073 - val_loss: 1344.6969\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1049.8103 - val_loss: 1028.2770\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 711.9590 - val_loss: 636.4625\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 410.9476 - val_loss: 404.9805\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 279.9056 - val_loss: 317.7143\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 232.3978 - val_loss: 278.1998\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 211.2589 - val_loss: 259.0467\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 201.0289 - val_loss: 244.5003\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.6322 - val_loss: 236.7970\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.5080 - val_loss: 229.4910\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.3558 - val_loss: 224.1344\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.2816 - val_loss: 220.3821\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.0255 - val_loss: 216.6400\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.1413 - val_loss: 213.0888\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.1374 - val_loss: 209.8491\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.1577 - val_loss: 207.0248\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.2349 - val_loss: 203.1522\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.8290 - val_loss: 202.7514\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.1907 - val_loss: 200.5031\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.0328 - val_loss: 198.8708\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.6534 - val_loss: 196.8209\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.2607 - val_loss: 195.5838\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.5616 - val_loss: 193.8728\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 161.1447 - val_loss: 191.5418\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.1259 - val_loss: 191.3445\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.4318 - val_loss: 189.6885\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.8616 - val_loss: 186.6959\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.6831 - val_loss: 186.5543\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.2124 - val_loss: 183.8194\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.4683 - val_loss: 182.6164\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.2970 - val_loss: 180.5036\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.4180 - val_loss: 180.6531\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.3145 - val_loss: 177.6799\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.9228 - val_loss: 178.0174\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.3955 - val_loss: 175.4910\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.4433 - val_loss: 174.2965\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.2810 - val_loss: 173.4874\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.2395 - val_loss: 171.7985\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.4126 - val_loss: 169.7766\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.7332 - val_loss: 169.9265\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.8145 - val_loss: 166.5953\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.5586 - val_loss: 168.9703\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.2061 - val_loss: 165.5860\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.3778 - val_loss: 166.7034\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.9734 - val_loss: 163.9383\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.6669 - val_loss: 163.3242\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.1870 - val_loss: 161.7969\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.3175 - val_loss: 160.2407\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.8677 - val_loss: 160.6927\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.0847 - val_loss: 159.6181\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.2031 - val_loss: 158.2556\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.8197 - val_loss: 157.6798\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.8323 - val_loss: 158.3523\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.7335 - val_loss: 157.3755\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.4182 - val_loss: 155.1130\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.1122 - val_loss: 154.7785\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.2618 - val_loss: 154.7083\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.6836 - val_loss: 154.3936\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.1874 - val_loss: 154.3119\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.5757 - val_loss: 151.8187\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.8071 - val_loss: 151.6516\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.6009 - val_loss: 154.5230\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.0147 - val_loss: 150.7028\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 131.0255 - val_loss: 151.8491\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.2601 - val_loss: 148.6758\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.3234 - val_loss: 148.5306\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.8797 - val_loss: 148.4105\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.1335 - val_loss: 148.8454\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.2153 - val_loss: 146.9443\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.8937 - val_loss: 147.0795\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.8918 - val_loss: 147.7582\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.7398 - val_loss: 148.1568\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.1309 - val_loss: 146.9634\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.7861 - val_loss: 148.9912\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.6987 - val_loss: 145.5950\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.1157 - val_loss: 146.9293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.6694 - val_loss: 144.6448\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.2561 - val_loss: 147.6544\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.3205 - val_loss: 144.9046\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.0122 - val_loss: 146.1195\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.7148 - val_loss: 144.1077\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.0977 - val_loss: 144.9771\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.0441 - val_loss: 144.9113\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.7821 - val_loss: 145.5671\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.2176 - val_loss: 143.7613\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.9350 - val_loss: 149.2966\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.5456 - val_loss: 144.2745\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.8316 - val_loss: 148.5108\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.6298 - val_loss: 145.0259\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.9088 - val_loss: 145.1605\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.8652 - val_loss: 146.3894\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.9414 - val_loss: 145.7677\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.4223 - val_loss: 144.1366\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.2232 - val_loss: 145.9449\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.8532 - val_loss: 144.9185\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.4529 - val_loss: 143.5655\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.5258 - val_loss: 143.8504\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 10ms/step - loss: 1526.6897 - val_loss: 1626.7255\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1504.3967 - val_loss: 1596.0840\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1458.6464 - val_loss: 1525.4003\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1356.7434 - val_loss: 1377.3195\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1160.9296 - val_loss: 1109.3669\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 842.7674 - val_loss: 705.9933\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 456.0552 - val_loss: 344.8480\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 255.7366 - val_loss: 241.5954\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 215.0738 - val_loss: 230.7212\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.6211 - val_loss: 225.7844\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.9486 - val_loss: 220.4967\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 194.5946 - val_loss: 216.2757\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.1142 - val_loss: 212.3453\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.4802 - val_loss: 209.3575\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.2547 - val_loss: 206.6631\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.1631 - val_loss: 204.4846\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.4371 - val_loss: 201.0758\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.1225 - val_loss: 197.9082\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.7903 - val_loss: 197.7728\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.0939 - val_loss: 195.0637\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.1994 - val_loss: 192.8110\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.7298 - val_loss: 190.0118\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 169.4306 - val_loss: 190.4037\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.1397 - val_loss: 188.6149\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.1512 - val_loss: 185.9393\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.4852 - val_loss: 184.3552\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.1461 - val_loss: 184.3872\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.0249 - val_loss: 182.4618\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.5239 - val_loss: 182.0409\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.6332 - val_loss: 179.8971\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.5225 - val_loss: 178.8195\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.3912 - val_loss: 176.5683\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.7907 - val_loss: 175.6475\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.9119 - val_loss: 176.0092\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.0086 - val_loss: 173.5884\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.1849 - val_loss: 172.7451\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.1885 - val_loss: 171.5788\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.0020 - val_loss: 170.2011\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.1954 - val_loss: 169.7963\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.8872 - val_loss: 167.9941\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.0194 - val_loss: 167.9050\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.2578 - val_loss: 166.3386\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 146.8724 - val_loss: 165.4593\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.2088 - val_loss: 164.1118\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.1957 - val_loss: 164.0811\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.1834 - val_loss: 162.2679\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.6164 - val_loss: 162.0358\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.5596 - val_loss: 160.5765\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.9043 - val_loss: 159.3444\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.5016 - val_loss: 158.4632\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.2480 - val_loss: 157.0016\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.2648 - val_loss: 155.9375\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.2074 - val_loss: 156.0375\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.7781 - val_loss: 155.5193\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.0617 - val_loss: 154.2066\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.2391 - val_loss: 153.3236\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.4300 - val_loss: 152.1171\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.6660 - val_loss: 152.1620\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.7516 - val_loss: 151.5606\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.3710 - val_loss: 150.8228\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.7404 - val_loss: 149.1694\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.0449 - val_loss: 149.7761\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.9896 - val_loss: 149.0149\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.8159 - val_loss: 148.2060\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.0541 - val_loss: 148.0561\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 128.1834 - val_loss: 146.0240\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.0240 - val_loss: 146.9106\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.7514 - val_loss: 146.1849\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.5647 - val_loss: 145.1701\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.9779 - val_loss: 144.2169\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.7599 - val_loss: 145.1512\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.6148 - val_loss: 144.6025\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.6196 - val_loss: 143.7867\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 123.8875 - val_loss: 144.3070\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.6885 - val_loss: 143.1832\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.5588 - val_loss: 143.7378\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.9154 - val_loss: 142.7990\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.3812 - val_loss: 142.3949\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.3502 - val_loss: 141.9799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.2289 - val_loss: 143.8355\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.6058 - val_loss: 142.3085\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.7339 - val_loss: 143.3103\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.7507 - val_loss: 142.1660\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.0399 - val_loss: 141.2682\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.5785 - val_loss: 141.9227\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.2741 - val_loss: 142.2101\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.6627 - val_loss: 142.2337\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.6034 - val_loss: 141.1601\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.4030 - val_loss: 141.6275\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.0513 - val_loss: 141.4964\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.2166 - val_loss: 140.6794\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.0123 - val_loss: 141.7236\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.8809 - val_loss: 140.9069\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.6826 - val_loss: 141.3288\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.1089 - val_loss: 141.5642\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 118.3417 - val_loss: 141.9320\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.3356 - val_loss: 140.9984\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.8896 - val_loss: 141.6617\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.1865 - val_loss: 141.6971\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 116.6367 - val_loss: 142.3215\n",
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 8ms/step - loss: 1507.4641 - val_loss: 1441.0758\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1424.2991 - val_loss: 1325.3800\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1272.7635 - val_loss: 1117.1519\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1011.8492 - val_loss: 779.5171\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 629.0636 - val_loss: 388.1018\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.3305 - val_loss: 232.8629\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 234.3872 - val_loss: 224.6848\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 214.9803 - val_loss: 217.5190\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.5726 - val_loss: 212.5945\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.9295 - val_loss: 209.7346\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.6577 - val_loss: 205.6682\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.7460 - val_loss: 202.4364\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 188.1210 - val_loss: 200.2834\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.2934 - val_loss: 196.3721\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.9964 - val_loss: 194.5763\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.4374 - val_loss: 192.3017\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.1469 - val_loss: 190.5553\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.3435 - val_loss: 188.2426\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.4392 - val_loss: 186.0887\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.5426 - val_loss: 184.8504\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 172.2504 - val_loss: 183.1889\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.4210 - val_loss: 182.2337\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.9124 - val_loss: 181.0406\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.0186 - val_loss: 180.5880\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.9234 - val_loss: 178.9135\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.7143 - val_loss: 177.0408\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.3835 - val_loss: 176.2036\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 163.6935 - val_loss: 175.8802\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.3029 - val_loss: 173.9215\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.1089 - val_loss: 173.4691\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.3161 - val_loss: 172.2492\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.3220 - val_loss: 172.0791\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.4111 - val_loss: 171.3419\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.1406 - val_loss: 169.9422\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.3895 - val_loss: 168.3482\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.4652 - val_loss: 168.2393\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.7950 - val_loss: 167.0863\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 155.1729 - val_loss: 166.6790\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.3971 - val_loss: 166.2424\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 152.3783 - val_loss: 166.6122\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.7558 - val_loss: 165.1012\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.8405 - val_loss: 164.6901\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.2681 - val_loss: 163.2487\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.7920 - val_loss: 165.0360\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.0632 - val_loss: 162.7116\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.6056 - val_loss: 163.2135\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.6543 - val_loss: 160.5448\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.4075 - val_loss: 162.5093\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.3855 - val_loss: 160.9485\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.9261 - val_loss: 160.8383\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.4585 - val_loss: 160.4975\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.2128 - val_loss: 159.9304\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.9085 - val_loss: 159.6711\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.3635 - val_loss: 159.1340\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.9234 - val_loss: 158.5719\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.4433 - val_loss: 157.8288\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.0836 - val_loss: 157.6433\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.9035 - val_loss: 158.3700\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.4705 - val_loss: 157.0473\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.3934 - val_loss: 158.2365\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.2088 - val_loss: 156.5329\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.7848 - val_loss: 156.0688\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.1618 - val_loss: 157.0456\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.6661 - val_loss: 156.4705\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.6260 - val_loss: 156.0314\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.5977 - val_loss: 156.9084\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.0207 - val_loss: 154.4078\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 137.1192 - val_loss: 155.1328\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.0979 - val_loss: 154.3553\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.9882 - val_loss: 154.8737\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.1182 - val_loss: 155.9654\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.2546 - val_loss: 153.5158\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.0885 - val_loss: 154.8147\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.3711 - val_loss: 153.4029\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.9450 - val_loss: 155.4015\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.0384 - val_loss: 154.0991\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.4312 - val_loss: 154.1809\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.3605 - val_loss: 154.2539\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.2572 - val_loss: 153.9101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.3396 - val_loss: 153.7910\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.5492 - val_loss: 153.6979\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.5096 - val_loss: 152.8811\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.7934 - val_loss: 152.7941\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.7257 - val_loss: 152.7539\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.1313 - val_loss: 153.1247\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.7833 - val_loss: 151.5794\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.7811 - val_loss: 152.5853\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 131.2392 - val_loss: 153.7603\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.8857 - val_loss: 151.0780\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.6155 - val_loss: 151.7676\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.6950 - val_loss: 151.7770\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.4420 - val_loss: 152.3301\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.4093 - val_loss: 151.5580\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.8339 - val_loss: 151.1079\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.4272 - val_loss: 152.7101\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.7418 - val_loss: 151.8574\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.2894 - val_loss: 151.1050\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.2419 - val_loss: 150.8509\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 128.8497 - val_loss: 151.5419\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.6897 - val_loss: 151.0806\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#The code\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "\n",
    "mse_values = []\n",
    "for i in range(50):\n",
    "    #The train test split:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3) \n",
    "    #Producing the model:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape=(X.shape[1],), activation='relu'))  # Input layer with 32 neurons\n",
    "    model.add(Dense(10, activation='relu'))  # Hidden layer with 10 neurons\n",
    "    model.add(Dense(10, activation='relu'))  # Hidden layer with 10 neurons\n",
    "    model.add(Dense(10, activation='relu'))  # Hidden layer with 10 neurons\n",
    "    model.add(Dense(1, activation='linear'))  \n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.001))\n",
    "    model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcecc30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average MSE over 50 runs: 143.16554021699667\n",
      "\n",
      "Average MSE standard deviations over 50 runs: 8.614863367744078\n"
     ]
    }
   ],
   "source": [
    "average_mse = np.mean(mse_values)\n",
    "std_dev_mse=np.std(mse_values)\n",
    "print(f\"\\nAverage MSE over 50 runs: {average_mse}\")\n",
    "print(f\"\\nAverage MSE standard deviations over 50 runs: {std_dev_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc3019b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## In comparison to the \"B model\", both the MSE and its standard deviation decreased."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
